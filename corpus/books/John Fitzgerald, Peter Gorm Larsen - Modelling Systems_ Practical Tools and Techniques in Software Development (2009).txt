***John Fitzgerald, Peter Gorm Larsen - Modelling Systems_ Practical Tools and Techniques in Software Development (2009)***









































MODELLING SYSTEMS: PRACTICAL TOOLS AND
TECHNIQUES IN SOFTWARE DEVELOPMENT

Second Edition

How can we make sure that the software we build does what it is supposed to
do? This book provides an insight into established techniques that help developers
overcome the complexity of software development by constructing models of soft-
ware systems in early design stages. It uses one of the leading formal methods, the
Vienna Development Method (VDM), and combines training in the formalism with
industry-strength tool support and examples derived from real industrial applica-
tions. The principles taught here also apply to many of the current generation of
formal methods.

This second edition has been updated to include advanced online tool support
for formal modelling as well as up-to-date reports on real commercial applications
in areas as diverse as business information systems and firmware design.





MODELLING SYSTEMS:
PRACTICAL TOOLS AND TECHNIQUES

IN SOFTWARE DEVELOPMENT

Second Edition

JOHN FITZGERALD

and

PETER GORM LARSEN



C A M B R I D G E U N I V E R S I T Y P R E S S

Cambridge, New York, Melbourne, Madrid, Cape Town, Singapore, São Paulo, Delhi

Cambridge University Press
The Edinburgh Building, Cambridge CB2 8RU, UK

Published in the United States of America by Cambridge University Press, New York

www.cambridge.org
Information on this title: www.cambridge.org/9780521899116

c© Cambridge University Press 1998, 2009

This publication is in copyright. Subject to statutory exception
and to the provisions of relevant collective licensing agreements,

no reproduction of any part may take place without
the written permission of Cambridge University Press.

First published 1998
Second edition 2009

Printed in the United Kingdom at the University Press, Cambridge

A catalogue record for this publication is available from the British Library

ISBN 978-0-521-89911-6 hardback

Additional resources for this publication at www.vdmbook.com

Cambridge University Press has no responsibility for
the persistence or accuracy of URLs for external or

third-party Internet websites referred to in this publication,
and does not guarantee that any content on such

websites is, or will remain, accurate or appropriate.



Contents

Foreword page ix
Preface xi
1 Introduction 1

1.1 Software 1
1.2 Modelling and analysis 2
1.3 This book 3
1.4 VDM-SL 4
1.5 The structure of a VDM-SL model 4
1.6 Analysing a model 9

2 Constructing a Model 13
2.1 Introduction 13
2.2 Requirements for an alarm system 13
2.3 Constructing a model from scratch 14
2.4 Reading the requirements 15
2.5 Extracting possible types and functions 16
2.6 Sketching type representations 16
2.7 Sketching function signatures 22
2.8 Completing the type definitions 23
2.9 Completing the function definitions 24
2.10 Reviewing requirements 29

3 VDMTools Lite 35
3.1 Introduction 35
3.2 Installing VDMTools Lite 36
3.3 Configuring the alarm example 36
3.4 Syntax and type checking models 38
3.5 Interpreting and debugging models 42
3.6 Test coverage 48

v



vi Contents

3.7 Integrity checking 49
3.8 Setting options 50

4 Describing System Properties Using Logical Expressions 55
4.1 Introduction 55
4.2 The temperature monitor 55
4.3 Logical expressions 57
4.4 Presenting and evaluating predicates 64
4.5 Using quantifiers 66
4.6 Coping with undefinedness 71

5 The Elements of a Formal Model 77
5.1 Introduction 77
5.2 A traffic light control kernel 78
5.3 Union and basic types 81
5.4 Basic type constructors 83
5.5 Record types 84
5.6 Invariants 85
5.7 Explicit function definitions 87
5.8 Functions for changing signals 88
5.9 Reviewing the safety requirements 96
5.10 Optional types: modelling failure behaviour 96

6 Sets 99
6.1 Introduction 99
6.2 The set type constructor 100
6.3 Defining sets 101
6.4 Modelling with sets 103
6.5 Distributed set operators 115
6.6 Summary 118

7 Sequences 121
7.1 Introduction 121
7.2 The sequence type constructor 122
7.3 Defining sequences 122
7.4 Modelling with sequences 125
7.5 Further operators on sequences 132
7.6 Abstraction lesson: choosing abstraction levels 135

8 Mappings 137
8.1 Introduction 137
8.2 The mapping type constructor 139
8.3 Defining mappings 139
8.4 Modelling with mappings 140
8.5 Summary 154



Contents vii

9 Recursive Structures 157
9.1 Recursive data structures: trees 157
9.2 Abstract syntax trees 161
9.3 Directed graphs 164
9.4 An application of directed graphs: code optimisation 167
9.5 Abstraction lesson: executability 169

10 Validating Models 171
10.1 Introduction 171
10.2 Internal consistency: proof obligations 173
10.3 Visualisation of a model 180
10.4 Interfacing to legacy code 182
10.5 Systematic testing 183
10.6 Using proofs 184
10.7 Choosing a validation technique 187

11 State-Based Modelling 189
11.1 Introduction 189
11.2 State-based modelling 190
11.3 A state-based model of the explosives store controller 191
11.4 A state-based model of the trusted gateway 196
11.5 Validation of state-based models 199

12 Large-Scale Modelling 203
12.1 Introduction 203
12.2 A structure for the tracker model 204
12.3 Information hiding 212
12.4 Object-oriented structuring 214

13 Using VDM in Practice 217
13.1 Introduction 217
13.2 Development activities and processes 218
13.3 Common development problems 219
13.4 Advantages of VDM technology 220
13.5 Getting started 223
13.6 VDM and its extensions 226
13.7 Industrial applications of VDM 227
13.8 Moving on: information resources 232

Appendix A Language Guide 235
A.1 Identifiers 235
A.2 Type definitions 236
A.3 Basic data types and type constructors 236
A.4 Data type operator overview 237
A.5 Expressions 246



viii Contents

A.6 Patterns 248
A.7 Bindings 249
A.8 Explicit function definition 249
A.9 Implicit functions 250
A.10 Operations 250
A.11 The state definition 251
A.12 Syntax overview 252

Appendix B Solutions to Exercises 263
B.1 Solutions for Chapter 2 Exercises 263
B.2 Solutions for Chapter 3 Exercises 263
B.3 Solutions for Chapter 4 Exercises 264
B.4 Solutions for Chapter 5 Exercises 265
B.5 Solutions for Chapter 6 Exercises 266
B.6 Solutions for Chapter 7 Exercises 268
B.7 Solutions for Chapter 8 Exercises 268
B.8 Solutions for Chapter 9 Exercises 270
B.9 Solutions for Chapter 10 Exercises 273
B.10 Solutions for Chapter 11 Exercises 275

Bibliography 277
Subject Index 283
Definitions Index 287



Foreword

Software engineers produce many descriptions: those of the environment or
domain in which a desired computing system software is to exist; descriptions of
the requirements put on the software; and descriptions of the software design that
implements the requirements. Thus the descriptions span the spectrum from appli-
cation domain, via requirements and software architecture, program organisation
and lower level designs, to executable code. While its concerns may be general,
software engineering is unique among engineering disciplines in that its primary
products are descriptions that must eventually satisfy the laws of mathematical
logic and metamathematics.

Other engineering disciplines have to handle a quantum leap into physical real-
ity – the stuff of natural science. In software engineering there is a different
quantum leap: that from description to execution. Software engineering is thus
about structuring and relating descriptions.

Abstraction and modelling taken together are the keys to mastering the com-
plexity of environments and systems. Formal specification is employed to express
abstractions and to ensure affinity to real domains. Such specifications open up
ways to establish the proper relation between domain and requirements models as
well as potentially verifying the links between software architecture, requirements
models and the stages of design. This increases the chance of achieving a proper fit
to the environment, to user expectations and of the correctness of implementation.

VDM was first conceived at the IBM Vienna Laboratory during the summer of
1973. The quarter of a century which separates that date from the publication of
this book has shown that VDM is characterised by having remarkably robust, yet
simple and elegant, means of abstraction and modelling. Careful attention was paid
during the 1980s to ensuring a consistent and comprehensive final version of the
VDM Specification Language (VDM-SL). This was supported by a method for
specification refinement (reification) including a Logic for Partial Functions Proof

ix



x Foreword

System. VDM is today as powerful a tool and technique for software development
as any available.

Software development is pursued in a world where the engineer is not always
allowed to pursue the ideas of formal development as epitomised by VDM-SL.
But anyone who is aware of the fundamental idea of building abstract models can
benefit from its immense power to aid understanding and communication.

In this delightful book former students of ours bring you realistic and effective
techniques for abstraction and modelling. The practical, tool-based, approach is
one which should give their readers and students (present and future software engi-
neers) the ability to employ these techniques in their everyday work.

Dines Bjørner
Cliff Jones

Hiroshima, November 1997



Preface

For developers of computer-based systems, capturing and understanding the com-
plex functional requirements and behaviour of software components has come to
represent a considerable challenge. This book aims to equip readers with skills and
techniques which will help them to address this challenge. It does so by stressing
the value of abstract system models which can be analysed and tested before an
expensive commitment is made to a particular design strategy. The book enables
the reader to understand the role and nature of abstract models as well as gain
practical experience in their creation.

In order to permit machine-supported analysis, system models must be formu-
lated in a well-defined notation. In this text, we use a formally defined language
called VDM-SL (the Vienna Development Method Specification Language). The
Vienna Development Method is a collection of techniques for developing comput-
ing systems from models expressed in the language. Since its origin in an industrial
environment, VDM has become one of the most widely used of a class of tech-
niques known as model-oriented formal methods. The language VDM-SL was
recently standardised by the International Organization for Standardization (ISO).
Although VDM-SL is used as a teaching medium in this text, the principles taught
apply equally well to other model-based formal methods such as B, RAISE and Z.

In this book we take a pragmatic approach to the use of formal methods. We aim
to illustrate the concepts and techniques used in VDM without overwhelming the
reader with mathematics. Unlike most teaching texts on formal methods, this book
does not treat formal refinement or formal proof. Instead it focuses on the construc-
tion of abstract and formal models for a range of computer systems. Mastering the
construction and validation of abstract models is in our view a prerequisite for
entering the world of verification.

This book is unusual in two other respects. First, the majority of the examples
presented are inspired by models developed in industrial projects over recent years.

xi



xii Preface

We believe that examples grounded in industrial practice provide motivating illus-
trations of the fact that this technology can be used for development of real systems
and not simply for stacks and vending machines. Second, the skills to develop
abstract models can only be acquired through practice. Throughout the text, the
use of an industrial tool is encouraged, in order to develop the reader’s intuitive
grasp of the reality of modelling.

Robust and appropriate tool support is essential for industrial application of
modelling technology, so hands-on experience is stressed throughout this book.
Readers will gain the most benefit if they use the freely available VDMTools tool
set1 introduced in Chapter 3. It is possible to carry out the exercises without tool
support, but this will not give the reader an appreciation of what can be expected
from such tools.

The web site accompanying this book (http://www.vdmbook.com) pro-
vides all the example models presented in the book, additional models used
for exercises and links to the full VDM-SL language manuals. This book uses
the (ASCII) interchange syntax of VDM-SL rather than the mathematical syn-
tax which is used in most some of the older texts. It is our experience that this
notation presents less of a barrier to the novice who does not have experience in
mathematical logic.

The subset of VDM-SL used in this book includes facilities for state-based spec-
ification. However, readers already familiar with VDM will notice that the tutorial
content is biased towards a functional modelling style. The functional style pro-
vides an environment in which type constructors and operators can be covered
without the distraction of operation syntax, side-effects and access restrictions
to external variables. Once the elements of data and functional modelling have
been covered, the ‘state and operations’ paradigm is introduced. The text omits
a discussion of explicit operations, because it is our experience that those who
learn abstraction skills within the language subset we have chosen can learn to
use explicit operations very easily, on the basis of experience from programming
languages.

Using this book

This text is aimed at software engineers who wish to investigate how the use
of models can improve the software development process, and at university
students studying software engineering or computing science. The material in

1 The URL is http://www.vdmtools.jp/en or via the book’s support pages at http://www.
vdmbook.com.



Preface xiii

the book has been used successfully on industrial training courses, undergradu-
ate and postgraduate level [Larsen&08]. The text is designed with independent
study in mind, and the support materials and discussion lists accessible via
http://www.vdmbook.com provide further support for readers not studying
this material as part of a university course.

No formal mathematical background is assumed, but the authors find that stu-
dents gain most benefit when they have some familiarity with programming and
with the realities of software development. In the university context, students’
experience of constructing a large piece of software in a group project, sometimes
suffering serious setbacks during integration, has been found to provide a valuable
motivating lesson.

The objective of this book is to bring readers to a point where they are able to
read, write and analyse formal models of computing systems using VDM-SL and
have an understanding of the kind of problems to which these techniques can be
applied cost-effectively.

The book is divided into four parts. Chapters 1 to 3 form the introductory mate-
rial. The first two chapters motivate and introduce the notion of modelling using
a formal language and indicate a systematic approach for using this kind of tech-
nology. On reaching the end of Chapter 2, the reader will have seen most of the
elements of VDM-SL covered in the book. Chapter 3 introduces VDMTools Lite,
the tool support provided for the tutorial material. Chapters 4 to 8 form the core of
the book, covering the use of logic, basic data types, type constructors and func-
tions in constructing models. Each of these chapters contains a description of the
requirements for an application for which a model is developed, introducing each
modelling construct in VDM-SL as it is needed. Chapters 10 to 12 are concerned
with the use of models in practice, in particular validation techniques, the repre-
sentation of persistent state and dealing with large-scale system models. The final
part of the book examines the introduction and use of formal modelling in the com-
mercial context. Chapter 13 discusses the introduction of modelling technology in
the industrial environment. The appendices include a language guide for the subset
of VDM-SL used in the text and supported by VDMTools along with solutions to
exercises.

Readers using the book as an introduction to formal modelling can follow the
text in the order in which it is presented. Practising software engineers may prefer
to read Chapter 13 after Chapter 1 for a consideration of the costs and benefits of
applying the techniques covered in depth in the remainder of the book.

Although the book is intended to embody a single course in formal modelling,
Chapters 1 to 9 would be suitable for a course covering modelling only. The
material in Chapter 9 on recursive structures is slightly more demanding than
the preceding chapters. Chapters 10 to 13 could be used in a second and more



xiv Preface

advanced course including a significant assignment in which students can explore
the construction and analysis of a model.

Exercises are included in the flow of the text and should be attempted as they are
encountered. More substantial exercises are normally included at the end of each
of the central chapters. Those exercises marked with a star (�) are more demand-
ing than the average. It is our experience presenting this material that instructors
are asked for large numbers of small exercises which increase familiarity with the
language. Often, lecturers also require more demanding exercises for the most
enthusiastic and capable students. Teaching material including samples of lec-
ture notes, slides and exercises of both these kinds will become available from
the World Wide Web Page at http://www.vdmportal.org/.

The production of a formal model is much less straightforward than a textbook
might lead one to suppose. By presenting particular models as solutions to prob-
lems, we do not intend to imply that they are the only, or even the best, solutions.
In addition, the developer of a model runs into many “dead ends” before reach-
ing a good solution. We are unable to present this process in all its detail in
this volume, but we do record some aspects of our practical experience which
we feel would be most helpful. This is done in distinguished boxes of text such
as this.

Developments since the first edition

When we published the first edition of this book ten years ago, our aim was
to lower the barrier to using formal modelling techniques that were still seen
as forbidding, specialised and expensive. By emphasising tool support, and by
using examples derived from industry applications, we hoped to encourage read-
ers to apply abstraction and modelling principles in a wide range of applications.
Although the underlying aim remains unchanged, this second edition takes account
of the significant developments in formal modelling, tool support, industry appli-
cation and experience gained in teaching and training in formal methods in the last
decade.

Tool support for the first edition took the form of a limited-capability version of
the VDM Toolbox, then being developed by IFAD A/S in Denmark. The Toolbox
technology was subsequently acquired and extended by CSK Systems in Japan,
following their successful application of VDM to a major financial back-office
system (TradeOne, described in Chapter 13). The tool that accompanies this second
edition takes advantage of CSK’s developments. VDMTools Lite now supports the
full VDM-SL language instead of just the subset covered in the book. Restrictions



Preface xv

on the size of model have been removed. The full functionality of the tool set is now
available, with the exception of the application programmer interface, the dynamic
linking facility and the C++ code generator.

Since the first edition was published, both of us have worked in the software
industry, in areas as diverse as business development and design of binary trans-
lation technology. The experience has reinforced our view that formal modelling
technology must work with existing development tools and processes, rather than
supplant them, if its benefits are to be realised. We have also become more aware
of the trade-off between the effort expended in analysing models and the insights
gained by doing so. As a result, we have added material on recent industrial appli-
cations of VDM (Chapter 13) and updated the industry-based examples throughout
the book. Our experience teaching formal modelling to practitioner engineers and
to university students has emphasised the importance of abstraction as a core skill
in modelling. We reinforce this point with abstraction lessons in each of the core
chapters.

This book concentrates on the core VDM-SL notation and the fundamentals of
abstraction and rigorous reasoning about system models. Over the last ten years,
the capabilities of the VDM formalism itself have been extended to encompass
development of concurrent and object-oriented systems, and real-time and dis-
tributed systems. We have added pointers into these more specialised and advanced
applications in the expanded Chapter 13.

Acknowledgements

We would like to thank our former professors Cliff Jones and Dines Bjørner for
introducing us to the subject of formal methods and to VDM in particular. Our
thanks also go to our supportive and patient editor David Tranah from Cambridge
University Press and to our colleagues at CSK in Japan, especially Shin Sahara.

Many colleagues have provided valuable comments on drafts of the book in
both editions: Sten Agerholm, Bernhard Aichernig, Mo Ajmal, Paul Ammann,
Nick Battle, Peer Bonnerup, Carsten Breum, Jeremy Bryans, Hanne Carlsen,
Tim Clement, Ian Cottam, Lionel Devauchelle, Albert Esterline, Kelsey Francis,
Brigitte Fröhlich, Anne Haxthausen, Niels Kirkegaard, Ole Bjerg Larsen, Janusz
Laski, Yves Ledru, David Morgan, Paul Mukherjee, Anne Berit Nielsen,
Erik Toubro Nielsen, Takahiko Ogino, José Nuno Oliveira, Lars Toftegaard
Olsen, Richard Payne, Jan Storbank Pedersen, Marie-Laure Potet, Abd-El-Kader
Sahraoui, Paul Smith, Vincent Stephan, Elliot Sullivan, Marcel Verhoef, Henrik
Voss and Mark Wigmans.

The first edition was published in a Japanese translation by the Iwanami Shoten
publisher in 2003. We are particularly grateful to our skilled translators: Keijiro



xvi Preface

Araki, Takahiko Ogino, Shin Sahara and Makoto Someya. Their work has been
a major stepping stone towards the adoption of formal modelling technology in
Japan.

Many colleagues were kind enough to use the first edition in courses on formal
modelling, and to provide us with comments and corrections. We are particularly
grateful to Bernhard Aichernig, V. S. Alagar, Pascal André, Keijiro Araki, Andreas
Bollin, Dan Cristea, Albert Esterline, Pascal Fenkam, Mats Heimdahl, Keith Hop-
per, Zarinah Mohd Kasirun, Janusz Laski, Yves Ledru, Peter Lucas, Michael Lutz,
Dominique Mery, Farid Mezidane, Pascal Molli, David Morgan, Tony Moynihan,
José Nuno Oliveira, Kasi Periyasamy, Steve Riddle, Angela Shiflet, Ivor Spence
and Robert Topp. Our thanks are also due to the hundreds of students who have
participated in our courses at Newcastle University and the Engineering College of
Aarhus.

We gratefully acknowledge the support of the European Union Framework 7
IST Project “DEPLOY” on industrial deployment of advanced system engineering
methods and the Erasmus programme for supporting our continued collaboration
on the learning and teaching of formal methods.

As always, we reserve our deepest thanks for our closest friends and families
who allowed us, once again, a decade on, to take advantage of their patience.

John Fitzgerald
Peter Gorm Larsen

Aarhus, Denmark



1
Introduction

Aims
The aim of this chapter is to provide a motivation for studying the mod-

elling of computing systems by discussing the challenges of developing correct
software. On completion of this chapter, the reader should be aware of the main
concepts to be presented in the book and know where to find the relevant mate-
rial in the text.

1.1 Software
Software is pervasive, error-prone, expensive to develop and, as an en-

gineering medium, extraordinarily seductive. Its seemingly infinite flexibility,
increasing power and the absence of physical characteristics, such as weight,
make it an ideal medium in which to express complex models which might not
exist at all were it not for software. As a result, software is often developed for
applications which are critical either to an enterprise’s mission or to the quality
of life of those with whom the system interacts.

Challenged by the variety and scale of software applications, the participants
in the 1968 NATO Conference on Software Engineering foresaw a discipline of
software development with a sound scientific basis [Naur&69]. Over the last 40
years, there is little doubt that enormous advances have been made in our ability
to control software development. However, software projects continue to suffer
from serious difficulties which can lead to the delivery of faulty goods that are
over budget and behind schedule.

The rapid increase in processor power has naturally led to increasing demands
being made on software and its developers. Software is almost always devel-
oped as part of a larger system involving computing hardware, special systems
such as sensors and actuators, human-computer interfaces and human beings.
However, the long lead-times associated with the production of special items of
hardware mean that additional functionality caused by changes in customers’
requirements is often realised in software because that medium is seen as more
flexible.

1



2 1 Introduction

A comparison between software engineering and the engineering in other me-
dia, whether mechanical, fluid, chemical or electronic, is difficult because of the
different characteristics of those media. However, there is little doubt that soft-
ware engineers can still learn from other more mature engineering disciplines.

1.2 Modelling and analysis
One of the major differences between software engineering and other

forms of engineering is that the other disciplines have a longer tradition of con-
structing abstract models of the product in the early stages of development. Such
models serve as a proving ground for design ideas and as a communication
medium between engineers and customers. As a result of modelling, engineers
can avoid errors which might otherwise only become obvious in the very late
stages of development, when expensive commitments have been made to mate-
rials and designs. There are two aspects of these models which are crucial to
their successful use: abstraction and rigour.

Engineering models are abstract in the sense that aspects of the product not
relevant to the analysis in hand are not included. For example, an aeronautical
engineer investigating the aerodynamics of an aircraft design may model the air
flow over the surfaces (mathematically or in a wind tunnel) because air flow is a
dominant design parameter. The model is unlikely to include the user interface
of the cockpit instruments. Similarly, human factors engineers who design cock-
pit instruments model the cockpit, not the aerodynamics of the wing surfaces.
The choice of which aspects of a system should be included in the model (its
level of abstraction) is a matter of engineering skill.

Perhaps the most significant property of a system model is its suitability for
analysis. The purpose of such an analysis is to provide an objective assess-
ment of a model’s properties. For example, a model of a new design of bridge
might be used to assess the design’s ability to withstand physical stresses with
acceptable risk of collapse. This contrasts with the more subjective analysis of
a review or inspection in which the outcome may depend on the consultants
carrying out the job. It is also important to be able to repeat the assessment on
alternative models and to be able to perform as much as possible of the analysis
mechanically, in order to minimise the risk of subjectivity and error as well as
the required human effort. To obtain this level of objectivity, mechanisation and
repeatability, mathematics is often used in the analysis. Indeed, many system
models exist only as mathematical constructions and not as physical entities at
all.

How do these concepts of system modelling transfer to the development of



1.3 This book 3

computing systems, and in particular to software? A wide range of modelling
techniques has been developed for computing systems, including pseudo-code,
natural language, graphical and mathematical notations. Ultimately, a computer
program could be seen as a model of the system which is to be provided: an ex-
ecutable model which meets all the relevant user requirements, or at least a large
enough subset of them to make the product acceptable. Although a wide variety
of modelling techniques is available, comparatively few provide the combina-
tion of abstraction and rigour which could bring the benefits of early detection
of errors and increased confidence in designs.

This book describes well-established modelling techniques which combine
abstraction with rigour. We will introduce the elements of a modelling language
that can be combined effectively with existing software engineering techniques,
opening up the possibility of improved analysis in early development stages.

Models expressed very abstractly in the early stages of system development
would normally be treated as specifications of a system. If the models instead
are described at a lower level of abstraction later in the process, they will nor-
mally be called designs. The borderlines between specification, design and im-
plementation are not clearly defined and the modelling and analysis techniques
discussed in this book are not confined to any particular stage of software de-
velopment. We will therefore tend to avoid loaded terms such as “specification”
and use the general term “model” to refer to the system descriptions we develop.
Nevertheless, we focus on requirements analysis and early design stages because
these are the phases in which the application of modelling is most beneficial.

1.3 This book
This book is concerned with the construction of abstract models for

computing systems. The notation used to describe such models is a subset of
the ISO standardised language VDM-SL [ISOVDM96]. The VDM-SL nota-
tion supports abstraction in a variety of ways which will be introduced in the
text. The rigour of the language lies mainly in its definition in the ISO standard,
which is extremely thorough and detailed. Indeed, the language is referred to
as a formal modelling language because its syntax and the meaning of models
expressed in the language are so thoroughly defined. This formality allows anal-
yses to be carried out consistently because the formal definition of the meaning
of the language constructs leaves little or no room for interpretations to differ
between support tools or practitioners.

This book is about the practical exploitation of modelling techniques. Our
pragmatic approach is realised in three ways. First, we make extensive use of a



4 1 Introduction

tool, VDMTools, which has a strong record of industrial application and which is
available for free download. Most exercises in the book are designed to provide
training in both modelling concepts and tool support. Second, we use concrete
examples to motivate the introduction of language features. The majority of
these examples are derived from real models developed by industrial engineers
or in close collaboration with industry. Third, the validation approach we use in
this book exploits testing rather than proof, which we see as a more advanced
technique to be used when occasion demands, but which does not form a part of
the initial training offered here.

1.4 VDM-SL
The Vienna Development Method (VDM) is a collection of techniques

for modelling, analysing and developing sequential software systems. VDM’s
modelling language, which we use as the main vehicle in this book, is commonly
known as VDM-SL (the VDM Specification Language). It is one of the most
widely used modelling languages, having been applied to the construction of
a variety of software systems. Its name refers to its origin in IBM’s Vienna
Development Laboratory [Jones99].

The VDM-SL notation is fixed in an ISO standard [ISOVDM96]. It permits
both abstraction from the data structures to be used in the final implementa-
tion of the system and also algorithm abstraction, whereby one can state what a
function should do without having to provide detail on how it should work.

The analysis techniques for models in VDM-SL covered in this text include
static checking of syntax and type-correctness of models, and animation of mod-
els by execution. Mathematical proof can be used to show internal consistency
of models and to show that less abstract models are faithful to more abstract
models of the same system. However, this book does not seek to cover the proof
techniques, instead focussing on the construction of models and analysis by the
other means mentioned above.

1.5 The structure of a VDM-SL model
This section provides a very brief introduction to the structure of a

VDM-SL model through the example of a simple air traffic control system which
monitors the movements of aircraft in the airspace around an airport. In what
follows, we are not concerned with notational detail, but only with the general
form and content of the model. As each main feature of the model emerges,
a reference is given to the relevant part of the book. The process of deriving



1.5 The structure of a VDM-SL model 5

a VDM-SL model from a collection of customer requirements is discussed in
Chapter 2.

A VDM-SL model, like many programs, is structured around descriptions
of data and functionality. Data are described through a collection of type and
value (constant) definitions; functionality is described through function defini-
tions. Each kind of definition is considered in turn below.

1.5.1 Modelling data in VDM-SL
Data are mainly modelled by means of type definitions. A type is a col-

lection of values which might arise in the model of a system. In our air traffic
control model, for example, we could have types to represent the positions of
aircraft, their latitude, longitude and altitude. A type definition gives a represen-
tation to a type. For example, the author of the air traffic control model could
choose a representation for latitudes. In VDM-SL, the modeller would write the
following1:

Latitude = ???

How could a latitude be represented? A latitude is usually a number between
−90 and +90, assuming a representation in degrees. The modelling language
VDM-SL provides the modeller with a collection of basic types from which
to build representations of new types such as Latitude. The basic types in-
clude collections of values such as the natural numbers, integers, real numbers,
Boolean values and characters. The basic types from which models can be con-
structed are introduced in Chapter 5. In this example, the representation of a
latitude could be as a real number. This would be written as follows:

Latitude = real

However, it is still necessary to record the restriction that the latitude must be
between −90 and +90. Such additional restrictions on the values included in a
type are recorded by means of invariants. An invariant is a property which must
always be true of values in a certain type. If a type has an invariant associated
with it, the invariant is stated as a Boolean expression on a typical element of
the type. Thus, the following type definition defines a type called Latitude
which contains all real numbers from −90 up to, but not including, +90. It does
this by describing the property that a typical latitude lat is greater than or equal
to −90 and less than or equal to +90. Thus:

1 In this book, VDM-SL models will be presented in a typewriter typeface.



6 1 Introduction

Latitude = real
inv lat == lat >= -90 and lat < 90

The Boolean expression defining the invariant on the type Latitude is writ-
ten and interpreted using the logic of VDM-SL. This logic, which incorporates
operators like and, or and not, is introduced in Chapter 4.

In VDM-SL there is no limit to the precision or size of the numbers in the
basic type real. This is an example of abstraction from computer systems
where a limit will exist. When the precision or maximum size of a number is a
significant factor in the model, this is expressed by defining a new type (e.g. one
called LongReal) which respects the relevant restrictions.

Types such as Latitude can be used in the representations of other, more
complex, types. For example, aircraft positions can be modelled by a type
AircraftPosition defined as follows:

AircraftPosition :: lat : Latitude
long : Longitude
alt : Altitude

Here AircraftPosition is represented as a record type. A record type is
similar to a record or struct type in other programming languages such as Ada
or C++. Its elements are values which are each made up of several components.
This definition says that an aircraft position will consist of three things: a lati-
tude, which is a value from the type Latitude; a longitude, which is a value
drawn from the type Longitude; and an altitude modelled by a value drawn
from the type Altitude. Records, and other ways to construct more complex
types from simple types, are introduced in Chapter 5.

Often it is necessary to model more elaborate data than just single numbers,
characters or records. Frequently we will need to model collections such as sets
of values, sequences of values, or mappings from values of one collection to
values of another. These three kinds of data type (sets, sequences and mappings)
are central to the construction of models in VDM-SL – so much so that they each
warrant an entire chapter later in the book (Chapters 6 to 8). As an example of
their use, we could here define a model of the flight information on a radar screen
as a mapping from aircraft identifiers to aircraft positions. The mapping can be
thought of as a table associating aircraft identifiers with positions. In VDM-SL,
we would make the following type definition:

RadarInfo = map AircraftId to AircraftPosition

The type AircraftId would be defined elsewhere in the model. In a pro-
gramming language there are many different ways of implementing this data
structure (e.g. pointer-based tree structures, arrays, hash tables) but, early in



1.5 The structure of a VDM-SL model 7

the development process, we may not be interested in precisely which structure
should be chosen. If the model has been constructed in order to analyse, for ex-
ample, the possibility of a “near miss” between aircraft being alerted, the space
efficiency of the data structure used to model the mapping is not a dominant
consideration, and so does not form part of the abstract model. At a later de-
velopment stage, this issue may become significant and so could form part of
a model used for space efficiency analysis. The use of an abstract modelling
language like VDM-SL in the early stages of design naturally encourages one to
think in this way, in terms of what concepts are needed in the model and not how
they are to be implemented.

Recursive data structures are common in software, and are especially signif-
icant in representing computer programs. Chapter 9 deals with such structures
including trees and graphs, and the recursive functions that can be used to con-
struct and traverse them.

1.5.2 Modelling functionality in VDM-SL
Given a collection of type definitions modelling system data, the sys-

tem’s behaviour is modelled by means of functions and operations defined on
the data model. For example, two functions of interest in the air traffic control
system might be functions to add a new aircraft, with its position, to the radar
information and a function to choose an aircraft to which landing permission is
to be granted.

The first function, to add a new aircraft which has just been detected by the
system, could be modelled as follows. Suppose the function is to be named
NewAircraft. When a function is defined, the types of its inputs and result
are given. In this case, the inputs are some radar information, the identifier of
the new aircraft and the position of the new aircraft. The result returned will
be a radar information mapping, the same as the input mapping, but with the
new aircraft and its position added. The types of the input and result are given
and the action performed by the function is described on some input parameters.
The function definition so far would be written as follows:

NewAircraft: RadarInfo * AircraftId * AircraftPosition ->
RadarInfo

NewAircraft(radar,airid,airpos) == ???

The “???” contains the body of the definition: an expression showing the value
of the result in terms of the input values supplied. In this case the result is just
the input mapping radar with airid and airpos added to it so that airid
maps to airpos. The details of the expression in the body of the function are



8 1 Introduction

not of concern here: they will be dealt with in full in later chapters. In VDM-SL
this is written as follows:

NewAircraft: RadarInfo * AircraftId * AircraftPosition ->
RadarInfo

NewAircraft(radar,airid,airpos) ==
radar munion {airid |-> airpos}

The NewAircraft function should not be applied to add just any aircraft to the
radar information. It should only be applied when the newly detected aircraft is
indeed new, i.e. it does not already occur in the mapping. To record a restriction
on the circumstances in which a function may be applied, a pre-condition is
used. A pre-condition is a Boolean expression which is true only for those input
values to which the function may be applied. In this example, the pre-condition
must state that the input airid is not already in the input mapping radar.
Again, the details of the expression are not important and will be discussed in
later chapters.

NewAircraft: RadarInfo * AircraftId * AircraftPosition ->
RadarInfo

NewAircraft(radar,airid,airpos) ==
radar munion {airid |-> airpos}

pre airid not in set dom radar

The function definition given here is abstract. There is no information about the
details of how the new information is to be added to the mapping. It simply
states that the new identifier and position are to be added.

In some cases, it is possible to have an even more abstract function definition.
An implicit function definition, rather than stating what the result of the function
should be, simply characterises the result by saying what properties are required
of it. This technique is often valuable where we do not wish to have to give
an algorithm for calculating a result. For example, we may not be interested
in modelling the algorithm which is used to select an aircraft for landing, but
we do need a function which describes the selection of an aircraft, because we
will wish to model its removal from the radar information once the aircraft has
landed. In this case, we do not give a result expression, but instead give a post-
condition.

A post-condition is a logical expression which states how the result is to be re-
lated to the inputs. For this example, the function SelectForLanding takes
the radar information as input and returns an aircraft identifier as the result. The
post-condition states that the result is an identifier from the mapping, but goes
no further in suggesting how the result is chosen. A pre-condition is recorded
to assert that this function should only be applied when the radar information



1.6 Analysing a model 9

is non-empty, i.e. there are some aircraft identifiers to choose from. Again, the
details of the expressions used will be dealt with in later chapters. The function
definition is as follows:

SelectForLanding(radar:RadarInfo) aircraft:AircraftId
pre dom radar <> {}
post aircraft in set dom radar

In a VDM-SL model, each function is self-contained in that the only data
which can be referred to in the function body are the input parameters. In par-
ticular, the function body has no access to any global variables. However, in this
example it is likely that many of the functions would need to access and possibly
update the radar information. There is a clear sense in which the radar informa-
tion is persistent, and the functions merely make changes to part of that radar
information. The functions in this case might be better expressed as procedures
with side-effects on global variables. For such situations it is possible to de-
scribe the persistent data in a state definition and record the modifications to the
state as operations. This state-based modelling style is the subject of Chapter 11.

The example used in this section does not reflect the size and complexity of a
realistic computing problem. Indeed, any course on modelling must use exam-
ples which fit into the textbook space available. However, Chapter 12 deals with
techniques for structuring large-scale models by splitting them into manageable,
and sometimes re-usable, modules.

1.6 Analysing a model
If a model is intended to form a basis for the development of software,

it is important to have confidence both in its internal consistency and in the ac-
curacy with which it records the customer’s original requirements. Checking
internal consistency involves ensuring that the language syntax has been cor-
rectly followed and that the functions can indeed be calculated on the values
provided as inputs (this is done by ensuring that operators are applied to values
of the correct types). A range of more demanding checks can also be performed:
for example, making sure that a function definition does not allow the invariant
on a data type to be violated. In addition, the model can be tested by supply-
ing sample input values and calculating the results of applying the functions to
these.

The process of increasing confidence in a model is called validation and is
described in detail in Chapter 10. When inconsistencies are discovered, or the
model does not correspond to expectations in some way, the model can be modi-
fied at this early stage in the development of the computing system, before going



10 1 Introduction

on to detailed design. Early identification and resolution of errors prevents their
propagation into detailed design and code and subsequent, late and expensive,
correction. The issues surrounding the use of modelling in the commercial de-
velopment process are the subject of Chapter 13.

Summary
• Software developers have a difficult task, because of the complexity

of the systems they build and the characteristics of the material out of
which they are built. Nevertheless, some useful lessons can be learned
from other engineering disciplines. One of these is the value of models
of systems in the early stages of development.

• If used in the early stages of software development, models can ease
communication between developers and between developers and clients.
They can help identify deficiencies in understanding and in require-
ments and thus help to reduce rework costs in later development stages.

• To be useful, a model should be abstract (so that it is not too complex)
and rigorously defined, so that objective and repeatable analyses can be
performed.

• Formulating an abstract model using a notation with a fixed syntax
and semantics enables machine support and provides a communication
medium without ambiguity. Such a formal definition of a notation also
provides a means of resolving disputes about the meaning of a model.

• VDM-SL is an ISO-standard modelling language which has a formal
definition. It is part of a collection of techniques for analysing models
and developing software from them. In this book we will concentrate
only on the system modelling and analysis aspects.

• A model in VDM-SL contains definitions of the data and functionality
of a system.

• The data is represented through types which are built from simple basic
types such as characters and numbers. Values of these basic types can
be grouped into elements of more elaborate types such as records, sets,
sequences and mappings. Types may be restricted by invariants. Ab-
straction is obtained, where required, by allowing data values of arbi-
trary size and precision. A modelling language such as VDM-SL allows
the modeller the freedom to choose a level of abstraction appropriate to
the analysis in hand. In contrast, a model in a traditional programming
language may have to contain machine-specific details not relevant to
the model or analysis.



1.6 Analysing a model 11

• Functionality in a VDM-SL model is defined through function defini-
tions. For each function, the types of the inputs and result are given.
The input values to which a function may be applied can be restricted
by means of a pre-condition. Abstraction is obtained because the func-
tion definitions only state the result of application, without giving details
of any particular algorithms to be used. An implicit function definition
only characterises the result, without explicitly stating what result value
is to be returned.





2
Constructing a Model

Aims
In this chapter we aim to provide an overview of the main components

of a VDM-SL model, and some insight into the process by which models are
constructed. This is done by developing a model of a small alarm system from
scratch.

2.1 Introduction
This chapter tells the story of how a simple formal model is developed

from informally expressed requirements. The model under consideration, the
call-out mechanism for a chemical plant alarm system, illustrates most of the
features of VDM-SL covered in this book. Although this is a great deal of ma-
terial for a single chapter, there is no need to be able to understand all the details
of the language as these will be covered at a slower pace in later chapters. The
intention is to introduce, albeit superficially, the concepts that will be covered
in depth later, and to provide some initial guidance on how to start developing
formal models using VDM-SL.

Constructing a model is never as straightforward as it appears in
the textbooks! We would not want to give the impression that
a model is reached by a sequence of steps which run smoothly
from start to finish: developers of models often run up against
problems and have to scrap previous attempts. Experience can
be the best guide here: where our work on building formal mod-
els has anything to offer the reader, we present it in distinguished
text like this.

2.2 Requirements for an alarm system
This section contains the requirements for a simple alarm system for a

chemical plant. The example was inspired by a subcomponent of a large alarm

13



14 2 Constructing a Model

system developed by IFAD, a Danish high-technology company, for the local
telephone company, Tele Danmark Process.

A chemical plant is equipped with a number of sensors which are able to raise

alarms in response to conditions in the plant. When an alarm is raised, an expert

must be called to the scene. Experts have different qualifications for coping with

different kinds of alarm. The individual requirements are labelled for reference.

R1 A computer-based system is to be developed to manage the alarms of this

plant.

R2 Four kinds of qualification are needed to cope with the alarms. These are

electrical, mechanical, biological and chemical.

R3 There must be experts on duty during all periods which have been allocated

in the system.

R4 Each expert can have a list of qualifications.

R5 Each alarm reported to the system has a qualification associated with it along

with a description of the alarm which can be understood by the expert.

R6 Whenever an alarm is received by the system an expert with the right

qualification should be found so that he or she can be paged.

R7 The experts should be able to use the system database to check when they will

be on duty.

R8 It must be possible to assess the number of experts on duty.

2.3 Constructing a model from scratch
There is no right or wrong way to compose a model from a require-

ments description. However, faced with a collection of requirements, it is useful
to have a rough procedure to follow which at least helps in getting a first at-
tempt down on paper. This section presents such a procedure. However, before
beginning the process of developing a model, it is vital to consider the model’s
purpose. A model is normally developed so that some analysis can be performed
on it. For example, in the development of a single system, a model might be con-
structed in order to help determine the resource requirements for the system; to
clarify the rules under which the system must operate; or to assess security or
safety. The purpose for which a model is constructed determines the model’s ab-
straction: which details will be represented and which will be ignored because
they are not relevant to the analysis. When we introduce the examples in each
core chapter of this book, we will try to make the purpose of the model clear. In
this chapter, the purpose of the model is to clarify the rules governing the duty
roster and calling out of experts to deal with alarms.



2.4 Reading the requirements 15

After establishing the purpose of the model, the following list of steps can be
a helpful guide to its construction:

1. Read the requirements.
2. Extract a list of possible data types (often from nouns) and functions

(often from actions).
3. Sketch out representations for the types.
4. Sketch out signatures for the functions.
5. Complete the type definitions by determining any invariant properties

from the requirements and formalise these.
6. Complete the function definitions, modifying the type definitions if nec-

essary.
7. Review the requirements, noting how each clause has been treated in

the model.

This procedure will be followed in our analysis of the chemical plant alarm
system. If any discrepancies are discovered during this process they will be
noted down when they are discovered.

2.4 Reading the requirements
In constructing a model of a computing system it is necessary to find

representations for the data and computations involved. While reading the re-
quirements, it is worth noting the nouns and actions which typically may corre-
spond to types and functions in the model.

Statements of requirements, like the example above, can contain undesirable
features such as noise, silence, ambiguity, wishful thinking and misstated inten-
tion. Look out for these when developing the formal model: when imprecision
is encountered, it is necessary to resolve the issue and record the resolution in
order to keep track of all the decisions made during the analysis.

Examining each of the requirements listed above yields possible types and
functions:

R1 This concerns the entire system and suggests that a type could be introduced
to represent the various alarms which can arise. Call this type Alarm. The
requirement also suggests that a type could be introduced to represent the
overall condition of the plant. This type will be called Plant.

R2 This requirement mentions a collection of kinds of qualification, so a type
Qualification is suggested. Alarms are also mentioned again.



16 2 Constructing a Model

R3 This requirement mentions experts and periods of duty, suggesting types
Period and Expert.

R4 Here Qualification and Expert are mentioned again.
R5 Descriptions appear to be associated with alarms, so this suggests a type

called Description. The types Alarm, Qualification and Expert
are mentioned again.

R6 This requirement refers to the action of finding an expert with the right qual-
ification to handle an alarm. This suggests that a function is required to find
an expert to page. Let this function be called ExpertToPage. The types
Alarm, Expert and Qualification are all mentioned again.

R7 This requirement refers to the action of checking when experts are on duty,
suggesting that a function is needed to perform this check. Call the function
ExpertIsOnDuty. In addition, the type Expert is mentioned again.

R8 A function to return the NumberOfExperts on duty is suggested, and the
type Expert is mentioned again.

2.5 Extracting possible types and functions
The systematic read through of the requirements above suggests the fol-

lowing list of possible types and functions:

Types Functions
Plant ExpertToPage

Qualification ExpertIsOnDuty
Alarm NumberOfExperts
Period
Expert

Description

It would be reasonable to expect that functions would be needed to add and
remove alarms and experts from the system, but these are not mentioned in the
simplified requirements presented here. For the rest of this chapter, the list of
types and functions above will suffice.

2.6 Sketching type representations
How would one go about writing the type definitions for the types iden-

tified above? Requirement R2 states the four kinds of qualifications needed in
this system. This suggests a type Qualification. Its definition has the
following form, where “???” stands for some representation for the type:



2.6 Sketching type representations 17

Qualification = ???

The qualifications are all mentioned by name and it is simply necessary to be
able to distinguish between them: the details of their representations (as strings
of characters, numbers etc.) are not significant factors at this stage of develop-
ment. It is therefore possible to abstract away from the particular representation
of these four values (as strings, numbers etc.), but we would like to provide a
name for each of them. In VDM-SL this is done by means of an enumerated
type, similar to the enumerated types found in programming languages. In this
case the type Qualification could be defined as follows:

Qualification = <Elec> | <Mech> | <Bio> | <Chem>

This defines a type consisting of four values corresponding to the four kinds of
qualification required in this system: <Elec>, <Mech>, <Bio> or <Chem>.
The “<” and “>” brackets are used to indicate a special type (called a quote
type) containing just the named value. For example, the type <Elec> contains
just the single value <Elec>. The “|” symbol forms a union type from the
quote types and thus constructs the new type with just four values in it. Union
and quote types are described in more detail when the basic type constructors of
VDM-SL are introduced (Section 5.3.1).

In Requirement R2, Alarm was identified as a potential type. Requirement
R5 states that an alarm “has a qualification associated with it”. In this case,
we will assume that exactly one qualification is associated with each alarm and
record this assumption in the model. However, the phrase could be understood
to mean that each alarm has at least one qualification associated with it. This is
an example where the textual description might be interpreted in different ways
by different readers. An advantage of building a model at this stage is that the
assumption is explicitly recorded and, if necessary, can be corrected when the
model is analysed and reviewed. In this case we will assume that an alarm has
exactly one qualification and one description.

Requirement R5 emphasises that the description should be made so that it
can be understood by the experts. This could indicate that the description is a
piece of text (a sequence of characters) which is to be sent to the pager of the
selected expert. Note that there is no guarantee that the sequence of characters
present here actually can be understood by an expert. Thus, at a later stage of
development it would be necessary to review the “alarm text” to check that they
are actually clear. The notion of clarity is subjective and beyond the scope of a
model in VDM-SL.



18 2 Constructing a Model

In VDM-SL, a record type, similar to the record or struct in a programming
language, is used to model values made up of several components. The defini-
tion of an alarm is

Alarm :: alarmtext : seq of char
quali : Qualification

This states that an alarm is composed of two fields called alarmtext and
quali. The type char used in the definition is a basic type in VDM-SL that
represents characters. The keywords seq of produce a sequence type so that
the alarmtext is represented by a sequence of characters.

Suppose a value a belongs to the type Alarm. The components can be se-
lected from a using a dot notation. For example, the description of an alarm a
is written a.alarmtext. Thus if a is of type Alarm then a.alarmtext is
a sequence of characters representing the text for the alarm.

Having modelled alarms, we now consider the experts. Requirement R4 states
that an expert can have a list of qualifications. Whenever we encounter a re-
quirement stating that a list should be used, we must ask ourselves how the
elements of the list should be ordered. In this example, the order cannot be de-
duced from the requirements, so we must note this as a point to be resolved and
record in the model any assumption made. In this case we assume that the order
is not significant and use an unordered collection of qualifications in the form of
a set.

In order to distinguish two experts from each other, some kind of unique
identification of experts is needed. Thus the type of an Expert can be modelled
using another record type:

Expert :: expertid : ExpertId
quali : set of Qualification

The representation of ExpertId is important in the final implementation, but
in this model none of the functions need be concerned with its final represen-
tation. All that is required at this level of abstraction is for the identifiers to be
values that can be compared for equality. In VDM-SL, the special type repre-
sentation called token is used to indicate that we are not concerned with the
detailed representation of values, and that we only require a type which con-
sists of some collection of values. This is usually the case when the functions
in the model do not need to read or modify the information stored in an ele-
ment of the type. For example, if we were to include a function which modifies
ExpertIds, then we would need to model the identifiers in detail in order to
be able to describe the modification. No such function is required in this model,



2.6 Sketching type representations 19

so the representation of expert identifiers is immaterial and the completed type
definition in VDM-SL is

ExpertId = token

Notice that no kind of unique identification of experts was mentioned explicitly
in the requirements although requirement R6 indicated the need for it. This is an
example where an extra clause like All experts must be uniquely identified could
be added to the requirements.

Now let us turn to the modelling of Period mentioned in R3. It is not
important whether the periods are represented as character strings or reference
numbers with some fixed syntax, and we cannot deduce from the requirements
whether a period is composed of entire working days, hours or some other time
period. In the final implementation this needs to be clarified. However, none of
the functions we develop in the model here require access to the representation
of Period, so this is not a core part of the model. It is enough to know that
a period has some identifier and that it is possible to compare periods to see
whether they are the same or not. Abstracting from this detail, the token type
can be used once again:

Period = token

Requirement R3 suggests that there must be a schedule relating periods to the
experts who are on duty in each period. We therefore identify Schedule as
a possible type. Note that we did not manage to identify Schedule as part
of the initial “nouns and actions” analysis of the requirements. The “nouns and
actions” approach is certainly not foolproof – it may fail to come up with types
which are only implied by the text. Moreover, some types corresponding to
nouns may not be needed.

For each allocated period, the schedule must record the collection of experts
on duty during that period. The schedule can therefore be thought of as a map-
ping from periods to collections of experts. Given a period, we can look up
the collection of experts in the mapping. Should the collections of experts be
sets or sequences? We resolve this by assuming that experts are not recorded
in any particular order, enabling us to use sets. If the requirements did suggest
that there was a significant ordering among the experts, such as the distance that
they live away from the chemical plant, we could use sequences.

A schedule is therefore represented as a mapping from periods to sets of ex-
perts. An example of such a schedule is shown schematically in Figure 2.1. The
corresponding type definition in VDM-SL is as follows:

Schedule = map Period to set of Expert



20 2 Constructing a Model

Figure 2.1 A possible schedule.

The map to notation represents mappings from the first type (here the
type Period) to the second type (here set of Expert). Consider a sched-
ule sch. The collection of periods in sch is called the domain of sch: in
Figure 2.1 the domain has four elements. The sets of experts in the mapping
are collectively called the range of sch: the range of the schedule in Figure 2.1
has three elements. If a period is in the domain, then it is part of the “allocated”
schedule and points across the mapping to a set of experts on duty in this period.
If a period peri is in the domain of sch, we write sch(peri) to represent
the range element (the set of experts) in sch to which peri points. If a period
peri has not yet been planned and assigned a collection of experts, it is not in
the domain of the mapping sch and so sch(peri) is not defined.

Finally, consider Requirement R1. This combines the type definitions we have
made into a top-level type definition modelling the entire Plant. This must be
a record with the schedule for experts that are on duty and a collection of alarms
which can be activated. We use a record type definition again:

Plant :: schedule : Schedule
alarms : set of Alarm



2.6 Sketching type representations 21

The model so far

At this point, representations have been proposed for the main types
which arose from a reading of the requirements. A substantial part of the VDM-
SL notation has been introduced, so it is worth taking stock. Each type has been
given a representation in terms of other types. Some of the representations have
been basic types which are already part of the VDM-SL language, e.g. token
and char. Others have been constructed from basic types and values, such as
the union type construction for Light. More sophisticated record structures
can be built up from components, each of which has its own type. Collections
of values can be built up as sets (where the ordering of the elements is insignifi-
cant), sequences (where the ordering is significant) and mappings (which repre-
sent relationships from values of one type to values of another).

The type definitions for the chemical plant alarm system developed so far are
shown below. At this point it is worth making a remark about how models are
presented. Models written in a special notation such as VDM-SL should never
be presented without comment to support the reader. Throughout this book, we
intersperse the VDM-SL text with natural language explanations typeset sep-
arately. VDMTools Lite supports several different ways of providing models
with comments. In the simplest form, the explanatory text and VDM-SL are
both in a plain VDM file. The explanatory text can be presented in comments
using the syntax shown below. Note that definitions are separated by semicolons
and that comments are put on lines beginning with “--”, in common with many
programming languages.

-- Expert call-out system.
-- VDM-SL model Version 3.5
-- Date: 21 August 2008
-- Engineer: PGL

-- Overall plant contains a schedule relating each period
-- to the set of experts on duty in the period; the alarms
-- component records the alarms which can possibly arise.

Plant :: schedule : Schedule
alarms : set of Alarm;

Schedule = map Period to set of Expert;

Period = token;

-- Experts represented by unique identifier and a
-- set of qualifications.



22 2 Constructing a Model

Expert :: expertid : ExpertId
quali : set of Qualification;

ExpertId = token;

Qualification = <Elec> | <Mech> | <Bio> | <Chem>;

Alarm :: alarmtext : seq of char
quali : Qualification

The data types are presented in a top-down order with the Plant type first. It is
quite common to do this because data type definitions are often more readable
this way. However, in VDM-SL, the names of types do not have to be defined
in any particular order, as long as they are all defined somewhere in the model.
The particular order of presentation is therefore left to the author of the model.

2.7 Sketching function signatures
Now it is possible to consider the functionality provided by the system,

beginning with the function signatures. Recall the functions identified from the
requirements (Section 2.4):

ExpertToPage
ExpertIsOnDuty
NumberOfExperts

A function takes a number of input parameters and returns a result. The signa-
ture of a function gives the name of the function, the types of its input parameters
and the type of the result.

First consider the ExpertToPage function. From Requirement R6, it ap-
pears that this function must take an alarm as input. In order to find the ap-
propriate expert it also needs an identification of the period and requires access
to the overall plant structure in order to read the schedule. The signature of
ExpertToPage lists the types of the inputs and result as follows:

ExpertToPage: Alarm * Period * Plant -> Expert

where * is used to separate the types of inputs from one another and -> is used
to separate the types of the inputs from the type of the result.

Requirement R7 suggests that the function ExpertIsOnDuty must take an
expert and a plant as inputs. The function must check when the expert is on duty
according to the schedule of the plant. The assumption is made here that the
order in which the periods are presented is not relevant to the model’s purpose,



2.8 Completing the type definitions 23

and so the result is a set of periods rather than a sequence. An assumption
such as this one is naturally something that must be appropriately recorded and
subsequently checked with the customer in order to find out whether a particular
ordering is desired. The signature of ExpertIsOnDuty is as follows:

ExpertIsOnDuty: Expert * Plant -> set of Period

Finally, Requirement R8 identifies a function NumberOfExperts. This
function must certainly take the plant as input. However, the requirement is not
very precise about whether this is for a specific period. We assume that this is
the case but we would need to record this imprecision and our assumption that
we are dealing with a specific period here. Thus, the signature is

NumberOfExperts: Period * Plant -> nat

The result type nat is a basic type in VDM-SL. It represents the natural num-
bers 0, 1, 2, 3, . . .

2.8 Completing the type definitions
At this stage, when all the type definitions and function signatures have

been sketched out, it is worth considering whether there are any constraints that
must hold in the model at all times. Such constraints are called invariants. Each
invariant is recorded immediately after the definition of the type to which it
refers. Indeed, the invariant forms part of the type’s definition so, for a value to
belong to the type, it must respect the invariant.

To state an invariant formally, we express the property which all values must
satisfy as a Boolean expression on a typical element of the type. As an example,
consider Requirement R4; arguably it should be strengthened. Experts with no
qualifications are not of much use in this plant. If the expert is called ex this
can be expressed by a Boolean expression as follows:

ex.quali <> {}

This expression can be used to introduce an invariant for the type Expert as
follows:

Expert :: expertid : ExpertId
quali : set of Qualification

inv ex == ex.quali <> {}

where inv is a keyword indicating the invariant definition and ex is a pattern
matching the structure of the type definition and finally the ==means “is defined
as”.



24 2 Constructing a Model

Requirement R3 indicates that there must be at least one expert on duty in all
periods for which the system has assigned a group of experts. This is a constraint
on schedules, so it should be defined as part of the Schedule type definition.
Consider a typical schedule (called sch, say). This is a mapping from periods
to sets of experts. The constraint is that all the sets of experts in the range of the
mapping are non-empty. Put formally:

forall exs in set rng sch & exs <> {}

The Boolean expression used here is called a quantified expression. It states that,
for all sets of experts in the range of the mapping, the set must be non-empty.
Quantified expressions are often used to express properties which should hold
for collections of values. This language of logical expressions will be introduced
in Chapter 4.

However, this constraint is not sufficient because we would also like to ensure
that the expert identifiers are unique in each set of experts in order that one could
not erroneously have two experts with different qualifications having the same
expert identification. Put formally:

forall ex1, ex2 in set exs & ex1 <> ex2 =>
ex1.expertid <> ex2.expertid

Again a quantified expression is used, but this time two experts called ex1 and
ex2 are selected from the set exs. In case they are different experts their iden-
tifications must also be different. The => symbol is used for implication and
this will also be introduced in Chapter 4.

Including both of these constraints into the invariant for Schedule gives us

Schedule = map Period to set of Expert
inv sch ==

forall exs in set rng sch &
exs <> {} and
forall ex1, ex2 in set exs &

ex1 <> ex2 => ex1.expertid <> ex2.expertid

The invariant is formulated as a logical expression that limits the elements be-
longing to the type being defined (in this case Schedule) to those satisfying
both the type description and the invariant.

2.9 Completing the function definitions
It has already been seen that the data descriptions in a formal model

need not contain all the intricate detail found in a program’s data structures.
We have simplified the model by abstracting away from a number of aspects



2.9 Completing the function definitions 25

which are not important for the functionality we want to describe. Indeed, a
good general principle is that a model should contain no more detail than is
relevant to its analysis. A similar principle applies to the definition of functions,
so VDM-SL provides facilities to give a function definition explicitly, stating
how a result can be calculated from the inputs. However, the language also
provides for implicit function definition, where the result is characterised, but
no specific “recipe” for calculating the result is used. This section illustrates
first the explicit style and later the implicit.

Let us first consider the NumberOfExperts function. Requirement R8
said “It must be possible to assess the number of experts that are on duty”. In
sketching the function signatures we decided that it would be natural to take a
Period as an input to this function. The signature is therefore as follows:

NumberOfExperts: Period * Plant -> nat

The function is defined by giving its result in terms of its inputs. Thus, we
need to look up the set of experts on duty for the given period in the schedule
and return the size of the set. This can be defined as follows:

NumberOfExperts: Period * Plant -> nat
NumberOfExperts(peri,plant) ==
card plant.schedule(peri)

The card notation indicates the cardinality (or size) of a set. It is applied to
the set of experts obtained by looking up the input period peri in the sched-
ule component of the plant record (plant.schedule). The operators and
expressions used here will be introduced in greater depth in later chapters.

Calling the function NumberOfExperts is only meaningful if the period
peri is actually described in the plant’s schedule. We record this assumption
by means of a pre-condition, a logical expression over the input parameters say-
ing that the function may be applied when it is true. The pre-condition can be
formulated as

NumberOfExperts: Period * Plant -> nat
NumberOfExperts(peri,plant) ==
card plant.schedule(peri)

pre peri in set dom plant.schedule

The pre-condition says that the input period peri must be in the set of periods
which forms the domain of the schedule mapping. We do not guarantee anything
about what happens if a function is applied to inputs which do not meet the pre-
condition. In a model at a later stage of design, we may wish to provide an error
message in the situation where the pre-condition is violated and this can be done
quite easily. However, at this early stage of analysis, we prefer to abstract away



26 2 Constructing a Model

from this and record the restriction that the function must not be applied in this
way.

Now consider the ExpertIsOnDuty function required by R7. In the case
of ExpertIsOnDuty, the function returns a set of all the periods where the
expert is on duty. Thus, in this case we need to select all the periods in the
schedule which have the expert ex as one of the experts on duty in that
particular period. The full function definition for ExpertIsOnDuty is as fol-
lows:

ExpertIsOnDuty: Expert * Plant -> set of Period
ExpertIsOnDuty(ex,plant) ==

{peri| peri in set dom plant.schedule &
ex in set plant.schedule(peri)}

The body of this function is expressed using a set comprehension expression
which collects all periods peri (from the domain of the schedule) for which
the expert ex is registered. Set comprehension is explained in Chapter 6.

Notice that the definition of the function ExpertIsOnDuty selects the
schedule component from the plant value twice. It may be worth using
a more general pattern in the parameter list to avoid this:

ExpertIsOnDuty: Expert * Plant -> set of Period
ExpertIsOnDuty(ex,mk_Plant(sch,-)) ==

{peri| peri in set dom sch & ex in set sch(peri)}

At the moment patterns should simply be viewed as a way to provide names
to the components of the Plant rather than having to use the dot notation for
selecting the schedule component all the time. The alarms component is
not needed in the function definition, and so is represented by a “-” symbol. We
will return to more explanation about patterns in Chapter 5.

From a system point of view, it should also be ensured that the experts have
the computing or telephone equipment they need to allow them to check whether
they are on duty. However, this model abstracts away from the communication
mechanism and interface.

Finally, consider the ExpertToPage function. Requirement R6, which
gives rise to the function, states “Whenever an alarm is received by the sys-
tem an expert with the right qualification should be found so that he or she can
be paged”. Note that the requirement does not mandate any method for deter-
mining which expert has to be found: any expert will do as long as he or she has
the correct qualification: there is some looseness in the requirement.



2.9 Completing the function definitions 27

A common reaction to looseness is to assume that the require-
ments are incomplete. While this may sometimes be the case,
careful consultation with a customer often reveals that resolving
the looseness would involve adding detail that is not relevant to
the model’s purpose and may constrain developers too early in
the development process by pre-empting design decisions that
should be taken later in the development process. In such cases,
the looseness should be left in the model. Modelling languages
such as VDM-SL provide specific facilities for retaining loose-
ness in models.
For many software developers, retaining looseness in a model
goes against the grain because it means that the model is not di-
rectly executable in the same way that programs are executable.
However, models are not the same things as programs, being
designed for analysis rather than execution. Successful applica-
tions of formal modelling actually seek to increase the looseness
in areas of the model that should not be “pinned down”.

In the alarm example, the designer of the system is free to choose a mecha-
nism for deciding which expert to call. This suggests that an implicit definition
may be appropriate. Recall that an implicit function definition characterises the
result without giving a particular mechanism for calculating it.

It is possible to model a function by stating what properties are required of
the result it returns, without indicating how the result is to be calculated. This
is done by means of an implicit function definition. The main advantage of
using implicit function definitions is the ability to state the required properties
of a result without biasing a subsequent developer towards any particular way
of producing the result from the input parameters. An implicit definition of
ExpertToPage is as follows:

ExpertToPage(a:Alarm,peri:Period,plant:Plant) r: Expert
pre peri in set dom plant.schedule and

a in set plant.alarms
post r in set plant.schedule(peri) and

a.quali in set r.quali

Notice that no separate signature is given, but that the names and types of the
inputs and results are given together in a header. A pre-condition describes
a condition under which the function should be applied and a post-condition
describes the result without giving a particular algorithm for calculating it. The
pre-condition is similar to that of the ExpertIsOnDuty function except that



28 2 Constructing a Model

we also require the alarm a to be known for the plant. The post-condition states
that the expert to be paged, r, must belong to the collection of experts on duty
in this period, and one of his or her qualifications should be the one required to
deal with the given alarm. If more than one such expert is available the post-
condition above does not state who should be chosen. A definition that does not
narrow the result down to a single possible outcome is said to be loose. We will
return to the subject of looseness in Chapter 6.

By this stage one problem with the model may have become apparent. The
requirements have been silent about the question “How can we be sure that
an expert with the required qualification exists in the required period?”. The
ExpertToPage function cannot yield a satisfactory result if no expert is avail-
able. The situation can be resolved in one of two ways. Either the pre-condition
can be made more restrictive (requiring that a suitable expert should be available
before an attempt is made to find one), or an invariant can be imposed on the
type Plant to require that, at all times, there is at least one expert for each kind
of qualification. This choice, between representing constraints as pre-conditions
and recording them as invariants, is commonly faced by modellers. As a general
rule, it is best to model this kind of constraint as an invariant if the property
should hold at all times. If the restriction is only required to hold when a func-
tion is applied, then a pre-condition is more appropriate. In this example, we
will assume that for each qualification at least one expert has to be available
at any time. Thus, we should modify the invariant. The modified Plant type
definition would be

Plant :: schedule : Schedule
alarms : set of Alarm

inv mk_Plant(schedule,alarms) ==
forall a in set alarms &

forall peri in set dom schedule &
QualificationOK(schedule(peri),a.quali)

and the function QualificationOK is defined explicitly as

QualificationOK: set of Expert * Qualification -> bool
QualificationOK(exs,reqquali) ==

exists ex in set exs & reqquali in set ex.quali

The body of this function is a Boolean expression which is true if an expert
with the required qualification (reqquali) exists in the given set of experts
exs. Note that the function QualificationOK has been written purely for
notational convenience: it makes the invariant easier to read. Unlike the other
functions defined so far, it is not required to be implemented in the system un-
der development. Such functions, defined for convenience rather than imple-



2.10 Reviewing requirements 29

mentation, are called auxiliary functions. The use of auxiliary functions is to be
encouraged, since they improve the ease with which a model can be read and
analysed.

There is an obligation (called a proof obligation) on the writer of function
definitions to check that each function will be able to produce a result whenever
its pre-condition is satisfied. Note that without the addition of the invariant to
the Plant type we would not have been able to meet this obligation for the
ExpertToPage function. The role of such obligations will be examined more
closely when we look at validation and consistency checking in Chapter 10.

2.10 Reviewing requirements

Having completed the formal model we look through the requirements
one last time to review how each clause has been considered:

R1 A computer-based system managing the alarms of this plant is to be de-
veloped. Considered in the overall Plant type definition and the function
definitions.

R2 Four kinds of qualifications are needed to cope with the alarms. These are
electrical, mechanical, biological and chemical. That is considered in the
Qualification type definition.

R3 There must be experts on duty during all periods which have been allocated
in the system. Invariant on the type Schedule.

R4 Each expert can have a list of qualifications. Assumption: non-empty un-
ordered set instead of an ordered list in Expert.

R5 Each alarm reported to the system has a qualification associated with it and a
description which can be understood by the expert. Considered in the Alarm
type definition assuming that it is precisely one qualification.

R6 Whenever an alarm is received by the system an expert with the right qualifi-
cation should be found so that he or she can be paged. The ExpertToPage
function with additional invariant on the Plant type definition.

R7 The experts should be able to use the system to check when they will be on
duty. The ExpertIsOnDuty function. Assumption that the ordering of the
periods during which the experts will be on duty is not important.

R8 It must be possible to assess the number of experts on duty. This is the
NumberOfExperts function with assumption for a given period.



30 2 Constructing a Model

Weaknesses in the requirements document
The development of the formal model has helped to identify some weak-

nesses in the original requirements document. We made assumptions to resolve
these, so it is important to record them. Below we list the deficiencies spotted:

• No explicit mention of unique identification of experts.
• Experts without qualifications are useless, and may not be considered

“experts” at all.
• How can we be sure that an expert with the required qualification is on

duty in the required period?
• Should the number of experts be relative to a period?
• Does “a qualification” mean “exactly one” or “at least one”?

Summary
In this chapter we have used a systematic approach to analyse the re-

quirements for an alarm system. In practice, there is no right or wrong way to
compose a model from a requirements description, but the following list of steps
can be a helpful guide for the novice:

1. Read the requirements.
2. Extract a list of possible data types (often from nouns) and functions

(often from actions).
3. Sketch out representations for the types.
4. Sketch out signatures for the functions.
5. Complete the type definitions by determining any invariant properties

from the requirements and formalise these.
6. Complete the function definitions, modifying the type definitions if nec-

essary.
7. Review the requirements, noting how each clause has been considered.

The presentation given here is a simplification of what would happen in the
development of an industrial system. Depending upon the context, involvement
from customers and/or local domain experts could be necessary to resolve the
unclear points discovered and the assumptions made during the construction of a
formal model. It is important to note, however, that the construction of a model
allows us to expose and record these assumptions at an early stage in system
development.

The approach to developing a model which has been presented in this chapter
underlies the models developed subsequently. However, when we are presenting



2.10 Reviewing requirements 31

an example for the purpose of introducing some types or operators, we will not
explicitly describe the individual steps in the process.

We have gone through the process of constructing a formal model. The lan-
guage, no doubt, still seems unfamiliar. However, most of the features of the
modelling language have been introduced: the main part of this book aims to
help the reader develop confidence using the logic employed for writing invari-
ants, pre-conditions and post-conditions, and familiarity with the operators on
the data types (sets, mappings, sequences and records, mostly). The subsequent
chapters take a much more detailed look at these, with plenty of examples. Ap-
pendix Appendix A provides an overview of all the constructs in the subset of
VDM-SL used in this book and serves as a quick reference on the usage of the
language’s constructs.

Exercise 2.1 This exercise is based on a (fictional) technical report written
by an engineer working on another part of the chemical plant alarm system and
describes a first attempt at a model for the system under development. Read the
report and then consider the questions which follow it. The object of this exer-
cise is simply to increase your familiarity with models expressed in VDM-SL.
Reading and considering the report are more important than getting “correct”
answers!

We have been asked to develop a detector for alerting the chemical plant’s experts

whenever there is a certain kind of failure in the sensors in any of the reactor

vessels. When a sensor fails, it does not reply promptly to a request for data.

The detector will broadcast requests for data to all the sensors in the plant at

certain times. A functioning sensor will reply to such a request within a time limit

(called maxtime). A malfunctioning sensor will not reply within the time limit.

If a malfunctioning sensor is discovered an alarm is to be raised. The qualification

needed to deal with these alarms is always electrical knowledge.

It was decided to develop a system model in VDM-SL in order to clarify the

rules for raising this alarm. Obviously, other kinds of failure are possible (sensors

sticking on a value, for example), but we were asked only to analyse the rules for

detecting this particular kind of failure, so the model abstracts away from other

factors which are not material to this analysis.

The system consists of a collection of sensors, each with its own identifier. In

addition, we keep a record of the times when requests are sent out and the

collection of replies obtained to each request. The system is modelled as the type

System shown below. The sensors are modelled as a set of sensor identifiers



32 2 Constructing a Model

while the requests and answers from the sensors are recorded as a mapping from

times (the times at which requests were issued) to sets of replies.

System :: sensors: set of SensorId
answers: map Time to set of SensorReply

Recall that the purpose of the model is to allow analysis of the alarm-raising

mechanism. The detailed representation of sensor identifiers is not a significant

aspect of this, and so the token type representation is used.

SensorId = token

Also, for the purposes of the model, time is represented by a natural number

denoting the number of elapsed time units since the combined sensors and alarm

system were started up.

Time = nat

The sensor replies contain information about the time of the request being

responded to, the sensor replying and the data it is carrying (a real number

representing reactor temperature):

SensorReply :: request: Time
sid : SensorId
data: Data

The data types for alarms and qualifications are taken from the current model of

the expert call-out system:

Alarm :: alarmtext : seq of char
quali : Qualification;

Qualification = <Elec> | <Mech> | <Bio> | <Chem>

We begin defining the functionality with a simple function which clears the

current record of requests and replies:

Clear: System -> System
Clear(sys) ==
mk_System(sys.sensors,{|->})

The function Request models the issuing of a new request. This adds the

request time to the domain of the answers mapping, pointing to an empty set of

replies:

Request: System * Time -> System
Request(mk_System(sens,ans),t) ==

mk_System(sens, ans munion {t |-> {}})
pre forall t1 in set dom ans & t1 < t

When sensor replies are received they must be registered in the system for the



2.10 Reviewing requirements 33

request made at the time given in the request field of the reply. Thus the

answers mapping must be updated with this information:

Reply: System * SensorReply -> System
Reply(mk_System(sens,ans),sr) ==
mk_System(sens,

ans ++ {sr.request |-> ans(sr.request)
union {sr}}

)
pre sr.request in set dom ans

An alarm is to be constructed if there is some request issued more than maxtime

time units ago to which not all of the sensors have yet replied. The function

RaiseAlarm is called with a system sys and the current time (now) as inputs.

It constructs an alarm, but should be called only if there are still some outstanding

responses to one of the requests. The precise definition of the alarm condition is

in the function CheckAlarm.

RaiseAlarm: System * Time -> Alarm
RaiseAlarm(sys,now) ==
mk_Alarm("Sensor Malfunction", <Elec>)

pre CheckAlarm(sys,now)

The function CheckAlarm returns a Boolean value which is true if there

exists some request in the answers component of the system which is more than

maxtime time units old and there is at least one sensor which has not returned a

reply. Its definition will be given in the next draft of this report.

The report presented above was reviewed by several other engineers. They
wrote the following comments and questions on the report. In each case, con-
sider whether you agree with the comment or try to answer the question. Re-
member that it is more important to think about the model and its level of ab-
straction than to get a “correct” answer.

1. Why do you represent the Data field in the SensorReply record? As
far as I can see, it never gets used.

2. Presumably you need to make sure that, when you issue a new request,
the time of the new request is later than all the other times in the system.
How does the model ensure this?

3. What do you need the function Clear for?
4. I heard that the team working on the expert call-out software had changed

their model of an alarm so that it includes a call-out time as well as a
message and a qualification. What parts of your model would be af-
fected by this?



34 2 Constructing a Model

The last comment raises a significant point. If several parts of a large system
are being developed simultaneously, it is helpful to have a mechanism for defin-
ing the interfaces between those subsystems, so that it is possible to check that
data types and functions provided by the model of one subsystem are used cor-
rectly in the models of other subsystems. The modular structuring mechanism
in VDM-SL (introduced in Chapter 12) allows for this kind of checking. It is
often the case in software developments that misunderstandings about the inter-
faces between subsystems are responsible for considerable reworking costs after
deficiencies are discovered when modules are tested together. �



3
VDMTools Lite

Aims
The aim of this chapter is to introduce VDMTools Lite, the development

environment for VDM-SL models. This is done by providing a “hands-on” tour
of the tool’s functionality using the alarm example introduced in Chapter 2.
This chapter should enable the reader to use VDMTools Lite for exercises in the
remaining part of this book.

3.1 Introduction
Models in VDM are formal in the sense that their semantics are very

precisely described. This formality makes it possible to analyse models in order
to confirm or refute claims about them. Such an analysis often reveals gaps in the
understanding of the system, allowing these to be resolved before an expensive
commitment is made to program code. The process of analysing claims about
systems modelled in this way is termed validation and is discussed in greater
depth in Chapter 10.

Software tools play an important role in supporting validation. This book is
accompanied by an educational version of the VDM-SL version of VDMTools,
called VDMTools Lite, that provides most of the functionality of the commercial
tool1.

This chapter introduces VDMTools Lite as a preparation for the examples and
exercises of later chapters. It takes the form of a tour through the facilities for
performing syntax checking, type checking, integrity checking, testing and de-
bugging of models, using the alarm example which was presented in Chapter 2.
The reader is encouraged to use the VDMTools Lite or the full VDM-SL version
of VDMTools for all the exercises in this and subsequent chapters.

VDMTools Lite exists for several operating system platforms including Win-
dows, Linux and MacOS. In the remainder of this book, we assume that the

1 Some features of the full version have been removed in the Lite version. These are
the CORBA-based Application Programmer Interface; the Dynamic Link facility in the
interpreter; and the automatic C++ code generation feature.

35



36 3 VDMTools Lite

reader is using the Windows platform; users of other platforms may notice mi-
nor deviations from the user interface screens shown.

3.2 Installing VDMTools Lite
At http://www.vdmtools.jp/en it is possible to register and

subsequently download a setup.exe application which can be executed. This
will automatically install VDMTools Lite onto the hard-disk. The user must
choose the desired working directory during the installation. Files containing
the VDM-SL source for the examples and exercises used in this book are avail-
able from http://www.vdmbook.com. Copy these source files to a local
examples directory.

3.3 Configuring the alarm example
In order to start VDMTools Lite, select it from the All programs entry in

the Windows start menu. The main VDMTools window as shown in Figure 3.1
will appear. The menu bar at the top of the main window allows the user to
invoke the actions available on models. The graphical buttons in the toolbars just
below the top menu bar provide ready access to the most frequently used actions.
Below the toolbars, the main part of the window contains sub-windows that
communicate information about the model being analysed. When VDMTools
is started up for the first time, a manager sub-window and a log sub-window
appear as shown in Figure 3.1.

In VDMTools, models are structured in units called projects, each of which is
composed of one or more files containing VDM-SL source text. These source
files can be edited by any external text editor tool chosen by the user. VDMTools
offers a number of actions that can be performed on the project files. Particular
actions, such as the execution of a model using the interpreter tool, use spe-
cialised sub-windows that appear when the action is invoked.

In the remainder of this chapter, we will introduce areas of the VDMTools
functionality. As each area is introduced, we will show a reference table indi-
cating the relevant toolbar buttons. However, hovering the mouse cursor over a
button on the screen will bring up a message indicating the intended usage of
that button.

At the top of the main VDMTools window are six pull-down menus (labelled
“Project”, “File”, “Windows”, “Actions”, “Interpreter” and “Help”). When the
Project menu is selected it is possible to load and save the current project or to
change its configuration. The buttons listed in Table 3.1 are simply shortcuts to



3.3 Configuring the alarm example 37

Figure 3.1 Startup window for VDMTools Lite

the items in the “Project” menu. However, the menu additionally contains an
entry for recently accessed projects that may be convenient on occasion.

Initially an empty project will be present, so we need to add selected files to
the project. Pressing the small icon with a “+” sign will cause a file browser
will appear. Since we are following the chemical plant alarm example, select
alarm.vdm. The file name alarm.vdm will appear in the Project part of the
Manager sub-window. VDMTools performs a syntax check on the file when
loading it, so now that the check is complete, it is possible to press the Module
tab in the Manager sub-window to see whether the loaded model is structured
into any special module units. The symbol DefaultMod is used to indicate that
the alarm example has been presented as a collection of definitions without any
use of modular structuring. Modules are primarily intended for structuring large
models with re-usable components and is reviewed in Chapter 12. Modular
structuring will not be used in the majority of examples in this book. This com-
pletes the project setup of VDMTools Lite to the alarm example file. It is now
possible to start analysing the definitions made in this model.



38 3 VDMTools Lite

Table 3.1 VDMTools project buttons

Button Explanation

Create a new project

Load an existing project

Save the current project

Save the current project under a new name

Add selected files to project

Remove selected files from project

Show and edit current project options

Select tool options

3.4 Syntax and type checking models
Returning to the Manager sub-window we will now consider the facil-

ities in VDMTools Lite that allow us to analyse the VDM-SL models in the
project that has just been created. Select alarm.vdm in the Project pane or
DefaultMod in the Module pane by clicking on it. Because syntax checking was
automatically carried out when the file was added to the project in the Modules
tab, a letter S shows that this file has been successfully syntax checked. This
means that the definitions presented in the alarm.vdm file follow the syntax
rules for VDM-SL.

After successful syntax checking it is possible to perform a type check on the
model, invoked through the Type Check button. If this button is pressed a T will
appear in the Module tab of the Manager sub-window. This indicates that the
model has been type checked without any errors (see Figure 3.2). This means
that, in addition to fulfilling the syntax rules of VDM-SL, the use of the different
operators etc. in the definitions has satisfied the scope and type rules provided
for VDM-SL. In our example, the file was both syntactically correct and type
correct right from the beginning. This is not surprising because this file has
been developed and analysed separately. However, most developers make errors
in early versions of models. It is therefore worth examining the facilities for



3.4 Syntax and type checking models 39

Figure 3.2 Having both syntax and type checked alarm.vdm

Figure 3.3 Syntax errors in the error tool

reporting and correcting errors in VDMTools Lite. To illustrate this, a file called
alarmerr.vdm, containing deliberate mistakes, has also been supplied.

In order to examine this file we need to configure VDMTools Lite again. In
order to get rid of the definitions from alarm.vdm, select the file name in the
Project tab of the Manager sub-window and press the icon with the small minus
sign. Then alarmerr.vdm can be added instead using the icon with the small
plus sign. When this is done the alarmerr.vdm file will be parsed directly.

Since this version contains errors the Error List sub-window will pop up with
four error messages as shown in Figure 3.3. We can traverse through the errors
using the > and < buttons. The Source sub-window in Figure 3.4 will in-
dicate the precise location of the error indicated in the Error List sub-window.
In each case the syntax checker indicates what kind of construct was expected
and provides a qualified guess at how the error can be corrected. The suggested
corrections are often, but not always, correct. Note that the Source sub-window
is not an editor – the file should be modified with your preferred external edi-



40 3 VDMTools Lite

Figure 3.4 Source sub-window with indication of error

tor. In Section 3.8 we will see how it is possible to set up VDMTools Lite to
automatically invoke a favourite editor when required.

Exercise 3.1 Correct all the errors that have been discovered by the syntax
checker on the alarmerr.vdm file and syntax check your corrected file again
until no syntax errors appear. �

When no more syntax errors are present the model can be type-checked. This
model contains some type errors, as is indicated by the slash through the T in the



3.4 Syntax and type checking models 41

Table 3.2 VDMTools action buttons

Button Explanation

Perform syntax check on selected classes

Perform type check on selected classes

Generate integrity properties for the selected classes

Generate C++ code for selected classes

Pretty print the selected classes

Table 3.3 VDMTools file buttons

Button Explanation

Open selected files in external editor

Close selected file from source sub-window

Close all files from source sub-window

Module tab of the Manager sub-window. In addition, the Error List sub-window
will appear again, this time containing type errors as shown in Figure 3.6. The
first one says: Error : Function is applied with wrong number of parameters.
This is because QualificationOK has been called with three parameters
instead of just two as indicated in its definition. The next error (Error : Un-
known identifier exss) is due to a typographical error which is easy to correct.
Altogether four errors and two warnings are reported. The type checker distin-
guishes between errors which are things that are definitely wrong and must be
corrected by the user, and warnings which are hints about things that could be
wrong.

Exercise 3.2 Correct all the errors that have been discovered by the type
checker on the alarmerr.vdm file and syntax and type check your corrected
file again until no syntax or type errors appear. �



42 3 VDMTools Lite

Figure 3.5 Tool options in VDMTools

3.5 Interpreting and debugging models

Syntax and type checking are static analyses, meaning that they are per-
formed without executing the model. VDMTools also supports dynamic anal-
ysis, allowing insight to be gained into the behaviour described by models by
testing them. We call this interpreting the models because they are not compiled
into a general-purpose assembly language as many programs are, but instead are
executed directly by an abstract machine (an interpreter). The VDMTools Lite
interpreter allows execution and debugging of models written in a subset of the
VDM-SL notation. To see this in action, take the third pull-down menu called
Windows and select the Interpreter item (or use the small debug icon button).
An overview of the window icons is provided in Table 3.4. When the interpreter
is selected, a sub-window like that shown in Figure 3.7 will appear.



3.5 Interpreting and debugging models 43

Figure 3.6 Type errors in the Error List sub-window

To access the definitions that have been read into the current project, first press
the button that Initialises the interpreter (see Table 3.5) with all the definitions
from the current VDM-SL model. Whenever updates have been made to the
VDM-SL model, syntax checking the newest version does not update the inter-
preter’s internal representation. Thus, whenever the model has been modified, it
is necessary to press this initialisation button again.

The internal representation in the interpreter includes type definitions, func-
tions, as well as any value (constant) definitions and global state variables present
(we discuss state definitions in Chapter 11). The alarm example only has type
definitions and function definitions. Now that the interpreter has been initialised,
these definitions are all available for testing.

The top two panes of the interpreter sub-window are, respectively, the Re-
sponse and Dialogue panes. Commands are entered directly in the interpreter
in the Dialogue pane and output from the interpreter appears in the Response
pane. Commands are typed in the Dialogue pane and are submitted to the inter-



44 3 VDMTools Lite

Table 3.4 VDMTools sub-window buttons

Button Explanation

Allow user to view text

Close selected file from source sub-window

Show project log

Open the VDM++ interpreter sub-window

List all errors that occurred

Show integrity properties

preter by hitting the return key on the keyboard. Typing functions will get
a list of explicit functions which have been read into VDMTools. For the alarm
example we provided three explicit function definitions and one implicit func-
tion definition. However, the list provided here contains nine function names.
The extra ones have special prefixes (inv , pre and post ). These functions
are automatically generated “for free” from the definitions containing invari-
ants, pre-conditions and post-conditions. We will describe them in more detail
in Chapter 5. Any of these functions returned using the functions command
can be executed if arguments are provided for them.

The file testalarm.vdm contains some value definitions for the alarm ex-
ample. The schedule used in these definitions reflects the schedule presented
in Figure 2.1 on page 20. All components from this figure have been given
a name as a value definition in testalarm.vdm and below we will refer
to these names. In order to get access to these definitions, the file contain-
ing them must be included in the project in the same way that alarm.vdm
and alarmerr.vdm were. In adding this file, do not remove the corrected
alarmerr.vdm file from the project setup. The new testalarm.vdm file
can be added using the small + icon button again (see Table 3.1). Then this file
can be syntax checked and type checked and we can reinitialise the interpreter
by pressing the Init button again (i.e. the flag icon in Table 3.5). In this way we
also get access to the value definitions provided by testalarm.vdm. In the
dialog part of the interpreter sub-window we can type values to see the list of
value definitions which are available.



3.5 Interpreting and debugging models 45

Figure 3.7 Start up sub-window for the VDM-SL Interpreter

          RESPONSE PANE

       DIALOG PANE

    CALL STACK PANE
  BREAKPOINTS PANE

As an example of the use of the VDMTools interpreter, type the print
NumberOfExperts(p1,plant) command in the Dialog part of the inter-
preter sub-window and press return. In this command, the name plant stands
for the mapping representing the plant as shown in Figure 2.1, and p1 corre-
sponds to the period “Monday day.” The interpreter responds by printing 3,
indicating that three experts are on duty in period p1.

Exercise 3.3 Use the interpreter to evaluate the following expressions:

NumberOfExperts(p2,plant)
NumberOfExperts(p3,plant)
ExpertIsOnDuty(e1,plant)
ExpertIsOnDuty(e2,plant)
ExpertIsOnDuty(e3,plant)

�

Sometimes it is not clear why a function is returning a particular result when
applied with some input values. In such cases it is valuable to be able to debug



46 3 VDMTools Lite

Table 3.5 VDMTools window buttons

Button Used Explanation

Yes Initialise the interpreter

Yes Perform a step

No Step inside

No Perform a single step

No Continue the execution

No Stop the interpreter

No Jump to where the current function or operation was called

No Jump to where the current subfunction was called

No Finish the execution

the model by setting up break points. A break point is a point in the model
at which we wish the execution to be interrupted during interpretation. Set
up a break point by typing break NumberOfExperts. The consequence
of this break point is that the name DefaultMod’NumberOfExperts ap-
pears in the Break Points part of the interpreter sub-window. Type debug
NumberOfExperts(p3,plant) in the Dialogue pane and press return. The
Source sub-window will pop up and show where the execution has been stopped,
as shown in Figure 3.82. Press Single Step a few times to see how the body of
the function is evaluated step by step. While debugging an expression, subex-
pressions can be evaluated by using the print command in the Dialog part of
the interpreter sub-window. When execution does not deliver the expected re-
sults, break points provide a useful aid to debugging models at the expression
level.

During debugging the stack trace of functions called is displayed in the Trace

2 The only difference between print and debug is that debug will stop when a break
point is reached whereas print will ignore break points.



3.5 Interpreting and debugging models 47

Figure 3.8 Debugging the VDM model

part of the interpreter sub-window (see Figure 3.7). The arguments to a function
are initially compressed into an ellipsis (three dots). An ellipsis can be unfolded
by clicking the left mouse button with the cursor on top of the dots; the value
can be folded back by pressing the left mouse button again. Press the Continue
button (the green arrow pointing forward) to end debugging. The interpreter will
continue either until the next break point is encountered or until the execution is
finished.

Notice that ExpertToPage did not appear in the list of functions returned
by the functions command. This is because it is an implicit function and
such functions cannot be executed directly3. However, it is possible to execute

3 The only other kind of construct that cannot be executed by the interpreter is a type
binding which we will illustrate in the next chapter.



48 3 VDMTools Lite

Figure 3.9 Test coverage information

pre-conditions and post-conditions of implicit functions. These functions return
Boolean values as described by the logical expressions inside the pre- and post-
conditions. We discuss them in more detail in Sections 5.8.3 and 6.4.3.

3.6 Test coverage
It is often useful to know how much of a model has been exercised

by a set of tests. This gives some insight into the thoroughness of a test suite
and may also help to identify parts of the model that have not been assessed,
allowing new tests to be devised to cover these. VDMTools has a facility to
support this kind code coverage, similar to the tools that already exist for many
programming languages. In VDMTools Lite, special commands can be used in
the Dialog part of the interpreter sub-window. There is a command called tcov
that can be used with arguments to reset the coverage information, to read and
write the coverage information to a file. The rtinfo command takes such a
coverage file for the VDM model in question and presents information about
the percentage of coverage for each function, as well as data on the number of



3.7 Integrity checking 49

times each function is called. Figure 3.9 illustrates how this can be done with the
alarm example. Even more detailed information at subexpression level can be
shown if the VDM model is pretty-printed but this requires special commands
depending upon the format used for the VDM model. In order to see how this is
done, refer to the user manual for VDMTools [UserMan].

3.7 Integrity checking
Another way to increase confidence in the internal consistency of a

VDM-SL model is to use the integrity examiner from VDMTools. This extends
the static checking capabilities of the VDMTools by scanning through VDM-SL
models for potential sources of internal inconsistencies or integrity violations.
The checks include the violation of data type invariants, pre-conditions, post-
conditions, sequence bounds and map domains. Each integrity property is pre-
sented as a VDM-SL expression that should evaluate to true – if it evaluates to
false instead, this indicates that there is a potential problem with the correspond-
ing part of the VDM-SL model. The only fully general technique for ensuring
that integrity properties are satisfied is formal proof. Proof is beyond the scope
of this book, but the underlying principles are explained in Chapter 10.

Pressing the integrity checking button (see Table 3.2) when the alarm.vdm
file is selected will bring up an Integrity properties sub-window (see Figure 3.10).

The Integrity properties sub-window is divided into three areas. The area at
the top lists the integrity properties currently in view in the Source sub-window.
Initially this will show all the integrity properties for the modules that have been
checked (here we only have a default module). To the left of the list are four
buttons. The first two are for scrolling through the list. The third marks the
currently highlighted property as having been checked manually. The fourth
button activates a filter that can be used to limit the view to certain kinds of
integrity property. The second pane of the integrity properties sub-window is
used to define the filtering criteria. The bottom pane of the integrity properties
sub-window shows the currently selected property. This property should hold at
the given position in the source sub-window.

Integrity checking can be valuable in the late stages of a model’s development.
Checking each property can help to identify potential run-time errors. The use
of this feature will be taken up again in Chapter 10.

Figure 3.10 shows one of the integrity properties generated for the alarm ex-
ample. The specific property is generated by the mapping application to be
found in the body of the ExpertToPage function. Mapping applications can



50 3 VDMTools Lite

be undefined if the value being applied to the mapping is not in the domain of
the mapping itself (this is equivalent to a run-time error). The integrity property
states that, in the context where it occurs in the body of the ExpertToPage
function, the period must be in the domain of the schedule mapping. This
requirement is stated as a logical expression:

forall a : Alarm, peri : Period, plant : Plant &
peri in set dom (plant.schedule) and
a in set plant.alarms =>

(forall r : Expert &
peri in set dom (plant.schedule))

This requires that, for all combinations of alarms, periods and plants, the period
must be in the domain of the plant’s schedule. This property is already guaran-
teed by the pre-condition, so the integrity property is trivially satisfied. If we
had omitted the requirement from the pre-condition, we would have discovered
the mistake by examining the integrity property in this way.

3.8 Setting options
We have already seen that invariants, pre-conditions and post-conditions

give rise to automatically generated Boolean functions that can be called during
the analysis of models. In addition, the tools support optional run-time (dy-

Figure 3.10 Integrity properties for the Alarm example



3.8 Setting options 51

Figure 3.11 The interpreter options

namic) checking of invariants, pre-conditions and post-conditions. The relevant
options are set using the Project Options entry in the Project pull-down menu.
This brings up the project options sub-window (Figure 3.11), allowing the rele-
vant options to be selected. Clicking OK causes the options to be saved.

As an exercise, make sure pre-condition checking is switched on. Now se-
lect the Interpreter item under the Tools menu. Go to the dialogue pane and
type “print NumberOfExperts(p5,plant)”. The response is “Run-
Time Error 58: The pre-condition evaluated to false”. This indicates that the
call of the function NumberOfExperts has violated the pre-condition from
its definition. In this case a violation has occurred because p5 is not incor-
porated in the domain of the schedule from plant. Such dynamic checks of
properties provide an additional way of gaining confidence in a model as it is
developed.

The Project pull-down menu also contains a Tool Options entry. This allows
the user to select a preferred editor. If this has been done it is possible to click
the editor icons present over the files in the Manager sub-window of the main
VDMTools window to automatically start up the editor with the correct file. This



52 3 VDMTools Lite

is particularly convenient if one is using Microsoft Word as the main editor, in
which case the VDM-SL source file needs to be in rich text format (rtf). This
is possible using special macros: more information about the choice of differ-
ent formats is provided in the VDMTools user manual [UserMan]. Throughout
this book, and in the example files available on-line, we use the ASCII syn-
tax, so these files may be processed by any ASCII editor such as Crimson
or Emacs. For both of these editors, it is possible to install setups specif-
ically for VDM source editing (available from the www.vdmportal.com
web pages).

Summary
We have introduced the following features of VDMTools Lite:

• project setup of selected VDM-SL files;
• syntax checking of VDM-SL models;
• type checking of VDM-SL models;
• error reporting;
• executing and debugging VDM-SL models;
• checking the integrity of VDM-SL models; and
• setting options for projects and different actions.

Exercise 3.4� Imagine an extension to the alarm example which would en-
able experts to swap duties. This function is called ChangeExpert. Given a
plant, two experts and a period it will yield a new plant where the plan has been
changed so that the first expert will be replaced by the second expert in the given
period. A first version of this function could be formulated as

ChangeExpert: Plant * Expert * Expert * Period -> Plant
ChangeExpert(mk_Plant(plan,alarms),ex1,ex2,peri) ==

mk_Plant(plan ++ {peri |-> plan(peri)\{ex1} union {ex2}},
alarms)

where the \ symbol removes the ex1 value from the schedule for the given
period peri and union adds the ex2 value.

Do you see any problems with this function? This definition is placed in the
file changeexpert.vdm so you should configure your project once again by
adding this file. When it has been syntax checked and type checked (the latter
is not strictly required) the interpreter can be initialised again. Now use the
interpreter to inspect the plant value returned from calls such as

ChangeExpert(plant,e4,e7,p3)
ChangeExpert(plant,e3,e7,p3)



3.8 Setting options 53

Will the invariant on the Plant data type be violated? Test this by setting the
option for invariant checking. If the invariant is broken it is possible to make
a break point for the invariant inv Plant itself and call that with a Plant
value which possibly satisfies the invariant. By single stepping inside this it
becomes easier to discover how the invariant is broken. If necessary, add the
pre-condition needed to complete the function. �





4
Describing System Properties Using
Logical Expressions

Aims
The aim of this chapter is to introduce the use of logic for stating the

properties of data and functions in system models. The logic used in VDM-SL
models is introduced via a temperature monitor example. On reaching the end
of the chapter, the reader should be able to state and analyse logical expressions
in VDMTools Lite.

4.1 Introduction
An important advantage of building a model of a computing system is

that it allows for analysis, uncovering misunderstandings and inconsistencies at
an early stage in the development process. The discovery of a possible failure of
the ExpertToPage function in the previous chapter was the result of just such
an analysis. The ability to reason about the types and functions in a model de-
pends on having a logic (a language of logical expressions) in which to describe
the properties of the system being modelled and in which to conduct arguments
about whether those properties hold or not.

This chapter introduces the language of logical expressions used in VDM-
SL, based on Predicate Logic. It begins by introducing the idea of a predicate,
then examines the basic operators which allow logical expressions to be built up
from simpler expressions. Finally, we examine the mechanisms for dealing with
mis-application of operators and functions in the logic of VDM-SL.

4.2 The temperature monitor
The example running through this chapter continues the chemical plant

theme. Suppose we are asked to develop the software for a temperature monitor
for a reactor vessel in the plant. The monitor is connected to a temperature
sensor inside the vessel from which it receives a reading (in degrees Celsius)
every minute.

55



56 4 Describing System Properties Using Logical Expressions

Figure 4.1 Sample temperature variations and last five readings

1 2 3 4 5 6 7 8 9

10

20

30

Time (m)

Temperature
(Celsius)

0

25 10 5 5 10

The monitor records the five most recent temperature readings in the order in
which they were received from the sensor. For example, suppose the tempera-
ture at a sensor has varied as shown on the graph in Figure 4.1. The last five
temperatures recorded in the monitor are shown as a sequence in the lower part
of the figure.

In order to keep the reactor under control, the monitor should be able to detect
and warn of certain conditions such as steady, wildly fluctuating or excessively
high temperatures. It can do this by examining the changes over the last five
temperature readings.

Suppose the following conditions are to be detected:

Rising temperature: the last reading in the sample is greater than the first;
Over limit: there is a reading in excess of 400◦C;
Continually over limit: all the readings in the sample exceed 400◦C;
Safe: if the readings exceed 400◦C by the middle of the sample then the reactor

is still safe provided the reading is less than 400◦C by the end of the sample;
Alarm: an audio alarm is to be sounded if and only if the reactor is not safe; and
One peak: there is exactly one reading in the sample that is in excess of 400◦C.



4.3 Logical expressions 57

The monitor is to be modelled formally. The purpose of the model is to help
define precisely the conditions which are to be detected. As indicated in Chap-
ter 2 the formal model will contain a description of the data held by the monitor
and descriptions of the functions which can be performed on the data. In this
case, the model must describe the conditions listed above. The logic part of
VDM-SL allows us to do this.

Before describing the conditions, we should introduce our formal model of
the temperature monitor. The main point of interest is the sequence of read-
ings on which the conditions have been described. To model these, a type
TempRead is introduced. The readings are for simplicity reasons modelled
as integers and, because the order in which they occur is significant, formed into
a sequence. An invariant records the fact that there must always be five readings:

TempRead = seq of int
inv temp == len temp = 5

where len is a basic operator that returns the length of a sequence. Modelling
using sequences will be presented in Chapter 7.

4.3 Logical expressions
4.3.1 Simple predicates

The simplest kind of logical expression in VDM-SL is a proposition. A
proposition describes some property of specific values and is built up from the
values using operators which return Boolean results, i.e. operators which return
either true or false when applied to values. For example, in the world of
numbers, the operators < (read “is less than”), > (read “is greater than”) and =
(read “is equal to”) allow propositions to be built up from values. For example,

3 < 27

is a proposition asserting that 3 is less than 27. Propositions can be true or false.
For example, the proposition just given is true, but the following proposition is
false:

5 = 9

Both are perfectly valid propositions.
Propositions have rather limited value in specifying realistic computing sys-

tems. For example, in our reactor monitor, we have to be able to deal with any
arbitrary sequence of readings, not just some specific values. Using proposi-
tions to describe the conditions is impractical: we would have to describe every



58 4 Describing System Properties Using Logical Expressions

possible sequence of readings and say whether it exhibited a condition or not.
For that reason, we allow variables to stand for values in expressions, in just the
same way as variables are allowed to stand for values in conventional applied
mathematics, where a mass might be termed m and a velocity v. If we allow the
variable x to stand for an arbitrary number then it is possible to write

x < 27

This expression will be true if x is 3, but false if x is 82, for example.
A logical expression containing a variable is termed a predicate in VDM-SL.

Here are some other examples of predicates in VDM-SL:

x < 23 The variable is x. If x is 3 then the predicate
is true, if x is 29, then it is false.

(x ** 2) + x - 6 = 0 The variable is x. The symbols + and -
are arithmetic addition and subtraction; **
raises a number to a power (in this case x is
squared). The predicate is true if x is 2 or
x is -3.

Predicates can have more than one variable. For example, the predicate

(x ** 2) + y = 3

has two variables (x and y). It is true when x is 0 and y is 3; also when x is 1
and y is 2.

Returning now to the reactor monitor, predicates can be used to describe the
conditions which must be detected. We introduce a variable which can stand for
any sequence of five readings. Call the variable temp. To refer to a reading
in temp, we index into the sequence, as one might index into an array in a
program. Thus, the oldest reading in the list is written formally as

temp(1)

(in VDM indexing starts with 1, not 0) while the most recent reading is

temp(5)

These readings are integers, so we can compare them using the conventional
numerical comparison operators < (less than), <= (less than or equal to) etc. For
example, if we want to say that the temperature has increased over the sample
period, we can formally write

temp(1) < temp(5)



4.3 Logical expressions 59

To state that the temperatures at the beginning and at the end of the sample
period are the same, we can write

temp(1) = temp(5)

The two formulae above are predicates: their truth or falsehood depends on the
readings in the variable temp. For example, if temp holds the sequence of
values shown in Figure 4.1, the following are true:

temp(1) >= temp(5)
temp(3) = temp(4)

but the following three predicates are false:

temp(1) = temp(5)
temp(4) > temp(2)
temp(1) < temp(3)

Condition 1: Rising temperature The temperature is said to be rising if the last
reading in the sample is greater than the first. To be able to use this predicate in
a model (and in VDMTools Lite), we incorporate it into a Boolean function:

Rising: TempRead -> bool
Rising(temp) ==
temp(1) < temp(5)

4.3.2 Building more complex predicates: logical operators
Simple predicates are very limited in their capabilities. It is often nec-

essary to build more complex predicates out of simpler ones by using logical
operators. In this section, each operator is introduced with an example.

Negation – “not” Negation allows us to state that the opposite of some logical
expression is true. For example, if the monitor needs to detect the condition
that the initial temperature in a sample is not over 350◦C, the condition could be
recorded as follows:

not temp(1) > 350

The condition above could equally well be stated positively as temp(1) <=
350. It is usually the case that logical conditions have several equally valid
representations. The symbol not represents the negation of a logical expres-
sion. The expression not A is true only when A is false. The operator’s
behaviour can be represented using a truth table as follows:



60 4 Describing System Properties Using Logical Expressions

A not A

true false
false true

The column headed “A” gives each possible truth value of an arbitrary logical
expression A. The column headed “not A” gives the corresponding truth value
of the expression not A.

Disjunction – “or”

Condition 2: Over limit A sequence of readings is over limit if one of the read-
ings exceeds 400◦C. There are five possibilities:

temp(1) exceeds 400◦C or temp(2) exceeds 400◦C or

temp(3) exceeds 400◦C or temp(4) exceeds 400◦C or

temp(5) exceeds 400◦C

The “or” is represented in VDM-SL using the logical disjunction operator “or”.
The condition above is formulated as follows1:

temp(1) > 400 or temp(2) > 400 or
temp(3) > 400 or temp(4) > 400 or
temp(5) > 400

The Boolean function incorporating this predicate is defined as follows:

OverLimit: TempRead -> bool
OverLimit(temp) ==

temp(1) > 400 or
temp(2) > 400 or
temp(3) > 400 or
temp(4) > 400 or
temp(5) > 400

Exercise 4.1 Try evaluating the following expressions by hand:

OverLimit([350,365,421,390,380])
OverLimit([350,390,320,395,330])
OverLimit([345,341,433,321,314])

Configure VDMTools Lite to work on the file monitor.vdm which contains
the definition of OverLimit. Initialise the interpreter and use it to evaluate the
expressions above, comparing the tool’s answer with those you expected. �

1 The line breaks in these logical expressions do not affect their meaning, but it is a good
discipline to space expressions out in order to make them easier to read.



4.3 Logical expressions 61

The truth table for disjunction makes it clear that disjunction is an “inclu-
sive or”, i.e. the disjunction is true if either or both of its components (called
disjuncts) are true:

A B A or B
true true true
true false true
false true true
false false false

The truth table defines the disjunction of a pair of logical expressions. The
extension from a binary disjunction to a longer one is straightforward: the dis-
junction is true if any of the disjuncts are true. Formally, we regard a disjunction
of the form

E1 or E2 or E3 or ... or En

as a left-to-right series of binary disjunctions:

(...((E1 or E2) or E3) or ...) or En

Parentheses can always be used to constrain the order in which subexpressions
should be evaluated.

Conjunction – “and” Conjunction allows us to say that more than one predicate
is true at a time. For example, if we want to state formally that the first three
readings in temp are decreasing, we can say

temp(1) > temp(2) and temp(2) > temp(3)

Condition 3: Continually over limit A sequence of readings is continually over
limit if all of the readings exceed 400◦C.

temp(1) exceeds 400◦C and temp(2) exceeds 400◦C and

temp(3) exceeds 400◦C and temp(4) exceeds 400◦C and

temp(5) exceeds 400◦C

The and symbol represents the logical conjunction of logical expressions called
conjuncts. Formally, in VDM-SL, the condition is

temp(1) > 400 and temp(2) > 400 and
temp(3) > 400 and temp(4) > 400 and
temp(5) > 400

This gives the following Boolean function:



62 4 Describing System Properties Using Logical Expressions

ContOverLimit: TempRead -> bool
ContOverLimit(temp) ==

temp(1) > 400 and
temp(2) > 400 and
temp(3) > 400 and
temp(4) > 400 and
temp(5) > 400

Exercise 4.2 Evaluate the following expressions by hand and compare your
results with those obtained by evaluating the same expressions using VDMTools
Lite configured on the file monitor.vdm.

ContOverLimit([450,465,421,590,480])
ContOverLimit([350,390,420,395,430])
ContOverLimit([345,341,433,321,314])

�

The truth table for the expression A and B indicates that it is true only when
both conjuncts are true:

A B A and B

true true true
true false false
false true false
false false false

Implication – “if”

Condition 4: Safe The sample is still considered safe if the readings exceed
400◦C by the middle of the sample as long as they fall to less than 400◦C later.
To express this formally, it would be convenient to have some notion of “if
. . . then . . . ” in the logic. This is embodied in the implication operator “=>”.

The reactor is safe when the following condition holds:

if the readings exceed 400◦C by the middle of the sample then the reading must

be less than 400◦C by the end of the sample.

Observe that the condition “by the middle of the sample” can be ambiguous,
referring to the first two or the first three readings. Disambiguation requires
consultation with the client. Assuming that this has been done, we express the
condition by the predicate

temp(3) > 400



4.3 Logical expressions 63

The condition that the readings exceed 400◦C by the end of the sample can be
expressed by the simple predicate

temp(5) < 400

The safety condition is formally expressed as

temp(3) > 400 => temp(5) < 400

and the Boolean function for checking safety is

Safe: TempRead -> bool
Safe(temp) ==
temp(3) > 400 => temp(5) < 400

The reactor must be safe if the middle temperature is lower than 400◦C. The
only possibility we must exclude here is the case where the temperature exceeds
400◦C by reading 3, but does not fall to less then 400◦C by reading 5. This is
reflected in the truth table for implication. The left-hand side of the implication
is called the antecedent and the right-hand side is called the consequent.

A B A => B

true true true
true false false
false true true
false false true

Biimplication – “if and only if”

Condition 5: Alarm Having expressed the prime conditions required in the
model, the requirement that an alarm should be raised if and only if the re-
actor is not in the safe condition. We have already formulated the safe condition
as Safe(temp).

The alarm should therefore be raised if and only if the negation of the safe
condition is true:

not Safe(temp)

If the Boolean variable alarm stands for the state of the alarm, it is either
true (alarm is sounding) or false (alarm is not sounding). We could try to
formulate the condition as

not Safe(temp) => alarm

This asserts that the alarm should be sounded when the reactor is not safe, but
does not prevent the alarm from going off when the reactor is perfectly cool. The
requirement said that the alarm should go off if and only if the reactor is unsafe,



64 4 Describing System Properties Using Logical Expressions

so we introduce the biimplication symbol “<=>” to stand for “if and only if”.
This can be considered a double implication because it works as a conjunction
of two implications: one in each direction. Thus, the biimplication

not Safe(temp) <=> alarm

is equivalent to the following conjunction of implications:

not Safe(temp) => alarm and
alarm => not Safe(temp)

The Boolean function for stating the alarm can be expressed as an implicit defi-
nition as follows:

RaiseAlarm(temp: TempRead) alarm: bool
post not Safe(temp) <=> alarm

The truth table for biimplication makes it clear that the two sides of the <=>
must have the same logical value for the biimplication to be true:

A B A <=> B
true true true
true false false
false true false
false false true

4.4 Presenting and evaluating predicates
The predicates presented so far in this chapter have been comparatively

simple. When evaluating more complex predicates, using parentheses to bracket
subexpressions helps to reduce confusion. Consider a complex logical expres-
sion such as

(Rising(temp) and
(ContOverLimit(temp) or OverLimit(temp))) =>

not Safe(temp)

The parentheses tell the reader how to evaluate the expression, starting with the
most deeply nested parts. If temp has the value [453,345,400,387,401]
the predicate is evaluated by first replacing the value for temp throughout and
then evaluating each of the function calls. The evaluation goes from the brack-
eted subexpressions of the most deeply nested parts outwards:

(false and (false or true)) => false
(false and true) => false
false => false
true



4.4 Presenting and evaluating predicates 65

This detailed evaluation seems very tedious, but, with practice, short cuts be-
come apparent: for example, the fact that one conjunct is false is enough to
make the whole expression false. Indeed, VDMTools Lite evaluates just enough
sub-expressions (working from left to right) to determine the overall value of a
logical expression.

Operator Precedence
In VDM-SL, the logical operators have a precedence relation which tells

the reader how to evaluate expressions when parentheses have been omitted. The
precedence relation is as follows:

Highest not
and
or
=>

Lowest <=>

In order to evaluate an expression, work from left to right, first bracketing ev-
ery not with the expression following it. Then work left to right again, brack-
eting each and with the expressions on either side of it. Carry on down the
precedence relation.

To see how this works suppose we are presented with the complex expression
above, but this time without any parentheses:

Rising(temp) and
ContOverLimit(temp) or OverLimit(temp) =>

not Safe(temp)

Bracketing the expression using the rules given above yields the following ver-
sion:

((Rising(temp) and ContOverLimit(temp)) or
OverLimit(temp)) =>

(not Safe(temp))

At first glance one may think that this gives the same result as before.
Exercise 4.3 Evaluate the new bracketed version of the expression by hand

using the same value of temp as was used at the beginning of the section. Check
your result using VDMTools Lite. �

The result is different from the original version because the bracketing is dif-
ferent. Notice that the precedence relation causes the ands to be evaluated



66 4 Describing System Properties Using Logical Expressions

before the ors, whereas the bracketing in the original version of the expression
forces the or to be evaluated before the and. The moral of the story is simple:
when in doubt, use parentheses to make clear the order of evaluation you want –
the default order based on the precedence relation may not be exactly what was
required.

4.5 Using quantifiers

Some of the predicates used in Subsection 4.3.2 to represent conditions
on the reactor temperature are rather long-winded. For example, the reactor
is over limit if there is a reading in excess of 400◦C. This was formulated as
follows:

OverLimit: TempRead -> bool
OverLimit(temp) ==

temp(1) > 400 or
temp(2) > 400 or
temp(3) > 400 or
temp(4) > 400 or
temp(5) > 400

This is acceptable for a short sequence of five readings, but suppose one was
modelling a system with hundreds of readings to compare, or one with an un-
known or variable number of readings. In this case, it would be much more
convenient to use a variable for the index into the sequence, referring to

temp(i)

for the ith element of the sequence. It is straightforward to state that temp(i)
exceeds 400◦C:
temp(i) > 400

However, we need to be able to say that this should hold for some value of i
in the range {1,...,5}. In the formal language of VDM-SL, we do this by
using an existential quantifier. We assert that there exists an element i of the
set {1,...,5} such that temp(i) > 400. In VDM-SL, this is formally
written as follows:

exists i in set {1,...,5} & temp(i) > 400

The existential quantifier allows us to construct a logical expression about a
whole collection of values of the variable i in one go, but it is equivalent to
forming a long disjunction out of all the possible instances of i.



4.5 Using quantifiers 67

The equivalent to taking a long conjunction of formulae is the universal quan-
tifier forall. The following formula states the “continually over limit” condi-
tion that all the recorded temperatures exceed 400◦C:
forall i in set {1,...,5} & temp(i) > 400

The variable which is constrained by a quantifier to range across a set of
values is called the bound variable (it is said to be bound to the elements of the
set of values). Variables which are not bound in a formula are said to be free,
e.g. temp in the formula above.

Quantifiers allow us to express properties of whole collections of values at
once, rather than just one at a time. For example, in real models we need to
describe properties such as the following:

• All reactors hotter than 500 degrees Celsius should have the heating
switched off.

• There are no two users with the same identifier.
• There is only one user with root access.

These logical expressions range over whole groups of values (e.g. all reactors,
users).

The syntax for expressions using the two basic quantifiers is

forall binding & predicate
exists binding & predicate

It is very important to stress that these are simply Boolean expressions; to the
novice formulae beginning with “forall” or “exists” may appear to be performing
some calculation. Universally quantified formulae can be interpreted as stating
that “for all values in the binding, it is true that the predicate holds”; existential
formulae are interpreted as “there exists a value in the binding such that the
predicate holds”. Note that “&” must merely be seen as a syntactic separator
between the binding and the predicate: in the universally quantified formula it
reads as “it is true that”, while in the existential version it reads as “such that”.

The binding part names the bound variables and gives the collection of values
(called the range) they belong to. If the range is a type, the binding is called a
type binding and we use a colon notation. For example the formula

forall x:nat1 & x>0

may be paraphrased as “For all x in the type nat1, it is true that x is greater
than zero”. If the range is a set, the binding is called a set binding and we use
the in set notation. For example, the formula



68 4 Describing System Properties Using Logical Expressions

exists x in set {1,2,6,7} & x>0

may be paraphrased as “There is a number x in the set {1,2,6,7} such that x
is greater than zero.” The main difference between types and sets is that types
can have infinitely many elements whereas sets are always finite in VDM-SL.
This also means that the interpreter from VDMTools Lite will be able to execute
quantified expressions with set bindings, but not those with type bindings. No-
tice that, for sets, we are using the { , , , } notation to list members. We can
also represent a contiguous range of integers in a set using the ... notation,
e.g. {5,...,15} which represents the integers from 5 to 15 inclusive. For
example, the following expression asserts that all the readings in temp are over
400:

forall i in set {1,...,5} & temp(i) > 400

The following expression asserts that every reading is less than its successor:

forall i in set {1,...,4} & temp(i) < temp(i+1)

Notice that the set {1,...,4} is used in the expression above to avoid com-
paring temp(5) with temp(6), which would involve indexing out of range
on the sequence of readings.

The name of a bound variable is not important, as long as it does not interfere
with the names of free variables in the predicate part of a quantifier. Thus, the
following expression is equivalent to the previous one:

forall fred in set {1,...,4} & temp(fred) < temp(fred+1)

Several variables may be bound at once by a single quantifier. Consider, for
example, a logical expression which states that no two readings are equal:

forall x,y in set {1,...,5} & not (temp(x) = temp(y))

Suppose we had the following value for temp:

[320, 220, 105, 119, 150]

Would the expression above be true? Certainly there are no two distinct readings
which have the same value, but let us look carefully at the formula. It asserts
that, for any x and any y, the reading at x and the reading at y are not equal.
The forall quantifier is required to consider all possible bindings of x and y
including the binding where the same index is selected for x and for y, say 3,
so that temp(x) and temp(y) are bound to be the same. Thus, the formula
above would never be true, because we will always find an x and y which
have the same reading. The lesson from this example is to be very careful when
dealing with quantifiers that use several bound variables ranging over the same



4.5 Using quantifiers 69

values: the formula has to work when the variables take the same values from
the common range. In this particular example, we could include a restriction
that x is not equal to y and assert that, for any x and y, if x and y are distinct,
then the readings at x and y are different:

forall x,y in set {1,...,5} &
not (x = y) => not (temp(x) = temp(y))

Exercise 4.4 Try formulating the following properties using predicate logic:

1. All the readings in temp are less than 400 and greater than 50.
2. Each reading in temp is greater than its successor by at least 1 and at

most 10◦C degrees.
3. There are two distinct readings in temp which are over 400◦C.

�

Mixing Quantifiers Much of the power of quantifiers arises from the ability to
mix them. For example, to assert that for any natural numbers between 10 and
20 inclusive there is a natural number equal to half of the first number, we write
the following:

forall n in set {10,...,20} & exists p:nat & 2*p=n

This logical expression is equivalent to false but it is still a valid expression.
In the chemical plant monitor, we might wish to record a condition where

there is a “single minimum” in the sequence of readings, i.e. there is a reading
which is strictly smaller than any of the other readings. This could be formalised
as follows:

exists min in set {1,...,5} &
forall i in set {1,...,5} &

i <> min => temp(i) > temp(min)

Notice that the order in which quantifiers are used is very important. The “sin-
gle minimum” example is a case in point. If the order of quantifiers is reversed,
the expression is

forall i in set {1,...,5} &
exists min in set {1,...,5} &

i <> min => temp(i) > temp(min)

Reading this carefully, we see that the expression says that, for every reading i,
there exists another reading at index min which is strictly less than the original
reading, providing min is a different index from i. We know that we can always



70 4 Describing System Properties Using Logical Expressions

select min to be the same as i, making the implication trivially true, so this
expression always evaluates to true, unlike the “single minimum” example.

Exercise 4.5 Debug the two different expressions mixing the forall and
exists quantifications to convince yourself that the order is important. Try
evaluating the expressions on the value [375,230,230,250,275]. �

Condition 6: One peak The final condition to be considered is the one where
there is exactly one reading in the sample that is in excess of 400◦C. In order
to do that effectively we will introduce an extra quantifier called a unique exis-
tential quantifier. This is similar to an existential quantifier except that it is true
only if exactly one of the values makes the body predicate true. Note that it is
false if there are no values to satisfy the body predicate. Unlike the normal exis-
tential quantifier, it is also false if more than one value makes the body predicate
true.

The syntax for the unique existential quantifier is

exists1 binding & predicate

in the same way as for the basic quantifiers introduced above. So it is unique
in the sense that exactly one value from the binding satisfies the body predicate.
This quantifier can be used to formalise condition 6 described above as

OnePeak: TempRead -> bool
OnePeak(temp) ==

exists1 i in set inds temp & temp(i) > 400

which will yield true if we have exactly one of the readings that is above 400◦C
degrees.

Exercise 4.6 Redefine the OnePeak function using the basic logical opera-
tors and, or, not and =>. �

In VDM-SL functions can themselves be used as parameters to other func-
tions. This can be used to describe the uniqueness as a function with a predicate
pred (a function which given a ’natural number yields a Boolean result) for
example over a set of natural numbers s as

Unique: (nat -> bool) * set of nat -> bool
Unique(pred,s) ==

forall x,y in set s & (pred(x) and pred(y)) => x = y

Note that here it is possible to actually take advantage of the fact that x and y
may be the same value. So if we had a small function defined as



4.6 Coping with undefinedness 71

GreaterThan7: nat -> bool
GreaterThan7(n) ==
n > 7

we would be able to use GreaterThan7 as a parameter to the Unique func-
tion. So, for example, Unique(GreaterThan7,{5,9}) would yield true
whereas Unique(GreaterThan7,{10,9}) would yield false.

Exercise 4.7� Make use of the Unique function to define a function called
ExistsUnique that corresponds to a unique existential quantifier for natural
numbers without using exists1 directly. �

4.6 Coping with undefinedness
Very often in modelling critical or high-integrity systems, we wish to

model failure and recovery behaviour. Suppose that the temperature sensors in
our example fail in such a way that they send a special value (called <ERROR>)
to the monitor when they are unable to send an accurate temperature reading. In
this situation, we cannot make comparisons like

<ERROR> < 400

The “<” operator does not make sense of <ERROR> and so the comparison is
neither true nor false, but simply meaningless. Our logic and modelling nota-
tion are meant to handle realistic computing systems, so they should be equipped
with some means of handling undefined applications of operators. Similar sit-
uations can arise, for example, when division by zero may occur. Attempts to
evaluate undefined expressions can lead to non-termination.

Dealing with undefinedness in logic
The logic in VDM-SL has been designed to cover undefined values. The

logic called LPF (Logic of Partial Functions) extends the truth tables to cover
undefined values. For example if a logical expression is undefined, so is its
negation. We represent an undefined value by * in the truth tables. Thus, the
table for negation is

A not A
true false
false true

* *



72 4 Describing System Properties Using Logical Expressions

The other tables are considered below.

Disjunction Consider the expression A or B. Either A or B or both could be
undefined, but it is sometimes possible to evaluate the expression as a whole
if we know the value of one of the disjuncts. Suppose we evaluate A and B in
parallel. As soon as one of the disjuncts evaluates to true we know that the
entire disjunction is true, regardless of whether the other disjunct evaluates to
true, false or undefined. If one disjunct evaluates as false, but the other
is undefined, we cannot know whether the disjunction as a whole is true or not,
so it remains undefined. This approach results in the following truth table:

A B A or B

true true true
true false true
true * true
false true true
false false false
false * *

* true true

* false *
* * *

Conjunction If one conjunct is false, we know that the whole conjunction is
false, regardless of whether the other conjunct is true or false or undefined. If
one conjunct is known to be true, but the other is undefined, we cannot determine
whether the conjunction as a whole is true or not, so it remains undefined:

A B A and B
true true true
true false false
true * *
false true false
false false false
false * false

* true *
* false false

* * *



4.6 Coping with undefinedness 73

Implication In the case of implication, we know that A => B is true if A is
false, regardless of the truth or undefinedness of B. We also know that A =>
B is true if B is true, regardless of A. This gives the following table:

A B A => B
true true true
true false false
true * *
false true true
false false true
false * true

* true true

* false *
* * *

Biimplication Here we need both values A and B to determine the truth of A
<=> B, so in all other cases the result must be undefined.

A B A <=> B
true true true
true false false
true * *
false true false
false false true
false * *

* true *
* false *
* * *

Dealing with undefinedness in the interpreter
How can we deal with undefinedness when interpreting logical expres-

sions in VDMTools Lite? The treatment of undefinedness requires subexpres-
sions to be evaluated in parallel because of the risk of non-termination of one
of the subexpressions. However, this is not a practical approach because of the
process management overhead. So we evaluate subexpressions in a fixed order,
from left to right as in most programming languages. Thus, it is necessary to
guard against expressions that can yield a run-time error (and thus an undefined
value). We have carefully done this in the VDM-SL definitions presented here.
Thus, if a value elem must be in the domain of a mapping m and it must be



74 4 Describing System Properties Using Logical Expressions

associated with a special value info when it is looked up in the map it must be
written as

elem in set dom m and m(elem) = info

rather than

m(elem) = info and elem in set dom m

because in this way it is guaranteed that elem belongs to the domain of m before
the partial operation of looking up in the map is carried out.

Consequently the truth tables for the logical operators implemented in the
interpreter in VDMTools are no longer symmetrical when subexpressions are
undefined. For disjunction the truth table becomes

A B A or B
true true true
true false true
true * true
false true true
false false false
false * *

* true *
* false *
* * *

where the small box indicates the place where there is a difference from the
tables presented earlier. For conjunctions the truth table becomes

A B A and B
true true true
true false false
true * *
false true false
false false false
false * false

* true *
* false *
* * *

and again the small box indicates the place where there is a difference. Finally,
for implication the truth table becomes



4.6 Coping with undefinedness 75

A B A => B

true true true
true false false
true * *
false true true
false false true
false * true

* true *
* false *
* * *

The truth tables for negation and biimplication are not affected.

Summary
• Predicates are logical expressions with free variables which may be

instantiated to values in a binding.
• Predicates may be composed using the basic logical operators and, or,
not, <=> and =>. The meaning of the basic operators are given via
truth tables.

• The Universal (forall), Existential (exists) and Unique Existen-
tial (exists1) Quantifiers allow logical expressions to be made about
collections of values. Bindings in quantifications allow variables to
range over types or sets. Universal quantification may be looked on
as a potentially infinite conjunction; existential quantification as a po-
tentially infinite disjunction.

• Universal and existential quantifiers can bind several variables. All
quantifiers can be nested and mixed in a logical expression.

• The Logic of Partial Functions extends the truth tables of basic Predicate
Logic to allow for reasoning with undefined values.

Exercise 4.8 Define the functions Xor and Nand with the following truth
table:

A B Xor(A,B) Nand(A,B)
true true false false
true false true true
false true true true
false false false true



76 4 Describing System Properties Using Logical Expressions

Test the functions using the interpreter with the different combinations. �

Exercise 4.9 Construct the truth table for “(not A) or B” and take the un-
defined element * into account. �



5
The Elements of a Formal Model

Aims
This chapter aims to introduce the reader to the most basic kinds of

data value available to the modeller and to show how values can be manipulated
through operators and functions. These are introduced using a traffic light ker-
nel control example. On completing this chapter the reader should be able to
recognise and use all the basic data types of VDM-SL.

5.1 Introduction
A functional model of a system is composed of definitions of types

which represent the kinds of data values under consideration and definitions
of functions which describe the computations performed on the data. In order
to develop a formal model, we therefore require a means of defining types and
values, and ways to construct logical expressions which state the properties of
values. This chapter illustrates these features in VDM-SL and introduces the
basic types available in VDM-SL using an example based on traffic light con-
trol. A data type (or simply type) in VDM-SL is a collection of values called
the elements or members of the type. For example, the type of natural numbers
consists of infinitely many elements, from zero upwards. To make use of a type,
we will need

• a symbol to represent the type, e.g. nat;
• a way of writing down the type’s elements, e.g. 3, "John";
• value operators to permit the construction of more sophisticated expres-

sions that represent elements of the type, e.g. + to represent addition;
and

• comparison operators, e.g. <, to allow expressions of elements of the
type to be compared.

This chapter introduces the basic types of VDM-SL (the ones that come “for
free” with the language), and the three most basic type constructors that build
new types from the basic types. These are: optional types with the nil value ([ ]),

77



78 5 The Elements of a Formal Model

union types ( | ) and record types (with :: definitions). Such type constructors
are used for constructing more interesting types from the basic ones.

When defining value operators, we will give signatures in the same way as
we do for function definitions. The values on which an operator works will be
termed arguments. Arguments may themselves be expressions built up from
operators applied to other values. Note that operators often have infix forms.
Thus, we may give the signature of real number addition as follows:

\_+\_: real * real -> real

and allow the operator to be written between the expressions on which it oper-
ates, e.g.

(3.5 + 5.8) + (2.0 + 9.8)

It is important to distinguish total and partial operators. An operator op
having the signature

op: A1 * A2 * ... * An -> B

is said to be total if op(a1,...,an) is defined for all combinations of argu-
ment values a1,...,an of types A1,A2,...,An. An operator op is said to
be partial if there is some input such that an application op(a1,...,an) is
undefined.

Real number addition is a total operator because any real numbers can be
added to any other real number. However, within a computer, “addition” is
normally a partial operator because the computer can only represent a finite
range of numbers. VDM-SL allows us to deal with unrestricted numeric values
or to introduce restrictions if they are relevant to the model. Numeric division
is an example of a partial operator because division by 0 is undefined. In an
implementation, division by zero would typically result in a run-time error.

Having introduced these basic definitions we are now ready to look at the
ongoing example for this chapter.

5.2 A traffic light control kernel
This example is derived from a model developed by Paul Ammann in

the Z notation [Ammann95, Ammann96]. Traffic light control is safety critical
because certain failures of traffic signals can lead to hazardous road conditions
which can result in accidents. One approach to ensuring that a traffic light con-
troller will not contribute to an accident is to develop a safety kernel of the sys-
tem [Rushby86]. The safety kernel provides the only means of control over the
critical functions of the system. Usually the kernel is the only part of the soft-



5.2 A traffic light control kernel 79

Figure 5.1 Example intersection with traffic lights

A66West

A66East

A1North

A1South

ware which has direct access to the controllers of the physical system, so that
other software components must use the kernel to interact with the environment.
Since the kernel is responsible for maintaining safety, it is worth modelling it at
an early stage of development, so that the designers have a clear understanding
of how the kernel should behave. A kernel must ensure a desired behaviour for
the overall system without making any assumptions about the trustworthiness or
proper functioning of the remaining parts of the software system.

Traffic lights. Where roads cross it may be necessary to regulate the traffic using
coloured lights. Each traffic light is responsible for informing drivers whether
they can drive through the intersection or whether they must wait. A green light
is used to indicate that drivers can continue and a red light is used to indicate that
drivers must stop. The amber light is used to indicate that the lights are about
to change from green to red. All traffic paths are regulated by lights and some



80 5 The Elements of a Formal Model

traffic paths conflict in the sense that traffic flowing simultaneously in conflicting
paths may result in an accident. A simple intersection with four traffic lights is
shown in Figure 5.1.

A traffic light controller is responsible for controlling the lights. The aim
of the traffic light controller is to ensure that the traffic will flow as smoothly
as possible without accidents. The safety kernel for such a controller should
ensure that the lights do not permit traffic to flow in conflicting paths simulta-
neously. A light associated with a particular path may only change according
to the transitions shown as arrows in Figure 5.2. For a light on a given path to
turn Red, it must have been Amber for at least AmberChange seconds prior to
the transition, thereby giving drivers fair warning of the impending Red. For
a light to turn Green all lights in conflicting paths must have been Red for at
least RedClearance seconds, in order to give traffic time to clear the junction.
From a functional perspective, for a light to turn Amber, the light must be Green
for at least MinimumGreen seconds in order to allow a fair chance for traffic to
flow smoothly. However, this requirement may be violated: for example, if an
emergency vehicle needs to pass in a conflicting path.

Figure 5.2 Rules for traffic light transitions

Safety requirements for a traffic light controller. The requirements for the safety
kernel of the traffic light controller are as follows:



5.3 Union and basic types 81

S1 It must always be the case that if a pair of paths conflict then the light asso-
ciated with one of the paths is red.

S2 Before a light is allowed to change from Red to Green, there must have been
a delay of RedClearance seconds after the lights in all conflicting paths turn
Red.

S3 There must be a delay of AmberChange seconds after the light turns Amber
before the light is allowed to change from Amber to Red.

This example is used to introduce some of the basic types and operators from
VDM-SL. We will first develop a model of the kernel, and then review the safety
requirements to check that they hold in the model. As always, we will be careful
to consider the purpose of the model before constructing it, as this purpose will
be our guide in determining which aspects of the system to include in the model.
In this case, the model is being built to help define the functionality of the safety
kernel. We therefore concentrate on those issues which affect the safety of the
lights system at the junction.

5.3 Union and basic types
5.3.1 Union and quote types

First we consider how to model the alternative colours of the lights. We
can introduce this by making a type definition:

Light = <Red> | <Amber> | <Green>

This type definition introduces a new data type Light which contains just three
distinct values: <Red>, <Amber> and <Green>. This corresponds to what is
known as an enumerated type in programming languages. In VDM-SL, such
an enumerated type is achieved by combining quote types using the union type
constructor. It is worth examining the type definition in a little more detail.

The symbols distinguished by the use of angle brackets are called quote types.
A quote type has only one element, and this has the same name as the type
itself. Thus, the value <Green> belongs to the type <Green> and to the type
Light. The type Light contains the union of the types <Red>, <Amber>
and <Green> and hence only the values <Red>, <Amber> and <Green>.

The union type constructor, written “ | ”, builds a type containing all the
elements of its argument types. For example, the expression

Person = Student | Staff

defines a new data type Person consisting of all the members of the type
Student and all the members of the type Staff. In the case of the type



82 5 The Elements of a Formal Model

Light, the union is composed of the three quote types, each of which has just
one member.

5.3.2 The numeric types
As it will be necessary to model periods such as the delays RedClear-

ance and AmberChange, we must introduce a type to model time. A numeric
type seems appropriate. However, there is a choice to make because a number
of numeric types exist. They are

Natural numbers incl. 0 nat 0, 1, 2, . . .
Natural numbers excl. 0 nat1 1, 2, 3, . . .
Integers int . . . , −2, −1, 0, 1, 2, . . .
Rationals rat . . . , −1.229, . . . , 0, . . . 53.0, . . .
Reals real . . .−3.7, . . . , 0, π, . . . , 5.8372, . . .

These types have the usual meanings but note that, because we are rarely con-
cerned with their internal representation, there are no fixed maximum or mini-
mum numbers, and there is no fixed or variable precision in the rationals or reals.
This is fine in theory but of course it is necessary to be able to represent actual
values in VDMTools. Only a finite number of real numbers can be represented
in VDMTools. For example, π cannot be represented because it has an infinite
number of digits so, as usual, it must be approximated.

In the traffic light controller example, the modeller chooses to model absolute
time by the real numbers and to operate in seconds. A new data type Time is
defined as follows:

Time = real

An alternative could be to work in, say, milliseconds and use the integers be-
cause the resolution at milliseconds would be sufficient. The natural numbers
could also be used with this unit, thereby excluding negative times. For numeric
types the usual arithmetic and comparison operators are available (see Subsec-
tion A.4.2). We will use them as they are required in the following chapters.

5.3.3 The token type
Another important concept for the model of the traffic light controller

is that of path (we will have to model the notion of conflicting paths). For the
model of the traffic light control system made here, we are not really concerned
about the underlying representation of the paths. In an instantiation of the im-
plementation of a general traffic light controller, paths may be identified using



5.4 Basic type constructors 83

a name of a road (e.g. “A1”) and the town the road is leading to (e.g. “towards
Washington” or “Northbound”). However, for this model, we need only to be
able to compare paths to see whether they are identical and record which paths
conflict with one another. In this case we make a type definition like

Path = token

The basic type token is used whenever the representation of a data type is
immaterial to the formal model. As a general guide, the representation is im-
material if the functions do not require access to the values of the type. For
example, if a function were required to modify the name of a path, we would
have to have defined a more elaborate representation. However, no such function
is required, and so token is sufficient as a representation for Path. The only
operation that can be carried out on a token value is a comparison for equality
with another token value.

In order to represent the paths shown in Figure 5.2 we could create some value
definitions. This is done by prefixing the definitions with the keyword values:

values

p1 : Path = mk_token("A1North");
p2 : Path = mk_token("A1South");
p3 : Path = mk_token("A66East");
p4 : Path = mk_token("A66West")

In order to define a value, we give the name of the value, its type and its actual
value. Note that value definitions must be given in such an order that each ex-
pression describing an actual value may only make use of other value identifiers
that have already been defined. Otherwise VDMTools Lite would not be able to
initialise the model. Token values are written with a mk token constructor and
an arbitrary value inside the braces1. In this case we have simply chosen to use
strings, i.e. sequences of characters.

5.4 Basic type constructors
We have introduced most of the basic types of VDM-SL. However, we

would not be able to model many useful computing systems if these were all
we had. Type constructors build more complex types from simpler ones. For
example, strings can be represented as sequences of characters:

types

1 Strictly speaking, this is an extension to the ISO VDM-SL Standard, which states that
values of the token type cannot be inspected or constructed.



84 5 The Elements of a Formal Model

String = seq of char

using the sequence type constructor “seq of” applied to the basic character
type char2. Note also that the keyword types is used in the same way as
values above. In the following sections we will introduce some basic type
constructors. Chapters 6, 7 and 8 show how to model systems using the most
important type constructors in VDM-SL (sets, sequences and mappings).

5.5 Record types
If we wish to model the possibility that paths can be conflicting, we

need to consider pairs of paths. This is done by introducing a type Conflict
which models two paths that are in conflict with each other:

Conflict :: path1: Path
path2: Path

This is a record type with two fields. Note that this type definition uses “::”
instead of the equality symbol used in the other type definitions above. This
notation indicates that all values belonging to the type contain a tag holding the
name of the type. The presence of a tag allows us to define a constructor operator
for the tagged type. The constructor is written mk tag, where tag is the name in
the tag. In the traffic light example, the constructor is called mk Conflict, so
one particular conflict value could be written as follows:

mk_Conflict(mk_token("A1North"),mk_token("A66East"))

Given the value definitions in Section 5.3.3 above, this conflict could also be
written as

mk_Conflict(p1,p3)

The “mk” operator is known as a record constructor.

Given a record, it is possible to extract the value of a field using the “dot” nota-
tion. For example, given a conflict con, the first path is given by “con.path1”.
An expression using the dot notation is called a field selection expression. In ad-
dition one can use is-expressions to test whether an expression is of a certain
record type. The syntax for this is is Conflict(c) where c is an expression
and if it is of the Conflict record type this expression would yield true.

2 The character values that can be used in VDM-SL are listed in Appendix Appendix A
on page 238.



5.6 Invariants 85

Modelling the kernel We now make a first attempt at the model for the kernel.
There are two components: the current status of the lights and the information
about the paths that conflict:

Kernel :: lights : ???
conflicts : ???

Which types could we use for these two fields? The conflicts component is
just a set of Conflicts:

Kernel :: lights : ???
conflicts : set of Conflict

while the lights component is a mapping relating each Path to the Light
on that path:

Kernel :: lights : map Path to Light
conflicts : set of Conflict

This definition uses mapping and set types, discussed in detail in Chapters 8
and 6 respectively. For the junction shown in Figure 5.2 the set of conflicts is

{mk_Conflict(p1,p3), mk_Conflict(p1,p4),
mk_Conflict(p2,p3), mk_Conflict(p2,p4),
mk_Conflict(p3,p1), mk_Conflict(p3,p2),
mk_Conflict(p4,p1), mk_Conflict(p4,p2)}

and the current setting of the lights could be

{p1 |-> <Red>,
p2 |-> <Red>,
p3 |-> <Green>,
p4 |-> <Green>}

5.6 Invariants
It is often necessary to express the property that only certain values of a

defined type should arise in a model. For example, we may wish to record that
a path may not be in conflict with itself. Such additional restrictions on a type
are recorded as data type invariants in VDM-SL.

For both of the record types introduced above it would be appropriate to write
an invariant. For Conflict we would like to record that a path cannot be in
conflict with itself. The type definition would then be changed to

Conflict :: path1: Path
path2: Path

inv mk_Conflict(p1,p2) == p1 <> p2



86 5 The Elements of a Formal Model

The invariant is defined by giving the properties of a typical element of the
type. After the “inv” keyword, we name a typical value and then describe the
restrictions on that value as a logical expression. In the example above, the
typical value is given by a pattern which matches the structure of the values
belonging to the type. The mk Conflict(p1,p2) part is called a record
pattern and it can be used whenever we know that a parameter value will have a
similar structure. In this case, we know that elements from the conflict type will
be tagged by the name Conflict and have two components. The identifiers
p1 and p2 can then be used by the right-hand side of the definition sign == to
formulate the desired logical expression.

An equally good alternative is to give the name for a whole Conflict and
use the dot notation to retrieve the fields from it:

inv con == con.path1 <> con.path2

When an invariant is defined on a type T, a truth-valued function inv T is au-
tomatically generated “for free”. Consider a typical type definition of the form

T = Rep
inv t == P(t)

The function inv T takes as input any value belonging to Rep and returns
a Boolean expression which is true if the invariant holds on it and false oth-
erwise. For the Conflict data type, the invariant yields a function called
inv Conflict which takes as input a conflict record and returns a Boolean.

Exercise 5.1 The file traffic.vdm contains the definitions presented in
this chapter. Configure VDMTools Lite with this file and check whether all of
the values from the conflicts set satisfy the automatically generated invari-
ant function for the Conflict type. Hint: use a quantified expression to check
this. Remember to initialise your model in the interpreter before executing any
functions. �

For the Kernel type we could express the property that, for all conflicting
paths, the lights must be known in the lights mapping:

Kernel :: lights : map Path to Light
conflicts : set of Conflict

inv mk_Kernel(ls,cs) ==
forall c in set cs &

c.path1 in set dom ls and
c.path2 in set dom ls

In addition it is required that one of the lights in such a conflicting path must be
red. Adding this restriction, we get



5.7 Explicit function definitions 87

Kernel :: lights : map Path to Light
conflicts : set of Conflict

inv mk_Kernel(ls,cs) ==
forall c in set cs &

c.path1 in set dom ls and
c.path2 in set dom ls and
(ls(c.path1) = <Red> or ls(c.path2) = <Red>)

A universal quantifier is used to express this here. The dot notation is used to
obtain the two different paths from a conflict value c.

Exercise 5.2 Before you read on, strengthen the invariant for Kernel by
adding the constraint that the set of conflicting paths is symmetric (i.e. if p1 is
in conflict with p2 then p2 is also in conflict with p1). �

For the Time type it would also be appropriate to introduce an invariant.
Under the assumption that we are not interested in negative numbers the type
definition should be

Time = real
inv t == t >= 0

Thus, any value t which belongs to the type Time is a real number and t
satisfies the predicate t >= 0.

Our experience in a number of industrial projects has been that
writing invariants is one of the most valuable activities in con-
structing a system model, because it encourages developers to
record and explicitly question properties which would otherwise
be assumed. This is particularly valuable in dealing with safety-
related constraints.

5.7 Explicit function definitions
Using only the basic operators can be tedious and repetitious, especially

in large formal models or with complex data types. It is often desirable to define
operators specifically for the model under development. In this section we look
at one way of defining such operators – as functions.

A function takes a number of arguments and produces a single result. For
any set of actual arguments, a function returns only one result. Functions may,
however, be partial. An explicit function definition in VDM-SL has the following
form:

f: T1 * T2 * ... -> T
f(p1, p2, ... ) == expression-defining-result



88 5 The Elements of a Formal Model

pre logical-expression

and it has the following parts:

• The signature giving the name of the function, types of formal parame-
ters and result (f: T1 * T2 * ...-> T);

• The parameter list, naming the parameters to the function using patterns
which are usually simply names ((p1, p2, ... ));

• The function body, which is an expression in terms of the parameters,
value definitions and other function definitions, evaluating to the result
(expression-defining-result); and

• The pre-condition, which is a logical expression that is true exactly for
those values where the function is defined (logical-expression).
The pre-condition may be omitted when the function is defined for all
possible input values.

The rest of this chapter gives examples of explicit function definitions. Func-
tions can also be defined implicitly, i.e. by means of a post-condition instead of
a function body. Implicit function definitions have already been introduced in
Chapter 2 but will not be discussed further until Chapter 6.

5.8 Functions for changing signals
In our traffic light example it would make sense to define functions for

changing the signals in a given path. We need three different functions for car-
rying out such changes. All of them will have a similar signature. That of the
function changing a signal to green is as follows:

ToGreen: Path * Kernel -> Kernel

This function will change the light to green in the given path and keep all the
other lights unchanged. The function will have a structure such as

ToGreen: Path * Kernel -> Kernel
ToGreen(p,mk_Kernel(lights,conflicts)) ==

mk_Kernel(ChgLight(lights,p,<Green>),conflicts)

using a record pattern in the parameter list and a record constructor expression
in the body. The function ChgLight updates the lights mapping so that the
path p now has the colour <Green>. We will defer the definition of ChgLight
to later in this section.

Exercise 5.3 Before reading on, define similar functions which change lights
to amber and to red. �



5.8 Functions for changing signals 89

5.8.1 Adding pre-conditions

The purpose of the traffic light kernel is to help avoid accidents, but
the light-changing functions have the potential to lead to hazards if they are
improperly used. Thus, each function must respect the safety requirements. Re-
strictions on the proper use of a function are documented using a pre-condition.
All the functions changing the light should, for example, require that the path is
known in the given traffic light controller kernel.

Let us start by considering the most dangerous function: changing a light to
green. From S2 it can be seen that it is only possible to make a transition to green
if the signal is already red. In addition we need to ensure that all the conflicting
paths are already red (let us not consider the timing requirements for now). A
first attempt at defining ToGreen is

ToGreen: Path * Kernel -> Kernel
ToGreen(p,mk_Kernel(lights,conflicts)) ==
mk_Kernel(ChgLight(lights,p,<Green>),conflicts)

pre p in set dom lights and
lights(p) = <Red> and
forall con in set conflicts &

(con.path1 = p => lights(con.path2) = <Red>) and
(con.path2 = p => lights(con.path1) = <Red>)

The pre-condition has three conjuncts. The first one checks that the path is
known about in the traffic light controller. The second states that we can only
move to green from red, and the third states that all the conflicting paths must
be red. However, since the invariant for the Kernel type should state that the
set of conflicting paths is symmetric (see Exercise 5.2) the final conjunct inside
the universal quantification is not needed. This simplification will be used at a
later stage in this chapter.



90 5 The Elements of a Formal Model

On data type invariants
Why do we write data type invariants? After all, if some con-
straint is to be respected by all the values that can arise in a
model, couldn’t we simply ensure that each function and value
definition only ever produces such valid values, perhaps using
pre-conditions to help ensure this? In fact, we could take such
an approach, but it is fraught with danger. It is important to
remember that models evolve over time, just as computer pro-
grams do. They go through many versions and are subjected
to updates and revisions. As these changes happen, it is impor-
tant to ensure that the constraints placed on data types when the
model was formulated remain in force. If we do not record these
conditions explicitly, we run the risk that they are forgotten and
go unchecked when changes are made. Invariants serve this im-
portant purpose by, at a single point, stating all the conditions
that must hold on data values.
Two useful checks can be performed to gain confidence that the
pre-conditions and invariants are chosen optimally, and do not
contain redundancy:

• If part of a pre-condition is already implied by the in-
variants on the types of the inputs, that part of the pre-
condition can be removed.

• If there is a conjunct which is common to all the pre-
conditions of functions using a particular input type, it
may be worth considering adding that restriction as an
invariant on the type rather than repeating it in all the
function definitions.

The structures of the functions describing the other two state transitions are
the same as that of ToGreen except that no check on the status of conflicting
paths is required. Thus, we get

ToRed: Path * Kernel -> Kernel
ToRed(p,mk_Kernel(lights,conflicts)) ==

mk_Kernel(ChgLight(lights,p,<Red>),conflicts)
pre p in set dom lights and lights(p) = <Amber>

and

ToAmber: Path * Kernel -> Kernel
ToAmber(p,mk_Kernel(lights,conflicts)) ==

mk_Kernel(ChgLight(lights,p,<Amber>),conflicts)



5.8 Functions for changing signals 91

pre p in set dom lights and lights(p) = <Green>

Finally let us consider the auxiliary function ChgLight:

ChgLight: (map Path to Light) * Path * Light ->
(map Path to Light)

ChgLight(lights,p,colour) ==
lights ++ {p |-> colour}

The ++ operator is used for overwriting one mapping with another. In this case
the resulting mapping will have the new colour for the given path p. We will
explain the operations on mappings in much more detail in Chapter 8.

Now we have developed a basic model for the key functions of the kernel.
However, we have not yet taken the timing constraints into account.

5.8.2 Adding timing constraints

In order to take the timing constraints into account we must assume
that we have defined the constants RedClearance, MinimumGreen and
AmberChange as value definitions in VDM-SL:

RedClearance : Time = 2.6;
MinimumGreen : Time = 1;
AmberChange : Time = 2.6

The actual values used here are arbitrarily chosen within the limits provided in
the United States standards for traffic lights with the unit of time being seconds.
Note that in each value definition the type of the construct is also supplied.

In addition to these definitions we need to add a field called lastch to keep
track of the last time the light on each path has been changed. Furthermore, the
functions for changing the signals in a given path must also take the time as an
argument.

The data model of the kernel is as follows:

Kernel :: lights : map Path to Light
conflicts : set of Conflict
lastch : map Path to Time

inv mk_Kernel(ls,cs,lc) ==
dom ls = dom lc and
forall c in set cs &

mk_Conflict(c.path2,c.path1) in set cs and
c.path1 in set dom ls and
c.path2 in set dom ls and
(ls(c.path1) = <Red> or ls(c.path2) = <Red>)



92 5 The Elements of a Formal Model

where the lastch component has been added and the invariant has been ex-
panded slightly, requiring the two mappings to have the same domain. In addi-
tion the result from Exercise 5.2 has been incorporated.

In the test data we will wish to define initial settings for the lights, i.e. that
they were changed to some initial settings at time zero (recall that Time is
defined as real numbers from zero upwards in Section 5.6). The initialisation
can be described in a value definition as follows:

lastchanged : map Path to Time
= {p1 |-> 0,p2 |-> 0,p3 |-> 0,p4 |-> 0}

The full traffic light controller value can be built from the components de-
scribed so far. The value definition would take the form

kernel : Kernel
= mk_Kernel(lights,conflicts,lastchanged)

The function which describes changing the light in a path to green now addi-
tionally involves ensuring that lights for all conflicting paths have been red for
at least the RedClearance interval. The ToGreen function can be changed
to

ToGreen: Path * Kernel * Time -> Kernel
ToGreen(p,mk_Kernel(lights,conflicts,lastch),clock) ==

mk_Kernel(ChgLight(lights,p,<Green>),conflicts,
ChgTime(lastch,p,clock))

pre p in set dom lights and
lights(p) = <Red> and
forall mk_Conflict(p1,p2) in set conflicts &

(p = p1 => (lights(p2) = <Red> and
RedClearance <= clock - lastch(p2)))

where the current time has been added as an extra parameter in the function
signature and in the parameter list. Here we have introduced another auxiliary
function called ChgTime for changing the lastch mapping to the current
time clock. This is defined in a way similar to the ChgLight function, but
we defer its definition to later in this section. The RedClearance delay has
been incorporated in the pre-condition as well. Note that this time we have used
a record pattern mk Conflict(p1,p2) directly in the quantified expression.
This can be done because elements from conflicts have this structure and

thus a pattern matching of each of the elements will take place in the universal
quantification expression. In case the value of a field in a record pattern is not
relevant to the remaining part of the expression it is possible to use a “don’t
care” pattern which is written as a dash; see the alarm example on page 26.

The ToRed function is changed in the same way:



5.8 Functions for changing signals 93

ToRed: Path * Kernel * Time -> Kernel
ToRed(p,mk_Kernel(lights,conflicts,lastch),clock) ==
mk_Kernel(ChgLight(lights,p,<Red>),conflicts,

ChgTime(lastch,p,clock))
pre p in set dom lights and lights(p) = <Amber> and

AmberChange <= clock - lastch(p)

For the ToAmber function it is tempting to make a similar change, this time
using MinimumGreen. However, since it should be possible to overrule the re-
quirement about a minimum time for the signal to be green, this timing require-
ment does not belong in the safety kernel and thus ToAmber is only changed for
the lastch component. Recall that the purpose of this model is to define the
functionality of the safety kernel and that we therefore concentrate on modelling
only those areas of functionality relevant to the kernel.

ToAmber: Path * Kernel * Time -> Kernel
ToAmber(p,mk_Kernel(lights,conflicts,lastch),clock) ==
mk_Kernel(ChgLight(lights,p,<Amber>),conflicts,

ChgTime(lastch,p,clock))
pre p in set dom lights and lights(p) = <Green>

Finally let us consider the auxiliary function ChgTime:

ChgTime: (map Path to Time) * Path * Time ->
(map Path to Time)

ChgTime(lastch,p,tim) ==
lastch ++ {p |-> tim}

The ++ operator is again used for overwriting one mapping with another. In this
case the resulting mapping will have the new tim for the given path p.

5.8.3 Combining the kernel functions

In the model developed so far, we have defined a separate function for
each possible change of colour in the lights. This means that the interface to
the traffic light kernel has at least these three functions. It might be considered
advisable to limit the size of the interface to the kernel and this could be done
by introducing a single function to permit any allowable change of lights. Call
this function ToColour. In addition to using the path, controller and time as
parameters for the different functions for changing the lights, the ToColour
function takes as input an indication of the colour the light should change to.
The signature for this function is

ToColour: Path * Kernel * Time * Light -> Kernel



94 5 The Elements of a Formal Model

Depending upon the value of the Light parameter, we would simply apply the
appropriate function already defined. To do this we use a cases expression. A
first version of the ToColour function definition could be

ToColour: Path * Kernel * Time * Light -> Kernel
ToColour(p,con,clock,light) ==

cases light:
<Red> -> ToRed(p,con,clock),
<Amber> -> ToAmber(p,con,clock),
<Green> -> ToGreen(p,con,clock)

end

The cases expression in VDM-SL is similar to those found in programming
languages except that the alternatives can be patterns (see page 262) and not
simply constant values such as <Red>, <Amber> and <Green> as used in
the present example. The value of light determines which of the alternatives
is chosen. However, ToColour is not always able to deliver an appropriate
result.

Since it uses the other functions, it is the responsibility of ToColour to en-
sure that the pre-conditions of the called functions are satisfied. Thus, we need
to supply a pre-condition for ToColour which is sufficiently strong to guaran-
tee this. It would be irritating to have to repeat all the logical expressions used
for defining the pre-conditions for the other functions. Worse, it would be a haz-
ard for maintenance and a possible source of defects as the model evolves (see
the advice on invariants in Section 5.8.1).

VDM-SL provides a feature known as pre-condition quotation which pro-
vides a convenient means of referring to pre-conditions. Recall that the defini-
tion of an invariant generates a Boolean function that can be used to invoke the
invariant elsewhere in the model. In the same way, defining a pre-condition gen-
erates a Boolean function “for free”. The function’s signature has the same input
types as the function on which the pre-condition is defined, and the return type
is bool. In the traffic light example, the pre-condition on the ToRed function
gives rise to the following function:

pre_ToRed: Path * Kernel * Time -> bool

Pre-condition quotation is the use of the pre-condition function. The function
ToColour can make use of pre-condition quotation as follows:

ToColour: Path * Kernel * Time * Light -> Kernel
ToColour(p,con,clock,light) ==

cases light:
<Red> -> ToRed(p,con,clock),
<Amber> -> ToAmber(p,con,clock),



5.8 Functions for changing signals 95

<Green> -> ToGreen(p,con,clock)
end

pre ((light = <Red>) => pre_ToRed(p,con,clock)) and
((light = <Amber>) => pre_ToAmber(p,con,clock)) and
((light = <Green>) => pre_ToGreen(p,con,clock))

Notice how a combination of conjunction and implication is used to formu-
late the pre-condition of ToColour. For large models this is normally a very
valuable way of documenting the assumptions made by a function. Notice also
the careful use of bracketing to ensure that the pre-condition has the intended
meaning.

In this example the different case selectors <Red>, <Amber> and <Green>
are constant values. The cases expression in VDM-SL is actually more powerful
because each of these can be arbitrary patterns which then are matched against
the selector value. We will return to this in Exercise 6.15.

Exercise 5.4 Configure VDMTools Lite with the traffic.vdm file. Syn-
tax check the file and start up the interpreter feature. Initialise the example and
type print ToGreen(p1,controller,8) in the Dialog part of the in-
terpreter window. Activate the pre-condition checking option in the interpreter
by choosing the interpreter item in the Options pull-down menu. Execute the
same call. What does the result indicate? �

Exercise 5.5 Call the pre-conditions for the functions in the model with the
inputs (p1,controller,8) as in the previous exercise. What can you con-
clude from the results? Try changing p1 to p3 in the input and see whether any
of the pre-conditions are satisfied. What does the result indicate? �

Exercise 5.6 In order to see how the traffic light controller kernel can evolve
over time you can try calling the light changing functions one after each other.
In order to refer to the result of the previous call, you can write $$. Provide a
list of calls which may change the initial traffic light. �

Exercise 5.7 Set the invariant checking option in the interpreter options menu.
Can you construct a call to one of the defined functions which breaks an invari-
ant? �



96 5 The Elements of a Formal Model

5.9 Reviewing the safety requirements
Having constructed a model for the traffic light kernel we need to anal-

yse whether the model satisfies the safety requirements S1 to S3 from Sec-
tion 5.2. Below we argue, for each of them, why they have been respected
in the model. In Chapter 10 we will return to more rigorous ways of validating
and verifying such requirements.

S1 It must always be the case that if a pair of paths conflict then the light associ-
ated with one of the paths is red. Considered in the invariant of the Kernel
type.

S2 Before a light is allowed to change from Red to Green, there must have been
a delay of RedClearance seconds after the lights in all conflicting paths turn
Red. Considered in the pre-condition of the function ToGreen.

S3 There must be a delay of AmberChange seconds after the light turns Amber
before the light is allowed to change from Amber to Red. Considered in the
pre-condition of the ToRed function.

5.10 Optional types: modelling failure behaviour
As we construct a model we use abstraction to suppress details not rel-

evant to the model’s purpose. In the model of the traffic light controller kernel
which we have provided above, we have abstracted away from failure behaviour
of the hardware associated with the system.

If we wanted to be able to represent the condition that, for example, the light
is dark due to a power failure or a broken bulb, an extra quote type <Dark>
could be added as a union to Light in a new type definition which we call
FallibleLight.

Light = <Red> | <Amber> | <Green>;

FallibleLight = Light | <Dark>

Alternatively, it is possible to use a type constructor letting us model the absence
of a physical light value. Then the FallibleLight type will look like

FallibleLight = [Light]

The square brackets surrounding the previous type definition are the optional
type constructor. Using this adds the special value nil to the elements from
the argument types. In this case we model the fact that the light is not working
by using the special nil value. Thus, it represents the situation where the light



5.10 Optional types: modelling failure behaviour 97

has failed. Equality, inequality and type membership are defined for nil. For
example, the following expression is true:

nil <> <Red>

On modelling failure
Many “textbook” formal models restrict themselves to describ-
ing normal behaviour. The model of the kernel discussed in the
main part of this chapter did not incorporate faults because it
was not considered to be important for the safety requirements
of the kernel in the US standard. However, for many systems
that are critical to safety, security, a business or a mission, it is
just as important to model faulty behaviour as the normal case.
This can be done in order to better understand the consequences
of a failure or to build tolerance of faults into the system design.
In any modelling activity, consider the often implicit assump-
tions being made about the correct functioning of components,
and bear the limitations of the model in mind.
Naı̈ve system models often confine themselves to describing the
computer system under construction. However, computer sys-
tems are almost never self-contained – they live in a context and
it only makes sense to talk about their dependability in certain
contexts. We find that most, if not all, major computer system
failures are related to mistaken assumptions about the context
and the ways in which it can behave and fail. The context is
not only the computing and physical environment, but also the
users, organisations and even societies that surround a comput-
ing system. If we wish to use formal modelling to build de-
pendable systems, we have to start by modelling the operating
environment as well as the technical system itself, its normal
and its abnormal behaviour.

Summary
In this chapter we have introduced the basic types, including quote

types, numeric types, characters and tokens, from which more sophisticated
models can be constructed. The fundamental type constructors used for build-
ing union, product and record types have also been illustrated. We have seen
how restrictions can be defined on data types, by means of invariants, and on



98 5 The Elements of a Formal Model

functions, by means of pre-conditions. The modelling of failure by means of
optional types has been introduced.

• Quote types are used in combination with union types in order to build
for enumerated types.

• There are five kinds of numeric types: nat, nat1, int, rat and
real. The usual arithmetic and comparison operators are described
in Subsection A.4.2.

• The token type is often used as an abstraction for identifiers. In princi-
ple, values of the token type have no internal representation, although
we compromise on this requirement in order to refer to them in tools.

• Record types have a number of fields which can be selected. Records
have special constructor expressions and can be decomposed into the
fields using record patterns.

• Invariants can be added to all type definitions. These put extra restric-
tions on the values which belong to a type.

• Explicit function definitions have four parts: a signature with the types
of the function, a parameter list, a function body and optionally a pre-
condition describing when the function is defined.

• Value definitions are made with a name for the value, its type and its
actual value.

• Both data type invariants and function pre-conditions give rise to Boolean
functions that may be used elsewhere in the model. This gives some pro-
tection against unanticipated consequences of changes during the evo-
lution of the model.

• It can be as important to model abnormal behaviour as to model normal
functioning. This is especially true if we wish to explore the conse-
quences of failures or to design fault tolerance into a system.



6
Sets

Aims
The aim of this chapter is to show how unordered collections of values

can be modelled as sets. The set type constructor and set operators in VDM-
SL are introduced via an example of a safety-related system. On completion of
this chapter, the reader should be confident in the use of sets and the associated
operators in models of systems involving collections of values.

6.1 Introduction
This is the first of three chapters that describe ways of modelling col-

lections of data values. The three collection types covered (sets, sequences and
mappings) describe progressively more structured collections. For each collec-
tion type, we will show how collections may be expressed

A formal model of a computing system should be sufficiently abstract to
model the system properties of interest, and not so concrete that a great deal
of irrelevant detail has to be tackled in order to understand or analyse the model.
Modelling languages such as VDM-SL contain a number of features supporting
such abstraction. One of the most fundamental is the facility to model sets of
values without being concerned about the order in which they are stored.

A set is an unordered collection of values. For example, the collection of
names

John, Peter, Edna, Alison

is a set. The order of presentation is not important, so it is the same set as

Alison, Peter, John, Edna

Duplication is also not significant, so another presentation of the same set is

Alison, John, Peter, Edna, Peter, Alison, Alison, John

In VDM-SL, collections of values which form a set are presented in braces, so
the following expression is a set (of strings of characters) in VDM-SL:

{"Alison", "John", "Edna", "Peter"}

99



100 6 Sets

The empty set is represented as {}.
Sets can contain values of any type, even other sets. For example, the follow-

ing expression represents a set of sets of numbers:

{ {9, 13, 77}, {32, 8}, {}, {77}}

When to use sets
Sets are used to model collections of values, but they are abstract in

the sense that ordering and duplication of the elements do not affect the set
itself. We therefore use sets in situations where ordering and duplication are
not relevant for the purposes of the model. Here are some examples of system
models where the decision about whether or not to use a set is important:

An air traffic control database containing information about the positions and
identifiers of aircraft in an air space. Suppose a model of the database is to
be developed in order to clarify the functionality of some software used to
plot possible future movement of aircraft and avoid close approaches. Two
identical records are giving the same information twice (since the records
contain the aircraft identifiers) and there is no inherent ordering among the
records so the use of a set is appropriate.

An airport departures display Suppose the purpose of a model of the departures
display at an airport is to clarify the rules for updating the display. Here, the
order may be deemed to be significant, in that the order of flights should be
preserved when the screen is updated. A sequence might be a more appropri-
ate abstraction than a set here.

A secure area controller This controller keeps track of who is in a controlled
area. If the model does not involve tracking the order in which people arrive
and leave, then the model would contain a set of identifiers for the people in
the area. If the order of arrival is important, then a sequence might be more
appropriate here too.

6.2 The set type constructor
Given a type T, the type of sets of elements of T is written

set of T

Thus, the set of natural numbers {1, 5, 7} belongs to the type set of
nat.



6.3 Defining sets 101

As with all the collections types (sets, sequences and mappings), the elements
of the collection are homogeneous: they all have the same data type. If they are
derived from several data types, this presents no problem: the type of the set is
built from the union of the constituent elements’ types. For example, if we had
a set consisting of natural numbers and, say, real numbers, it would be of type

set of (nat|real)

6.3 Defining sets
There are three ways of defining sets: enumerating the elements; select-

ing a subrange from the integers; and using set comprehension to generate a set
containing all values which satisfy a predicate.

Enumeration A set with just one element, e.g.

{45}

is called a singleton set. The elements of the set are listed in no particular order,
separated by commas, e.g.

{45, 77, 8, 32, 9, 13}

Subranges Obviously enumeration is not suitable for large sets. Where the ele-
ments of a set come from the integer type int, the expression

{integer1, ..., integer2}

represents the set of integers greater than or equal to integer1 and less than
or equal to integer2. Thus, for example,

{12, ..., 20}

represents the integers from 12 to 20 inclusive, i.e.

{12, ..., 20} = {12, 13, 14, 15, 16, 17, 18, 19, 20}

Exercise 6.1 What is the value of the subrange

{integer1, ..., integer2}

when integer1 = integer2, e.g. {12,...,12}? Try evaluating such
an expression in VDMTools Lite to see whether you are correct. Note that it is
possible to interpret expressions such as these which do not use any definitions



102 6 Sets

from a VDM-SL model directly in the interpreter’s Dialog part with the print
command.

What happens if integer2 < integer1, e.g. {9,...,3} ? �

Comprehension This is the most powerful way to define a set. The form of a set
comprehension is

{ value-expression | binding & predicate }

The binding binds one or more variables to a type or set, just as with the logical
quantifiers. The predicate is a logical expression using the bound variables.
The value-expression is also an expression using the bound variables but
this expression defines a typical element of the set being constructed. The com-
prehension represents the set of all values of the value expression for each pos-
sible assignment of values to the bound variables for which the predicate is true.
For example, the comprehension

{x**2 | x:nat & x < 5}

represents the set of all values of x**2, where x is a natural number such that
x is less than 5, i.e.

{x**2 | x:nat & x < 5} = {0**2,1**2,2**2,3**2,4**2}
= {0,1,4,9,16}

Exercise 6.2 Evaluate the following by hand and check your answer by eval-
uating them in VDMTools Lite:

{x | x in set {1,...,15} & x < 5}

{y | y in set {1,...,20} &
exists x in set {1,...,3} & x*2 = y}

{x+y | x,y in set {1,...,4}}

�

It is possible to think of set comprehensions in terms of their execution. Begin
by considering all the values in the binding, then ask whether each of them
satisfies the predicate (think of the predicate as filtering out unwanted values).
For each value satisfying the predicate, evaluate the value expression, and place
the outcome in a result set.



6.4 Modelling with sets 103

As mentioned in Chapter 4, expressions with type bindings cannot be exe-
cuted by VDMTools Lite because of the need to range over a potentially infinite
class of values. As a result set comprehensions with type bindings generate
Run-Time error messages in the interpreter.

Comprehension is a valuable technique for expressing collections of values.
Further examples of set comprehension will occur in the main part of this chap-
ter, along with advice on how to build comprehension expressions.

A note on finiteness All sets in VDM-SL are finite. However, the predicate
in a set comprehension might be satisfied by infinitely many values. If this is
the case, the set comprehension expression is not well-defined. For example,
the following comprehension expression contains a predicate satisfied by all the
natural numbers greater than 10:

{x | x:nat & x > 10}

To define an infinitely large collection of values, define a type rather than a set
and define an invariant to restrict the type as required, e.g.

BigNats = nat
inv x == x > 10

6.4 Modelling with sets
6.4.1 The explosives store controller example

In this chapter, the basic features of sets are introduced by means of
a case study inspired by the work of Paul Mukherjee and Victoria Stavridou
[Mukherjee&93] who formulated a VDM-SL model for the control of explo-
sives stores, based on United Nations regulations. Their model describes the
structure of an explosives store consisting of a range of different buildings con-
taining explosive objects. The positions, orientations and strength of the build-
ings are modelled, as are the positions and explosive characteristics of the ob-
jects. Here we will look at a simplified part of the problem: positioning objects
in stores. An informal requirements description is given below.

The system to be modelled is part of the controller for a robot which positions

explosives such as dynamite and detonators in a store.

The store is a rectangular building. Positions within the building are

represented as coordinates with respect to one corner which is designated the

origin. The store’s dimensions are represented as maximum x and y coordinates.



104 6 Sets

Figure 6.1 Example store with rectangular objects

x

y

xbound

ybound

o.position

o

o.xlength

o.ylength

Objects in the store are rectangular packages, aligned with the walls of the

store (see Figure 6.1). Each object has dimensions in the x and y directions. The

position of an object is represented as the coordinates of its lower-left corner. All

objects must fit within the store and there must be no overlap between objects.

The positioning controller must provide functions to

1. return the number of objects in a given store;

2. suggest a position where a given object may be accommodated in a

given store;

3. update a store to record that a given object has been placed in a given

position;

4. update a store to record that all the objects at a given set of positions

have been removed.

The purpose of the formal model to be developed here is to help fix the rules
for the safe positioning of objects within the store. The model therefore concen-
trates on representing objects, positions and the bounds of the store.



6.4 Modelling with sets 105

6.4.2 The explosive store controller’s data model

The description suggests that a store has various component parts: its
contents and upper bounds in x and y directions. This leads us to consider
modelling stores by means of a record type:

Store :: contents : ???
xbound : ???
ybound : ???

Consider each component in turn. The contents are a collection of objects. We
are not concerned about any ordering among the objects, so a set would appear
to be an appropriate abstraction:

Store :: contents : set of Object
xbound : ???
ybound : ???

Carrying on with Store, the distances are all measured to the nearest whole
unit, so we shall model the bounds as positive natural numbers:

Store :: contents : set of Object
xbound : nat1
ybound : nat1

Now we take the type Object further. We can tell from the problem require-
ments that an object has a position (a point in space) and that it has dimensions
in the x and y directions. Again, this suggests a record type definition:

Object :: position : ???
xlength : ???
ylength : ???

The position is a point in two-dimensional space. We could model points as
records with x and y coordinates (natural numbers):

Point :: x : nat
y : nat

Then an object is modelled as follows:

Object :: position : Point
xlength : nat1
ylength : nat1

As usual, it is necessary to ensure that any additional restrictions on the types
defined are recorded in invariants. Two conditions relate to the store: that all
the objects are within the bounds of the store and that no objects overlap. Both
of these restrictions relate to the contents of a store, and so they should be



106 6 Sets

recorded in an invariant on the Store type. Store’s type definition then takes
the following form:

Store :: contents : set of Object
xbound : nat1
ybound : nat1

inv mk_Store(contents, xbound, ybound) ==
objects fit within bounds of the store
and
no two distinct objects overlap

where a record pattern has been used to define the typical element in the invari-
ant. It is not immediately clear how the clauses of the invariant will be expressed.
In such a situation, it often best to break the modelling task down by formalising
the main concepts used in each part of the invariant as auxiliary functions. Here,
for example, one could define a function (called InBounds, say) returning a
Boolean value true if a given object fits within the bounds of a given store, and
a function (called Overlap, say) which returns true if two objects overlap.
Given these functions, the invariant could be defined as follows:

Store :: contents : set of Object
xbound : nat1
ybound : nat1

inv mk_Store(contents, xbound, ybound) ==
forall o in set contents & InBounds(o,xbound,ybound)
and
not exists o1, o2 in set contents &

o1 <> o2 and Overlap(o1,o2)

Note the “o1 <> o2” conjunct which ensures we are checking two distinct
objects for overlap, and not comparing an object with itself. In Section 4.5 we
discussed why this is necessary.

Now we look in more detail at the auxiliary functions, starting with InBounds.
The function’s definition has the following form:

InBounds: Object * nat * nat -> bool
InBounds(o,xbound,ybound) == ???

The object o will be within the xbound if its position’s x component plus the
length is less than or equal to the bound. The comparison on the y bound is
similar and so the completed function definition is

InBounds: Object * nat * nat -> bool
InBounds(o,xbound,ybound) ==

o.position.x + o.xlength <= xbound and
o.position.y + o.ylength <= ybound;



6.4 Modelling with sets 107

Note that we have used <= in the comparisons, allowing objects to be placed up
against the edges of the store area. When modelling variables with discrete types
such as natural numbers, it is worth being careful about edge values, equality and
adjacency.

The second auxiliary function (Overlap) assesses whether or not two ob-
jects overlap. It would be possible to define a calculation on the coordinates and
dimensions of the two objects in order to determine whether their boundaries
cross at any point. This is likely to be quite a complex definition: we have to
consider all the possible ways in which objects could overlap or even be placed
within one another. If we want a simple description of the overlap property, we
can exploit the abstraction facilities of the modelling language and view objects
as sets of points. Then two objects overlap if they have any points in common.
We can first formalise the notion of the set of points associated with an object.
A suitable auxiliary function would have the following signature:

Points: Object -> set of Point

If we have two objects o1 and o2, they could be said to overlap if the two sets
Points(o1) and Points(o2) had any elements in common. To test for
this commonality, we use the intersection operator. Given two sets

s1, s2 : set of A

The set

s1 inter s2

is the collection of elements common to both s1 and s2. If there are no elements
in common, then

s1 inter s2 = {}

Exercise 6.3 Evaluate the following, checking your answers using VDM-
Tools Lite:

{89, 33, 5} inter {2, 9, 5}

{{<RD>, <RA>, <RB>}, {<RA>, <RB>}} inter {{<RB>}, {<RA>, <RC>}}

{x**x | x in set {10,...,15} & 2*x < 26} inter
{x**x | x in set {8,...,12} & 2*x < 25}

�

Returning now to the definition of two objects overlapping, o1 and o2 will
overlap if they have any points in common:



108 6 Sets

Points(o1) inter Points(o2) <> {}

The completed function definition is

Overlap: Object * Object -> bool
Overlap(o1,o2) ==

Points(o1) inter Points(o2) <> {}

This definition embodies a major abstraction. An implementation for this func-
tion would include an algorithm which checks whether the edges of objects cross
one another. Here, however, the model is sufficiently abstract for its purpose: it
states what constitutes an overlap without clouding the issue by presenting an
efficient algorithm for its computation.

It remains to complete the definition of Points. The set of points in an ob-
ject is precisely the set of points with coordinates within the object’s bounds. A
set comprehension will allow us to describe the set of all points satisfying the
constraint that they are within the bounds of the object. A point mk Point(x,y)
is in the object mk Object(pos,xlen,ylen) if its x coordinate is between
pos.x and pos.x + xlen inclusive and its y coordinate is between pos.y
and pos.y + ylen inclusive. Using set ranges, we can conveniently express
this as follows:

x in set {pos.x ,..., pos.x + xlen} and
y in set {pos.y ,..., pos.y + ylen}

The set of all the points in an object is given by a comprehension:

{mk_Point(x,y) | x in set {pos.x ,..., pos.x + xlen},
y in set {pos.y ,..., pos.y + ylen}}

and the overall function definition is

Points: Object -> set of Point
Points(mk_Object(pos,xlen,ylen)) ==

{mk_Point(x,y) | x in set {pos.x ,..., pos.x + xlen},
y in set {pos.y ,..., pos.y + ylen}}

A useful technique in forming a set comprehension is to begin by thinking of the
set of values one wishes to quantify over. Represent these by a binding. Then
consider whether it is necessary to limit this set and if so describe the character-
istics of the desired values in a predicate. Finally, form the value expression to
get the desired elements in the resulting set. In this example, the quantification is
over x and y drawn from the dimensions of the object, and there is no predicate.
The value expression is just the Point made from the x and y coordinates.

Exercise 6.4� A formal model can provide a useful basis for a consideration
of the intention in the informal requirements or system description. In the model



6.4 Modelling with sets 109

developed so far, the notion of overlapping has been defined precisely. Do you
think it has captured exactly the intention? In particular, does the formal model
allow two objects to be placed together, sharing a common side? Do you think
that this should be allowed? �

6.4.3 The controller’s functionality
Four main functions are required for this example:

1. to return the number of objects in a store,
2. to suggest a free space large enough to accommodate an object,
3. to record the placing of an object in a store and finally
4. to update a store by removing a collection of objects.

First, consider the function to return the number of objects in a store. A store
contains a set of objects, so this function simply returns the number of objects
in that set. The skeleton of the function is

NumObjects: Store -> nat
NumObjects(store) == ???

The number of elements in a set, called its cardinality, is obtained by applying
the card operator.

Exercise 6.5 Evaluate the following expressions by hand, comparing your
answers with those produced by VDMTools Lite:

card {1, 5, 7, 5, 3}

card {}

card {x*x | x in set {-5,...,3}}

�

The number of objects in store is given by the expression

card store.contents

The completed function definition is as follows:

NumObjects: Store -> nat
NumObjects(store) == card store.contents

The next function should suggest a position in a store where there is enough
space to house an object. The system description is not specific about which
point is to be suggested – any point with sufficient space available will do. Since



110 6 Sets

we need not be specific about exactly which result is returned, an implicit func-
tion definition is appropriate here. Recall from Chapter 2 that an implicit func-
tion definition characterises the result without giving a particular mechanism for
calculating it. An implicit function definition has three parts:

The function heading with the function name, the parameters and the result
identifier, each accompanied by their types;

The pre-condition which is a logical expression stating what assumptions are
made about the inputs to the function being defined; and

The post-condition which is a logical expression stating the relationship be-
tween the input parameters and the result which must hold after application
of the function.

A suitable function might have the following header:

SuggestPos(xlength,ylength:nat1, s:Store) p:Point

As in this example, it is possible to abbreviate the parameter list when several
adjacent parameters have the same type. The order of parameters is significant
in VDM-SL in that function applications use the same parameter order as the
declaration.

The header for SuggestPos above does not take account of the possibility
that there is no suitable position in the store. We modify the header using an
optional type constructor to allow the function to return the value nil in this
case:

SuggestPos(xlength,ylength:nat1, s:Store) p:[Point]

The body of the function has the following form:

SuggestPos(xlength:nat, ylength:nat1, s:Store) p:[Point]
post if there is room at a point

then p is a point where there is room
else p = nil

We are not interested in which of the positions is chosen, as long as there is
room at that position. This leaves freedom to an implementer to optimise the
suggested position in different ways. In the abstract formal model we are de-
veloping here we are interested in abstracting away from this optimisation and
this is expressed using looseness in the model – several functionally different
implementations will satisfy this post-condition.

The outline of SuggestPos above suggests that an auxiliary function could
usefully be defined to model the idea of there being sufficient room at a point:

RoomAt: nat1 * nat1 * Store * Point -> bool



6.4 Modelling with sets 111

The function will return true if a point p is within the bounds of a store s and
there is enough space to accommodate an object with the dimensions xlength
and ylength there without overlapping any other object in s. Let new o be
the object placed at the position p. Then new o is in the bounds of the store if

InBounds(new_o,s.xbound,s.ybound)

An overlap is present if there exists an object in the store which overlaps with
new o, i.e.

exists o1 in set s.contents & Overlap(o1,new_o)

The object will not interfere with anything else so long as there does not exist
an object in s.contents with which it overlaps, i.e.

not exists o1 in set s.contents & Overlap(o1,new_o)

So, re-using the auxiliary functions defined earlier, it is possible to complete the
definition of RoomAt:

RoomAt: nat1 * nat1 * Store * Point -> bool
RoomAt(xlength,ylength,s,p) ==
let new_o = mk_Object(p,xlength,ylength) in

InBounds(new_o,s.xbound,s.ybound) and
not exists o1 in set s.contents & Overlap(o1,new_o)

Here we have used a let expression to introduce an identifier new o as a local
name. The structure of this construct is

let pattern = defining-expression
in

use-expression

and this construct is evaluated as follows:

1. evaluate the defining-expression and match the result of that
against the pattern (in this case simply the identifier new o) and

2. evaluate use-expression, replacing each occurrence of the identi-
fiers from the pattern (in this case simply new o) in use-expression with
the value obtained in step 1.

Such let expressions can be used anywhere that expressions can be used – not
just in function bodies, but also in places such as set comprehension expressions.

It is now possible to complete the definition of SuggestPos. For the con-
dition in the if expression, it is necessary to state that there exists a position
which has room for the object:

exists pt:Point & RoomAt(xlength,ylength,s,pt)



112 6 Sets

The then part states that there is room at p, giving the completed function
definition as follows:

SuggestPos(xlength,ylength:nat1, s:Store) p:[Point]
post if exists pt:Point & RoomAt(xlength,ylength,s,pt)

then RoomAt(xlength,ylength,s,p)
else p = nil

The post-condition here is constrained to ensure that p is set to an appropriate
point only if there is room at p; otherwise it is set to nil. Note that a post-
condition of the form

post RoomAt(xlength,ylength,s,p) or p = nil

would be too weak.
In Chapter 5 it was illustrated how pre-condition quotation could be done. In

the same way it is possible to make post-condition quotation. However, for post-
conditions it is necessary to provide both the input and the suggested output;
then the predicate in the post-condition will be calculated using these values.
Thus the signature for post SuggestPos is

post_SuggestPos: nat * nat * Store * [Point] -> bool

This function is automatically produced and can be used in the interpreter of
VDMTools Lite.

The third function records the placement of an object at a position in the store,
returning the updated store:

Place: nat1 * nat1 * Store * Point -> Store
Place(xlength,ylength,s,p) == ???

The store is to be updated by adding the new o mentioned above to the set of
store contents. To add a value to a set we use the union operator. Given two
sets

s1, s2 : set of A

the set

s1 union s2

contains all the elements in s1 or s2 or both, and no more.
Exercise 6.6 Evaluate the following expressions by hand and test your re-

sults using VDMTools Lite:

{{1,5,6}, {1,3,3}} union {{12,7}, {1,3,3}}

{x | x in set {2,...,5} & x*x < 12} union
{x | x in set {-2,...,-5} & x*x < 12}



6.4 Modelling with sets 113

{2,...,10} union {}

�

The contents of the new store, with new o added, are given by the following
expression:

s.contents union {new_o}

The complete Place function returns the modified store, with the new contents,
leaving the bounds unchanged. The function has a pre-condition requiring that
there should be room at the chosen point:

Place: nat1 * nat1 * Store * Point -> Store
Place(xlength,ylength,s,p) ==

let new_o = mk_Object(p,xlength,ylength) in
mk_Store(s.contents union {new_o},

s.xbound,
s.ybound)

pre RoomAt(xlength,ylength,s,p)

The final function to be described models the removal of the objects at a given
set of points in the store. A possible signature is

Remove: Store * set of Point -> Store

The set difference operator is used to describe removal of elements from sets.
Given sets

s1,s2 : set of A

the set

s1 \ s2

is the set consisting of those elements of s1 which are not in s2. Elements of
s2 which do not occur in s1 have no effect. If there are no elements in common
between s1 and s2, the set difference evaluates to s1.

Exercise 6.7 Try evaluating the following expressions by hand and then
check your answers with VDMTools Lite:

{89, 33, 5} \ {5}

{89, 33, 5} \ {43, 5, 22}

{20,...,40} \ {2*x | x in set {10,...,20}}

�



114 6 Sets

Exercise 6.8 Set difference can be defined in terms of a set comprehen-
sion. Complete the following definition of the function SetDiff, which re-
turns s1\s2, using set comprehension rather than the “\” operator in the defi-
nition. Test your answer using VDMTools Lite:

SetDiff: set of nat * set of nat -> set of nat
SetDiff(s1,s2) == ???

�

Returning to the Remove function:

Remove: Store * set of Point -> Store
Remove(mk_Store(contents,xbound,ybound),sp) == ???

In order to define this function we need to be able to check whether a given point
belongs to the given set of points. This kind of check can be carried out using a
set membership operator. If a point p belongs to a set of points sp the expression
“p in set sp” will be true. Otherwise it will be false. The set of objects
represented by the given points can be described by a set comprehension using
the membership operator as a restricting predicate1:

{o | o in set contents & o.position in set sp}

These are the objects to be removed from contents, so the Remove function
can be defined as follows:

Remove: Store * set of Point -> Store
Remove(mk_Store(contents,xbound,ybound),sp) ==

let os = {o |o in set contents & o.position in set sp} in
mk_Store(contents \ os, xbound, ybound)

If some points in the input set sp do not correspond to the positions of objects,
then no objects for these points will make their way into os and so will not be
removed. Having some spurious points in sp therefore appears to be harmless.
Nevertheless, spurious points could be excluded by a pre-condition. We have a
subset operator for comparing two sets which can be used for this purpose. This
operator returns a Boolean result. A set s1 is a subset of another set s2 if all the
elements of s1 are also elements of s2. Thus, it holds that {} subset s for
any set s, and a set is always a subset of itself, i.e. s subset s. For Remove
we add the pre-condition giving the following:

Remove: Store * set of Point -> Store

1 Note that the first “in set” operator is a part of the binding whereas the second “in
set” is a logical operator taking two expressions as input, the second of which must
be a set.



6.5 Distributed set operators 115

Remove(mk_Store(contents,xbound,ybound),sp) ==
let os = {o |o in set contents & o.position in set sp} in
mk_Store(contents \ os, xbound, ybound)

pre sp subset {o.position | o in set contents}

Exercise 6.9 Try evaluating the following expressions by hand and then
check your answers with VDMTools Lite:

{89, 33, 5} subset {5}

{89, 33, 5} subset {43, 89, 5, 22, 33}

{20,...,40} subset {19,...,39}

�

Exercise 6.10 Configure VDMTools Lite with the file explo1.vdm, syn-
tax and type check it and initialise the interpreter. Construct a store value
mk Store({},7,15) which can be used to test the different functions. Re-
member that in order to refer to the result of the previous call you can write $$.
Note that, since SuggestPos is defined implicitly, it cannot be called directly,
but its post-condition can be quoted. In this case the post-condition itself is de-
fined using a type binding so, as explained in Section 4.5, it will not be executed
by VDMTools in this case. �

6.5 Distributed set operators
So far, we have seen how sets can be used to model collections of ob-

jects where ordering among values is not important. The means of expressing
sets (enumeration, subranges and comprehension) have been described, and we
have seen the basic set operators (intersection, union, cardinality, difference,
membership and subset) in use in the explosives store controller example. In
this section, we examine some of the more powerful, and more rarely used, op-
erators on sets which, instead of dealing with one or two sets, deal with whole
collections of sets at once. These are called distributed operators and we intro-
duce them by considering an extension to the controller.

Rather than dealing with a single store, the system is to be extended to provide

information on a site. A site is a collection of stores, each of which has a unique

name. The following additional functionality is to be provided to allow an

inventory to be taken over the whole site:



116 6 Sets

1. For a given site, provide a listing, in no particular order, of all the

objects in the site. For each object, give the label of the store in which it

is to be found and the object details already recorded.

This extension requires some modification to the data types defined so far
(adding names to stores, for example) and the addition of new types such as one
describing a site.

The Store data type is extended with a component modelling the name of
the store:

Store :: contents : set of Object
xbound : nat1
ybound : nat1
name : StoreName

inv mk_Store(contents, xbound, ybound, -) ==
forall o in set contents & InBounds(o,xbound,ybound)
and
not exists o1, o2 in set contents &

o1 <> o2 and Overlap(o1,o2)

The type StoreNamemodels the names given to stores. Note that, in the record
pattern used to define the typical element in the invariant, a “don’t care pattern”
has been introduced for the name component. This is to indicate to the reader
that this component has no effect on the predicate in the invariant.

For the purposes of modelling the functionality described, the details of the
particular representation of store names are immaterial, i.e. we abstract away
from their actual representation. Thus, the token type can be used:

StoreName = token

A new type to model a site is introduced. As no special ordering is required
among the stores, a set is used:

Site = set of Store

The store names are all required to be unique, so an invariant to this effect must
be added to the type definition. This states that, for any two stores, if their names
are the same, then they must be the same store (recall that two records are equal
only if they have the same values in the same fields):

Site = set of Store
inv site ==

forall st1, st2 in set site &
st1.name = st2.name => st1 = st2

An inventory is to be taken, consisting of a collection of items, each consisting
of the name of a store and the details of an object in the store. Observe from



6.5 Distributed set operators 117

the system description that the ordering of the items is not important, so the
inventory can be modelled as a set:

Inventory = set of InventoryItem;

InventoryItem :: store : StoreName
item : Object

The required functionality is to return the inventory for the whole site:

SiteInventory: Site -> Inventory

We will model the inventory for a single store and then consider its exten-
sion to the collection of stores which constitutes a site. Consider a function
StoreInventory which returns the inventory for a given store:

StoreInventory: Store -> Inventory
StoreInventory(store) == ???

The inventory here is the set of items formed from the name of the store (store.name)
and each object in store.contents. This set is expressed as a set compre-
hension:

StoreInventory: Store -> Inventory
StoreInventory(store) ==
{mk_InventoryItem(store.name,o) | o in set store.contents}

It is possible to construct the inventory for each store, but how can these be
combined to form the inventory for the whole set of stores in the site? The
union operator already introduced allows two sets to be combined, but here
it is necessary to gather a set of sets. The operator used for this purpose is a
distributed union, written dunion. Given a set of sets

ss: set of (set of A)

the set

dunion ss

is the single set containing all the elements of the sets in ss. If ss is empty,
dunion ss is the empty set.

Exercise 6.11 Try evaluating the following expressions by hand and com-
pare your answers with those given by VDMTools Lite:

dunion {{1, 3, 5}, {12, 4, 3} , {3, 5, 11}}
dunion {{3, 8, 15} inter {4, 9, 23}}
dunion {{x | x in set {1,...,y}} | y in set {3,...,6}}
dunion {{{1}},{1},{2}}

�



118 6 Sets

Returning to the inventory example, the inventory across the whole site is the
distributed union of the individual store inventories:

SiteInventory: Site -> Inventory
SiteInventory(site) ==

dunion {StoreInventory(store) | store in set site}

Exercise 6.12� For a given site, provide an inventory in the Inventory
format described in the requirements for SiteInventory above of all items
over a certain size, given the minimum size in the x and y directions. A possible
signature is

ListBigItems: Site * nat * nat -> Inventory

The items returned should be those items in the inventory of the site whose
xlength exceeds the first natural number argument and whose ylength ex-
ceeds the second. Write the body of the function as a set comprehension. Test
the function using VDMTools. Here the file explo2.vdm can be configured
with VDMTools where explo1.vdm is removed from the current project. This
file contains the definitions made so far for the distributed operators. �

There is a distributed version of the intersection operator. Written dinter,
this forms the intersection of all the sets in a given set of sets. For example,

dinter {{1, 3, 5}, {12, 4, 3}, {3, 5, 11}} = {3}

Notice an important but subtle point: the distributed intersection returns only
those elements in all of the sets of the collection. It does not return those ele-
ments which occur in two or more sets. Distributed intersection is partial: the
intersection of an empty set of sets is undefined. The distributed intersection of
a set of sets which includes the empty set is the empty set:

dinter {{1, 3, 5}, {7, 11}} = {}
dinter {{}, {2, 5, 6}} = {}

6.6 Summary
• Sets are finite collections of elements. Repetition and order of presen-

tation are not significant.
• Sets can be presented by enumeration, subrange or comprehension.
• Some operators on sets, such as distributed intersection, are partial.
• Special operators allow for distributed operations on sets of sets.
• In building a formal model, one strategy is to begin with a type repre-

senting a “high-level” component of the system and pursue a top-down



6.6 Summary 119

strategy, making new definitions of types and auxiliary functions as re-
quired.

Exercise 6.13 Evaluate the following expressions:

1. { x | x in set {2,3,4,5} & x>2 }
2. { x | x in set {2,3,4,5} & x**2 > 22 }
3. dunion {{1,2},{1,5,6},{3,4,6}}
4. dinter {{1,2},{1,5,6},{3,4,6}}

�

Exercise 6.14 Suppose that

s: set of (set of nat)

Write an expression to state that all the sets in s are pairwise disjoint (i.e. if you
choose two different sets from s they must not be overlapping). �

Exercise 6.15� In reality there is a serious risk associated with placing fuses
in close proximity to explosives. In this exercise, the model developed in this
chapter is extended to take account of this.

The rule for placement of fuses is that explosives may be placed next to explo-
sives and fuses next to fuses, but fuses must be at least 10 units from explosives.
We begin by defining two classes of objects: explosives and fuses. We define a
safe space around each object and modify the functions in the model so that an
object of one class may not be placed in the safe space around an object of the
other class.

1. Define an enumerated type Classwhich contains two values: <Expl>
and <Fuse>.

2. Redefine the type Object so that it has a field indicating the class of
the object.

3. Now we define the function

SafeSpace: Object * Object -> set of Point
SafeSpace(o,s) == ???

We could define the safe space around the object o as the set of points
with x coordinate from o.position.x - 10 up to o.position.y
+ 10. Here we will use a let expression as introduced on page 111 in
order to give a name to two rather complex subexpressions:



120 6 Sets

let xrange = {o.position.x - 10,...,o.position.x + 10},
yrange = {o.position.y - 10,...,o.position.y + 10}

in
{mk_Point(x,y) | x in set xrange,

y in set yrange}

Take some time to consider this model before reading on.
The problem arises if the object o is within 10 units of the wall of the
store. For example, if o is at mk Point(5,3) then some points in the
safe space would have negative coordinates, while we defined positions
as having natural number coordinates.
The modeller has a choice here. One approach would be to modify the
types of the coordinates to int in order to allow negative values. Here
we will follow a different approach which is to define functions to “cut
off” the safe space.
Given the function

Bottom: nat -> nat
Bottom(n) ==

if n < 10
then 0
else n - 10

define the function SafeSpace, so that the points returned are non-
negative.

4. Modify the definition of the function Overlap, so that it returns true
if the points in o1 and o2 have different classes and the SafeSpace
of o1 overlaps with the points in o2.

When all these types and functions have been defined, use VDMTools Lite to
check them. Use debugging for example with objects such as

mk_Object(<Fuse>,mk_Point(3,1),3,3)

and

mk_Object(<Expl>,mk_Point(12,4),5,4))

to check whether the definition of the function of the Overlap is adequate. �



7
Sequences

Aims
The aim of this chapter is to show how ordered collections of values can

be modelled as sequences. The sequence type constructor and sequence oper-
ators in VDM-SL are introduced via an example of a security-related message
processing system. On completion of this chapter, the reader should be confi-
dent in the use of sequences and the associated operators in models of systems
involving ordered collections of values.

7.1 Introduction
In Chapter 6 finite sets were introduced as a way of modelling collec-

tions of values in which ordering and the presence of duplicate values is not
significant. In this chapter, finite sequences are introduced as a way of mod-
elling collections where these two factors are relevant.

A sequence is a collection of values which are ordered in some way. In VDM-
SL, sequences are presented in square brackets, with elements separated by com-
mas. The following expression shows a sequence of values:

[<Red>, <Amber>, <Green>]

The order and duplication of elements is significant, so

[<Red>, <Amber>, <Green>] <> [<Red>, <Green>, <Amber>]

and

[<Red>, <Amber>, <Green>] <> [<Red>, <Green>, <Red>, <Amber>]

When to use sequences
Sequences are used to model finite collections of values where the order

in which the values are recorded is significant. We typically use sequences in
cases where values have to be dealt with in a certain order, or have some order
in their presentation, which must be preserved. Here are some examples of

121



122 7 Sequences

system models in which the decision about whether or not to use a sequence is
important:

Email addresses An Email address such as J.Bloggs@newcastle.ac.uk
typically contains domain information (the user name, the area, the network
and the domain) which has to be presented in the correct order. A model of
an Email router could have to treat these components in order, and hence the
ordering is significant. We could model Email addresses as sequences of user
or domain names.

Railway signalling If a model of a railway signalling system is to be developed,
the order in which trains encounter signals may be of significance and so
sequences may be needed to model train paths. As usual, this depends on the
purpose of the analysis. If we wish to record the fact that trains may leave one
sequence of signals and join another, a more complex network representation
might be appropriate.

Text processing A text processing system, such as one which searches through
text for key strings, should model the text as a sequence, since the order in
which symbols arise is significant when matching against a search string.
This is the case with the trusted gateway example shown later in this chapter.

7.2 The sequence type constructor
Given a type T, the type of sequences of elements of T is written

seq of T

For example, strings could be modelled as sequences of characters:

String = seq of char

Because non-empty sequences are used frequently an additional type operator
is made available for this special case. A type of non-empty strings could be
defined by

String = seq1 of char

7.3 Defining sequences
The three definition mechanisms used for sets (enumeration, subrange

and comprehension) are also available for sequences. Below, we briefly examine
each in turn.



7.3 Defining sequences 123

Enumeration The empty sequence is represented as []. A sequence of length
1 is called a singleton sequence. Sequence enumeration is just a matter of list-
ing the elements of the sequences in the way shown above. The elements of a
sequence can be sequences themselves, e.g.

[ [ 2, 5, 4, 5 ],
[ 2, 5, 4, 5 ],
[ 3 ]

]

Subrange Given a finite sequence of values, it is possible to extract a subse-
quence by giving the positions of the first and last elements of the subsequence
required. In VDM-SL, sequence indexing starts with position 1. Given a se-
quence s, the subsequence from position i to position j inclusive is given by

s(i,...,j)

This is a sequence itself. If i>j the subsequence is empty, and if j lies beyond
the end of s, the subsequence goes up to the end of s. If both i and j are
beyond the end of the sequence, the subsequence is empty.

Exercise 7.1 Evaluate the following expressions, checking your answer with
VDMTools Lite:

[4, 5, 3, 3, 9, 3, 2, 3](2,...,5)

[4, 5, 3, 3, 9, 3, 2, 3](5,...,12)

[4, 5, 3, 3, 9, 3, 2, 3](5,...,5)

[4, 5, 3, 3, 9, 3, 2, 3](5,...,2)

�

Comprehension Sequences can be defined by comprehension. This construc-
tion can provide a concise way of describing filters on sequences of values.
Sequence comprehension takes the following form:

[ expression | set-binding & predicate ]

The set binding must be satisfied by a collection of numeric values. The values
satisfying the binding are considered in order, smallest first. Those which do not
satisfy the predicate are ignored. The expression is evaluated on those which do
satisfy the predicate, yielding a sequence as a result.



124 7 Sequences

For example, suppose we have a sequence of natural numbers and wish to
filter out all the even numbers in the sequence. Given the input sequence

[6, 7, 4, 9, 3, 3]

we would want to return the result

[7, 9, 3, 3]

This could be achieved by the following comprehension:

[s(i) | i in set inds s & not Even(s(i))]

where inds returns the set of indices of a sequence (here {1,...,6}) and
Even is an auxiliary function checking the evenness of natural numbers using a
simple sequence index application to get hold of a specific element.

The comprehension works as follows. The values satisfying the binding are
{1,...,6}. Those which satisfy the predicate are {4,6,2,5}. These are
taken in increasing numerical order, resulting in the sequence [s(2), s(4),
s(5), s(6)], namely [7,9,3,3].

Exercise 7.2 The following function takes the sequence s and the number n
as inputs. It filters out the elements of s which are greater than n. Complete its
definition and test it using VDMTools Lite.

FilterBig: seq of int * int -> seq of int

FilterBig(s,n) == ???

�

A note on finiteness As with sets, sequences in VDM-SL are finite. However,
since sequence comprehensions can only be described using set bindings, their
use does not entail a risk of violating the finiteness constraint.

Using recursion to traverse data structures It is often necessary to define func-
tions that travel over (traverse) collections such as sets, sequences and map-
pings. For example, a function might be required to travel through all the objects
in the explosives store in order to return the size of the largest object. A common
approach to defining functions that traverse collection data structures is to use
recursion. Function definitions in VDM-SL are allowed to be recursive, i.e. the
definition of a function f can include a call to f, operating on a new input.

In order to define recursive functions over sequences we need to be able to se-
lect the next value to be visited. For sequences this is often done using operators
that split a sequence up into its head and tail. The first element in a non-empty



7.4 Modelling with sequences 125

sequence s is called the head of the sequence, written hd s. By convention, the
head of a sequence is written at its left-hand end. The hd operator is partial in
that the head of the empty sequence (hd []) is undefined. The remainder of the
sequence after the head has been removed is called the tail of s, written tl s.
Again, the tail of the empty sequence is undefined.

Using the head and tail functions, and an if expression, the function SeqSum
produces the sum of a sequence of natural numbers:

SeqSum: seq of nat -> nat
SeqSum(s) ==
if s = []
then 0
else hd s + SeqSum(tl s)

A recursive function is defined only if the recursion is guaranteed to terminate on
every valid input (i.e. inputs of the correct type satisfying any relevant invariants
and pre-conditions). In this case, the function is applied to the tail of s, then the
tail of its tail, and so on until the empty sequence [] is reached, when the “then”
part of the conditional applies and the function delivers 0 (the neutral element
of addition). To guarantee termination, a recursive function requires a base case
where there is no recursive call, and all recursive calls in the function body have
to be on values which take us closer to the base case until eventually the base
case is reached. In the SeqSum function, this constraint is satisfied because the
recursive call is always applied to the tail of a non-empty sequence, which is
shorter that the sequence itself. Eventually, we reach the empty sequence and
the base case. Recursion will be treated in more detail in Chapter 9.

Exercise 7.3 Type the definition of SeqSum into a file using an editor and
configure VDMTools with this file. Initialise the interpreter and make a break-
point in SeqSum. Debug SeqSum([2,8,5,6]) and pay attention to the
recursive calls recorded in the function trace part of the interpreter window. �

7.4 Modelling with sequences
7.4.1 The trusted gateway example

The example used in this chapter is inspired by the trusted gateway
model developed as part of the ConForm project at British Aerospace Systems
& Equipment Ltd. (BASE) [Fitzgerald&95, Larsen&96].

A trusted gateway is a device for processing messages which may contain

confidential information. It is typically used to prevent secret messages from



126 7 Sequences

Figure 7.1 Overview of the trusted gateway

High
Security
System

Low Security System

High Security System

Trusted
Gateway

entering computer systems which are not authorised to process such messages

securely.

A message is a stream of 1 to 100 characters. A sequence of messages arrives

at the gateway’s input port. The messages are then assessed to determine their

security classification, either high or low. Messages which are high-security are

passed to a high-security output port. Messages which are low-security are passed

to a low-security output port.

A message is deemed to have a high classification if it contains any

occurrences of special marker strings. The set of marker strings is called a

category. Marker strings have minimum length 1.

The gateway provides one major function: to take an input stream of messages

and category and produce the streams of messages at the output ports with the

messages classified.

The purpose of the trusted gateway model is to define the security level of
messages and fix the security policy which the gateway must respect. The model
therefore concentrates on the definition of messages, their security classification
and the allocation of messages to output ports. Other aspects of the gateway,
such as the details of particular communications protocols, are not relevant to
the analysis of the model. After introducing the model, the issue of abstraction,
as it applied to the model of the trusted gateway developed “on project”, is
discussed in Section 7.6.



7.4 Modelling with sequences 127

7.4.2 The gateway’s data model
Non-empty strings of characters appear in the definitions both of mes-

sages and the category. A type String could be introduced to model this:

String = seq of char

Non-emptiness could be modelled by a simple invariant:

String = seq of char
inv s == s <> []

Alternatively this could also be defined as

String = seq1 of char

A message can be viewed as a string of characters. A type Message is
defined to model this:

Message = String

The system description also indicates that messages are restricted to a maximum
length of 100 characters. This could be recorded as an invariant, provided we
have a means of obtaining the length of a sequence. The operator len, given a
sequence, returns the number of elements of the sequence, zero if the sequence
is empty. The completed definition of Message is therefore

Message = String
inv m == len m <= 100

Note that we have modelled the non-emptiness restriction on the String data
type but imposed the maximum length restriction on the Message type. The
String type is used in several type definitions: both in messages and in marker
strings defined in categories, for example. As these different uses of String
may have different maximum length restrictions, we have chosen to place the
invariant on the maximum length at the lowest-level type definition to which it
applies. This serves to protect against unintended consequences if the invariant
changes as the model evolves in future. For example, if we had placed the max-
imum length restriction on String and this changes in future, the maximum
length of messages would also change.

Place invariant definitions carefully, bearing in mind the possi-
bility of future evolution of the model. As a general rule, place
a restriction on the most specific data type to which it applies.

A message classification is simply high or low. We could model this as a
Boolean:



128 7 Sequences

Classification = bool

However, this suffers from a few deficiencies. First, it does not reflect the high-
/low naming used in the system description and it is not clear what true and
false means in the context of classification. Second, it does not provide the
flexibility to allow any additional classifications to be introduced without sub-
stantially revising the type definition and all its points of use. Finally, a type
checker will allow Boolean operators such as not, and, or, => to be applied
to classifications, which we would be surprised to see in the model. Rather,
we prefer to use an enumerated type, built up from a union of quote types as
described in Subsection 5.3.1:

Classification = <HI> | <LO>

This can be extended if, at a later stage, one wishes to add a new classification,
e.g.

<HI> | <LO> | <TOPSECRET>

The category of marker strings could simply be modelled as a set of strings:

Category = set of String

Finally, the output ports can be modelled as a record with two ports, each a
sequence of messages:

Ports :: high: seq of Message
low : seq of Message

7.4.3 The gateway’s functionality
Having modelled the principal data types for the gateway, we can now

consider the functionality. We will call the main function Gateway and it will
have a signature as follows:

Gateway: seq of Message * Category -> Ports

Since the input sequence of messages could be empty we must consider what the
result should be in this case. A port value with two empty output ports seems like
a reasonable choice. As a general rule, it is wise to consider empty data values
when using collections such as sets, sequences and mappings, especially since
operators on these collections are often undefined when applied to the empty
structure. A first sketch of the function is thus

Gateway: seq of Message * Category -> Ports
Gateway(ms,cat) ==

if ms = []



7.4 Modelling with sequences 129

then mk_Ports([],[])
else process list of messages one by one

It is appropriate to use recursion to complete the definition. A recursive call of
Gateway with the tail of the sequence of messages will give us a Ports value
for all messages except the first one. We could define an auxiliary function
ProcessMessage which will be responsible for adding the result of the first
message to the Ports value from the rest of the sequence. Gateway can thus
be completed as

Gateway: seq of Message * Category -> Ports
Gateway(ms,cat) ==
if ms = []
then mk_Ports([],[])
else let rest_p = Gateway(tl ms,cat)

in
ProcessMessage(hd ms,cat,rest_p)

We have now reduced the problem to processing a single message. If the mes-
sage has a high classification it must be passed to the high-security output port.
Otherwise, the message must be passed to the low-security output port. We can
record this by using an if expression. The structure of ProcessMessage is

ProcessMessage: Message * Category * Ports -> Ports
ProcessMessage(m,cat,ps) ==
if the message has a high classification
then add message to high output port
else add message to low output port

From the test here, it appears we need to be able to work out the classifica-
tion of a message and so we will develop a suitable auxiliary function for this
purpose:

Classify: Message * Category -> Classification
Classify(m,cat) == ???

If there is a string from the set cat which occurs inside the message m, then
the classification is <HI>. Otherwise the classification is <LO>. This can be
modelled as

Classify: Message * Category -> Classification
Classify(m,cat) ==
if exists hi in set cat & Occurs(hi,m)
then <HI>
else <LO>

The function Occurs will return the Boolean value true if the string hi oc-
curs at some point in the string m:



130 7 Sequences

Occurs: String * String -> bool
Occurs(substr,str) == ???

The argument substr is a substring of str if we can find positions i and j in
str such that

substr = str(i,...,j)

The positions in a sequence are known as its indices. The indices of the sequence
[3, 6, 6, 2, 3] form the set {1, 2, 3, 4, 5}. The set of indices of
the empty sequence is the empty set {}.

Exercise 7.4 Define a function with the following signature to return the
set of indices of a sequence of integers. The body of the function definition
should use set subrange and len. Test your function using VDMTools Lite,
remembering to evaluate it on the empty sequence as well as more complex
examples.

Indices: seq of int -> set of nat

�

The built-in operator inds introduced in Subsection 7.3 above will return
the set of indices of any given sequence. We can complete the definition of
Occurs, by quantifying i and j over the indices of the string str:

Occurs: String * String -> bool
Occurs(substr,str) ==

exists i,j in set inds str & substr = str(i,...,j)

So the definition of Classify has now been completed. Let us now return to
the ProcessMessage function.

ProcessMessage: Message * Category * Ports -> Ports
ProcessMessage(m,cat,ps) ==

if Classify(m,cat) = <HI>
then add message to high output port
else add message to low output port

Consider first high classification output. We need to return a Ports value con-
sisting of

• at the high output, the current message on the front of ps.high;
• at the low output, ps.low.

The current message is to be placed at the front of this sequence. Here we use
the sequence concatenation operator. Given sequences s1 and s2, the sequence



7.4 Modelling with sequences 131

Figure 7.2 Operation of the trusted gateway

ACDE

F B

Trusted
Gateway

Processed messages
added to head end
of output port.

Messages read
in from head end
of input port.

ABCDEF

s1ˆs2 is the single sequence obtained by joining the two sequences together.
Thus, if s1 is non-empty, the following expressions are both true:

hd s1ˆs2 = hd s1
tl s1ˆs2 = (tl s1)ˆs2

The empty sequence is a neutral element for the concatenation operator, i.e.
[]ˆs = s and sˆ[] = s.

In the ProcessMessage function, we place m onto the head end of the
result of processing the rest of the input, ps. This process is illustrated in Fig-
ure 7.2, where the input messages A, C, D and E are high classification and the
messages B and F are low classification. We use the head end to ensure that
messages appear at each output in the same relative order as they were in the
input, although this is not stated as a specific requirement:

[m]ˆps.high

Note that the added value m must be made into a singleton sequence, because
ˆ only accepts two sequences as its arguments. A common error in using se-
quences is to forget that concatenation expects sequences as arguments (so, in
this case, mˆps.high would not pass a type check).

The output to be returned in the high classification case is the Ports record
value consisting of the high port constructed above and the unchanged low port
component of ps. This is formulated using a record constructor expression as



132 7 Sequences

mk_Ports([m]ˆps.high, ps.low)

The completed version of ProcessMessage is as follows:

ProcessMessage: Message * Category * Ports -> Ports
ProcessMessage(m,cat,ps) ==

if Classify(m,cat) = <HI>
then mk_Ports([m]ˆps.high,ps.low)
else mk_Ports(ps.high,[m]ˆps.low)

Note how the third input parameter to ProcessMessage is acting as an ac-
cumulating parameter gradually constructing the result in reverse order. This
approach, with an accumulating parameter which gradually builds up the result-
ing value, was also shown in the Gateway function and is often used when
recursive functions are defined.

This completes the definition of the trusted gateway’s functionality using re-
cursion.

Comprehension versus recursion
As the example above illustrates, the use of recursive definitions can be

complex. On some occasions it is possible to express the same functionality us-
ing comprehension instead. Comprehensions seem to be easier to understand in
general, and thus we would recommend their use when possible. The Gateway
function can be expressed using two sequence comprehensions with the follow-
ing form:

Gateway2: seq of Message * Category -> Ports
Gateway2(ms,cat) ==

mk_Ports([ms(i)|i in set inds ms & Classify(ms(i),cat) = <HI>],
[ms(i)|i in set inds ms & Classify(ms(i),cat) = <LO>])

Note that the function ProcessMessage is not even needed in this case.
When we have data in a set, sequence or mapping we can almost always use
comprehensions if the result we wish to get back is also a collection. In the
Gateway case we wish to get two such collections back whereas in the SeqSum
case we “reduced” the collection to a single value. Whenever such a compres-
sion is carried out recursion is the only way to model the functionality.

7.5 Further operators on sequences
Some useful operators on sequences are not covered by the trusted gate-

way example, and these are introduced via a number of small examples related
to the trusted gateway.



7.5 Further operators on sequences 133

Gathering the elements of a sequence Suppose it is necessary to analyse a se-
quence of messages to see whether or not any of them have a high classification.
An auxiliary Boolean function could be defined to return true if there is a
message in the sequence which would be classified as high security:

AnyHighClass: seq of Message * Category -> bool
AnyHighClass(ms,cat) == ???

To complete the body of the function, we would expect to quantify over all
the elements of the sequence, but how can we build the set of such elements?
The elems operator, given a sequence s, returns the set of elements of s.
If s is the empty sequence, elems s = {}. The completed definition of
AnyHighClass is as follows:

AnyHighClass: seq of Message * Category -> bool
AnyHighClass(ms,cat) ==
exists m in set elems ms & Classify(m,cat) = <HI>

Exercise 7.5 Evaluate the following expressions, checking your answer with
VDMTools Lite:

elems [<Red>]
elems [2,5,4,5]
elems tl [2]
elems [tl [2,5,4,5] ]

�

Distributed concatenation: flattening sequences of sequences Recall from Chap-
ter 6 that there exist distributed versions of the operations for set union and inter-
section. A useful distributed version of sequence concatenation is also provided.
As an example, suppose we were asked to provide a compression utility which
takes a sequence of messages and transforms them into a single message. We
would need an operator which joins all the messages in the sequence together.
Remember that each message is itself just a sequence of characters:

FlattenMessages: seq of Message -> Message
FlattenMessages(ms) == conc ms

The conc operator takes a sequence of sequences and returns the sequence
formed by concatenating all the individual sequences.

Although FlattenMessages looks simple, it is, in fact, faulty! The func-
tion is supposed to return a Message, but recall that a Message is a sequence
of no more than 100 characters. The messages in the input, although individually
less than 100 characters long, could add together to give too long a sequence,



134 7 Sequences

violating the invariant on Message. We restrict the use of the function to those
cases where the input messages will add together to a message of no more than
100 characters. This is done by adding a pre-condition stating that the length of
conc ms is no greater than 100:

FlattenMessages: seq of Message -> Message
FlattenMessages(ms) ==

conc ms
pre len conc ms <= 100

Sequence modification Suppose a facility is to be provided allowing messages
to be altered so that certain parts of the contents are removed: some kind of
Censor function. Let this function take as input a message along with a start
index and length of the string we would wish to remove. We would like the
Censor function to return a message where the described interval has been
filled with, for example, blanks:

Censor: Message * nat1 * nat1 -> Message
Censor(m,index,length) == ???

For this purpose we would like to introduce one final sequence operation: se-
quence modification.

The sequence modification expression updates a sequence at desired indices.
The sequence s ++ {3 |-> <Red>} is the sequence s with the third ele-
ment changed to the value <Red>. In general we have

_++_ : seq of T * map nat1 to T -> seq of T

The first parameter is the sequence we wish to modify, and the second parameter
maps indices we wish to change to the new value we wish to place at those
indices. The sequence modification operator is partial: the indices from the
domain of the mapping must be in inds s, i.e. they must be valid for the
sequence being modified.

Exercise 7.6 Evaluate the following expressions, checking your answer with
VDMTools Lite:

[<Red>] ++ {1 |-> <Green>}
(tl [2,5,4,5]) ++ {3 |-> 6}
[3,8,4,2,3,4] ++ {1 |-> 8, 3 |-> 8}

�

Returning to the Censor function, we must first describe the modification
mapping. The indices we wish to modify must start at index and go up to
index + length - 1. Thus we can define a mapping like



7.6 Abstraction lesson: choosing abstraction levels 135

{i |-> ’ ’ | i in set {index,...,index + length - 1}}

With this mapping we can produce a first version of our Censor function as
follows:

Censor: Message * nat1 * nat1 -> Message
Censor(m,index,length) ==
m ++ {i |-> ’ ’ | i in set {index,...,index + length - 1}}

We should also consider what the pre-condition, if any, should be for this func-
tion. Since the sequence modification expression is only well-defined if the
indices in the domain of the mapping are indeed proper indices of the sequence,
the final version of the function is as follows:

Censor: Message * nat1 * nat1 -> Message
Censor(m,index,length) ==
m ++ {i |-> ’ ’ | i in set {index,...,index + length - 1}}

pre index + length - 1 <= len m

7.6 Abstraction lesson: choosing abstraction levels

The model of the trusted gateway in this chapter deals with whole streams
of input messages at once. However, the real trusted gateway operates in real
time, handling individual messages when they arrive at the input port. It would
therefore seem natural, faced with the problem of modelling the gateway, to
model the classification of messages one at a time in some sort of looping state-
machine model. Why then, did we choose to model the system in this more
abstract way?

The reason for the abstraction is closely related to the purpose of the model.
The model was developed primarily in order to analyse the security policy of
the gateway (the rules for classifying messages and for treating them), not for
analysing its design at the level of the order or time limits in which operations
are performed. With that in mind, a more complex model with several oper-
ations and a loop would have been unnecessary and more difficult to analyse.
Had the model been developed for other purposes (for example to determine the
characteristics of the input buffering mechanism), a different abstraction would
have been appropriate.



136 7 Sequences

In the project which actually developed the gateway, models of
other aspects of the system (e.g. the handling of power loss)
were developed. It was noted that the first attempt at a model
was often at a lower level of abstraction than was necessary.
For example, the system engineer’s first model of string search-
ing (the Occurs definition) was a complicated forward search
function working on messages.

An important lesson from the BASE study ConForm was that the first model
to be developed may be obvious, but can often be complex to write and analyse.
The “life-cycle” of a model often shows increasing complexity in the early drafts
of the model as developers incorporate as many aspects of the system as they feel
are expressible. There typically comes a point at which simplifying abstractions
become apparent and the overall size of the model is reduced. Concentration on
the purpose of the model can often yield significant simplification.

Summary
• Sequences are finite ordered collections of elements of the same type. In

contrast to sets, both repetition of elements and the order of presentation
are significant.

• Sequences can be presented by enumeration, subrange or comprehen-
sion.

• Some operators on sequences are partial, in the same way as the numeric
division operator / in numeric expressions.

• A distributed concatenation operator allows a sequence of sequences to
be flattened out.

• In building a formal model, one strategy is to begin with a type repre-
senting a “high-level” component of the system and pursue a top-down
strategy, making new definitions of types and auxiliary functions as re-
quired.

• Consideration of the purpose of a model can often lead to the introduc-
tion of abstractions that simplify the model and its analysis.

• Recursion is often used in functions designed to traverse collections of
values such as sequences. Sequence comprehension also models in-
order iteration over the elements of a sequence.



8
Mappings

Aims
The aim of this chapter is to show how relationships between data can

be modelled as mappings. The mapping type constructor and operators in VDM-
SL are introduced through an example from the nuclear industry. On completing
this chapter, the reader should be confident in modelling and analysing systems
involving mappings.

8.1 Introduction
Computing systems frequently centre on relationships between sets of

values. For example, a database might link a set of customer identifiers to de-
tailed information. Such relationships can often be modelled as mappings from
elements of one set, known as the domain, to elements of the other set, known
as the range. Mappings can be thought of as tables in which one can look up
the domain element and read across to see the range element to which it is re-
lated. We will say that each domain element maps to the corresponding range
element. Each line of the table, being a small part of the mapping, is called a
maplet. Each domain element can have only one maplet in a mapping, so there
is no ambiguity about which range element it points to. For example, the fol-
lowing table represents a mapping from names (strings of characters) to bank
balances (integers). It consists of three maplets:

John −500
Peter −750
Susan 1025

In VDM-SL, mappings are presented as sets of maplets, with each maplet con-
sisting of the domain element and an arrow pointing to the value of the corre-
sponding range element. For example, the table above would be represented as
follows:

{ "John" |-> -500, "Peter" |-> -750, "Susan" |-> 1025 }

137



138 8 Mappings

Since a mapping is shown as a set of maplets, the order of presentation of the
maplets is not important. Thus

{ "John" |-> -500, "Peter" |-> -750, "Susan" |-> 1025 } =
{ "Susan" |-> 1025, "John" |-> -500, "Peter" |-> -750 }

Two mappings are equal only when they have the same domains, and each do-
main element points to the same range element in each mapping. Thus

{ "John" |-> -500, "Peter" |-> -750, "Susan" |-> 1025 } <>
{ "Susan" |-> 1025, "Peter" |-> 0, "John" |-> -500 }

because the domain value "Peter" maps to a different value in the two map-
pings.

It is possible for different domain elements to map to the same range element.
Thus the following is a perfectly good mapping:

{ "John" |-> -500, "Peter" |-> 1025, "Susan" |-> 1025 }

However, each domain element must map to exactly one range element. Thus,
the following is not a mapping:

{ "John" |-> -5, "Peter" |-> 1, "Susan" |-> 1, "Peter" |-> 63 }

When to use mappings
The special characteristic of a mapping is that each domain element

points to exactly one range element. We therefore often use mappings to de-
scribe relations between identifiers and the records they identify. Two examples
are as follows:

Patient records In models of clinical systems, a patient identifier such as a
health service or insurance number normally points to a record which con-
tains patient details. The details, such as name, address and blood group,
would be modelled as a record, while the overall collection is a mapping from
patient identifiers to records. Such models are idealised in the sense that pa-
tients may develop several separate records, e.g. through movement between
care providers or regions. If this is relevant to the analysis of the model, we
could use a mapping from patient identifiers to sets of patient records.

Symbol tables Computer language processors such as compilers and editors keep
track of the attributes of variables declared in computer programs. This infor-
mation is often stored in a symbol table which is modelled in compiler design
as a mapping from variable names to information about the variable such as
its type and initial value.



8.2 The mapping type constructor 139

The characteristics of mappings make them at least as useful in system mod-
elling as functional dependences are in the field of database design. Indeed,
mappings often arise in models of systems which have a database aspect.

8.2 The mapping type constructor
A mapping records a relation between two sets of values: the domain

and the range. The type constructor is map to ; for example, the type

map AccountNo to int

represents mappings from account numbers to (possibly negative) balances.
In a mapping, each element of the domain must map to only one range ele-

ment (each account has exactly one balance; no account can have two or more
balances at once). In this respect, a mapping is like a mathematical function. Of
course, two different domain elements may map to the same range element (two
accounts can have the same balance).

8.3 Defining mappings
Mappings can be defined either by enumeration or by comprehension.

Below we briefly examine both.

Enumeration The empty mapping is represented as {|->}with the arrow show-
ing the direction from the domain on the left to the range on the right. A mapping
can be enumerated as a set of maplets, for example, the following expression is
a mapping enumeration (from account numbers to balances):

{"9311290" |-> -500,
"1392842" |-> 3129,
"445829n" |-> 0}

Each maplet is written as a domain value followed by an arrow and a range
value. Each maplet is separated with a comma. A mapping type definition
may have any types for the domain and range, so they could be mapping types
themselves. The following expression is a mapping enumeration of type map
char to (map nat to nat):

{’a’ |-> {2 |-> 7}, ’b’ |-> {|->}}

Comprehension Just as with sets and sequences, we can also describe mappings
by means of a powerful comprehension notation. This is very similar to set and



140 8 Mappings

sequence comprehension, except that we must quantify over maplets rather than
single values. For example, the mapping of numbers from 1 to 5 to their squares
can be enumerated as follows:

{1 |-> 1, 2 |-> 4, 3 |-> 9, 4 |-> 16, 5 |-> 25}

The same mapping can be described by a mapping comprehension using a type
binding:

{n |-> n*n | n:nat1 & n <= 5}

or with a set binding:

{n |-> n*n | n in set {1,...,5}}

Recall from Section 4.5 that type bindings cannot be executed using the inter-
preter from VDMTools Lite.

A note on finiteness As with sets and sequences, mappings in VDM-SL are
finite collections, and so we have to be careful that a mapping comprehension,
especially with a type binding, does not yield an unbounded set of maplets.

Exercise 8.1 Evaluate the following expressions by hand and check your
answers in VDMTools Lite:

{x |-> 2 * x | x in set {1,...,15} & x < 5}

{y |-> true | y in set {1,...,20} &
exists x in set {1,...,3} & x*2 = y}

{x+y |-> x+y | x,y in set {1,...,3}}

What happens if one of the addition symbols “+” from the last expression above
is changed to a subtraction sign? �

8.4 Modelling with mappings
8.4.1 The nuclear tracker example

The example used in this chapter to introduce mappings and mapping
operators concerns a system for tracking the movement of containers of haz-
ardous material between phases of processing in a nuclear reprocessing plant. It
is inspired by the formal model of a plant controller architecture developed by
Manchester Informatics Ltd. in collaboration with British Nuclear Fuels (Engi-
neering) Ltd. (BNFL) in 1995 [Fitzgerald&98].



8.4 Modelling with mappings 141

A tracker monitors the position of containers of material as they pass through the

various stages of processing in the plant. A typical plant consists of several

phases corresponding to physical processes. For example, crates could arrive at

an initial unpacking phase where they are opened and the packages inside

removed and sorted into different baskets on the basis of the types of material they

contain (e.g. glass, metal, plastic, liquid). A subsequent phase could measure the

radioactivity and recoverable material content of each basket before passing on to

other processes which might involve dissolving metal contents or crushing glass.

Finally, the products of the process can be packaged and returned to the customer

or put into storage. Figure 8.1 shows an overview of a typical plant.

Each container has a unique identifier. It contains a certain fissile mass

(quantity of radioactive material) and contains material of only one kind (glass,

metal, liquid etc.).

Each phase has a unique identifier. It has a certain collection of containers in it

at any time. These containers should all contain a certain kind of material (e.g. the

crushing phase accepts only containers with glass in them). Each phase also has a

maximum capacity: the maximum number of containers that can be in the phase

at any time.

Obviously, when dealing with hazardous materials, it is very important to

ensure that no material goes missing and that care is taken to avoid too much

material getting into a phase, in case there is a build-up of dangerous substances

in one area. The tracking manager is responsible for giving permission for

movements of containers between phases of processing in order to avoid

dangerous situations.

The purpose of the formal model of the tracker is to define the rules for the
addition, removal and movement of containers in the plant. The model is there-
fore concerned with modelling enough information about containers and phases
to allow the rules for movement to be fixed. The model is not concerned with
other aspects such as the timing of movement between phases.

8.4.2 Basic data types in the tracker model
The tracker must keep a record of the whereabouts of containers, so

it needs to model the contents of phases as well as details of the containers
themselves. This suggests that we could model the tracker as a record type with
two components containing information about containers and phases:

Tracker :: containers : ContainerInfo
phases : PhaseInfo



142 8 Mappings

Figure 8.1 Overview of typical tracker plant

Compaction

SortingUnpacking

New
containers

Load on trucks

Calc. fissile
content

Assay

Glass, Liquid, ...

No Liquid!
Storage

How will containers and phases be modelled? The requirements indicate that
containers have a unique identifier, so this implies a mapping relationship be-
tween container identifiers and information about each container. Each con-
tainer identifier maps to a record containing a description of the container: the
amount and type of material it contains. Thus we get

ContainerInfo = map ContainerId to Container

Similarly for phases, we can have a mapping from phase identifiers to descrip-
tions of the contents of the phase.

PhaseInfo = map PhaseId to Phase

The details of how identifiers are represented (as serial numbers, time-stamps
etc.) are not relevant to the abstract tracker model, so the token type represen-
tation is appropriate here:



8.4 Modelling with mappings 143

ContainerId = token;
PhaseId = token

For each container, we must record the fissile mass of its contents (a real num-
ber) and the kind of material it contains. This suggests we use a record type for
Container:

Container :: fiss_mass : real
material : Material

The particular materials accepted by a given plant are not of concern here, so
Material can be modelled with token:

Material = token

That deals with containers; it remains to model the phases of the plant. Each
phase houses a number of containers, expects certain material types and has a
maximum capacity. Again, this suggests a record type:

Phase :: contents : collection of containers
expected_materials: material types
capacity : number of containers

The requirements do not deal with the order in which containers have to be
treated within a phase (this would be the subject of a subsystem managing ef-
ficient throughput which could, for example, handle prioritisation and “rush
jobs”). We shall therefore model the contents of the phase as an unordered
set of container identifiers. The expected material is an unordered collection of
materials and the number of containers is a natural number:

Phase :: contents : set of ContainerId
expected_materials: set of Material
capacity : nat

In the tracking manager project with Manchester Informatics,1 domain experts
from BNFL were closely involved in the development of the formal model.
These experts were able to point out to the modelling experts the main safety
properties which had to be respected by the tracker. Among these was the
important requirement that the number of containers in a given phase should
not exceed the phase’s capacity. This was recorded as an invariant on the type
Phase:

Phase :: contents : set of ContainerId

1 When we refer to the Manchester Informatics project, the reader should bear in mind
that the formal model developed on the project was much more complex than that de-
veloped in this tutorial book, since it had to cope with nesting of phases, buffering,
storage and recording container histories.



144 8 Mappings

expected_materials: set of Material
capacity : nat

inv p == card p.contents <= p.capacity and
p.expected_materials <> {}

In addition the invariant here expresses the requirement that a phase cannot have
an empty set of expected materials.

When developing a model for specialists in a particular appli-
cation domain, make a point of considering data type invariants
as part of the modelling process. Consider the possibility of
“extreme” values such as empty sets, sequences or mappings,
and possible inconsistencies between components of composite
types.
The domain experts from BNFL often commented that this abil-
ity to record constraints formally as invariants which had to be
respected by all the functions in the model was extremely valu-
able. Invariants allow us to record information that is often re-
garded as “common knowledge” in a particular application do-
main, but which may in fact be less well known than many prac-
titioners in the domain suppose, and certainly not well known to
computer systems developers!

8.4.3 The tracker invariant

Having modelled the basic types representing identifiers, materials, con-
tainers and phases, we return to the model of the tracker itself:

Tracker :: containers : ContainerInfo
phases : PhaseInfo

The containers mapping represents our knowledge of the contents of each
container known to the tracker. The phases mapping represents our knowl-
edge of the locations of containers in phases. Here too, a number of invariant
properties were identified:

1. all of the containers present in phases are known about in the containers
mapping;

2. no two distinct phases have any containers in common;
3. in any phase, all the containers have the expected kind of material inside

them.



8.4 Modelling with mappings 145

We must incorporate these conditions in an invariant on the Tracker type.
The conditions themselves appear a little complex at first reading, so we will
consider them separately by defining an auxiliary Boolean function for each of
them. The definition of Tracker can then be completed as follows (using
auxiliary functions to stand for each of the three invariant properties):

Tracker :: containers : ContainerInfo
phases : PhaseInfo

inv mk_Tracker(containers,phases) ==
Consistent(containers,phases) and
PhasesDistinguished(phases) and
MaterialSafe(containers,phases)

The first condition states that all the containers mentioned in the phases
mapping should appear in the containers mapping. In order to say this
formally, we need to be able to extract all the container identifiers in the phases
mapping and all the container identifiers from the containers mapping. We
will therefore need to be able to get all the phase descriptions in the range of
phases and all the container identifiers in the domain of containers. To
extract the domain of a mapping, we use the dom operator. Given a mapping m
of type map A to B, the expression dom m represents the set of values of type
A present in the domain of m. Thus

dom containers

represents the domain of the containers mapping: a set of container identifiers –
in fact the set of container identifiers of all containers known to the tracker.

The operator rng extracts the range of a mapping. If m is of type map A to
B, the expression rng m represents the set of values of type B present in the
range of m, i.e. those values pointed to by some element of dom m. So, to get all
the phase descriptions in the range of phases, we write

rng phases

Exercise 8.2 Evaluate the following by hand and then try evaluating them in
VDMTools Lite:

dom {3 |-> 8, 7 |-> 4, 4 |-> 8}
rng {3 |-> 8, 7 |-> 4, 4 |-> 8}
dom {|->}

�

Exercise 8.3 Express the following as set comprehensions and check your
answer using VDMTools Lite:



146 8 Mappings

rng {x |-> x + 3 | x in set {6,...,12}}
dom {x**x |-> x + 1 | x in set {1,...,5}}

�

Given a particular phase description ph, i.e.

ph in set rng phases

the set of containers in the phase description is given by

ph.contents

We require that ph.contents should be a subset of dom containers.
Thus, the first part of the invariant is stated formally as follows:

Consistent: ContainerInfo * PhaseInfo -> bool
Consistent(containers, phases) ==

forall ph in set rng phases &
ph.contents subset dom containers

The second condition to be recorded in the invariant states that no two phases
have any containers in common. The basic form of this condition is

not exists p1, p2 in set dom phases &
p1 <> p2 and
Phase p1’s contents intersect with Phase p2’s contents

How can we formalise the notion of the contents of the phase identified by
p1 or p2? This is done by “looking up” the identifier in the mapping and seeing
what phase it points to. This “looking up” is called mapping application because
we apply the mapping to the domain element to get the corresponding range
element. Given a mapping

m : map A to B

and a value

a : A

such that a in set dom m, the expression

m(a)

represents the value of type B pointed to by a in m. Note that mapping applica-
tion is partial: if a is not in the domain of m, m(a) is undefined.

In the tracker model, the phase information pointed to by the phase identifier
p1 is written phases(p1). The invariant condition is formalised as follows:

PhasesDistinguished: PhaseInfo -> bool
PhasesDistinguished(phases) ==



8.4 Modelling with mappings 147

not exists p1, p2 in set dom phases &
p1 <> p2 and
phases(p1).contents inter phases(p2).contents <> {}

The final invariant clause requires that each phase only has containers of the cor-
rect type for that phase. To express this, we need to consider each phase and each
container in the phase. We need to look each container up in the containers
mapping to get its material type and check this against the material types of the
phase under consideration:

MaterialSafe: ContainerInfo * PhaseInfo -> bool
MaterialSafe(containers, phases) ==

forall ph in set rng phases &
forall cid in set ph.contents &

cid in set dom containers and
containers(cid).material in set ph.expected_materials

This completes the formal data model of the tracker, which introduced the map-
ping type constructor and the operators for domain, range and mapping applica-
tion. We can now consider the functions to be defined in the model.

8.4.4 The tracker’s functionality
The tracker is required to provide certain functionality. Functions are to

be provided for

1. introducing a new container to the tracker, given its identifier and con-
tents;

2. giving permission for a container to move into a given phase;
3. removing a container from a phase;
4. moving a known container to a given phase from another phase;
5. deleting a container from the tracker.

Introducing a new container This function adds a new container to the tracker,
given the new container’s identifier, its fissile mass and the kind of material
contained. The signature and the beginning of the function body are as follows:

Introduce: Tracker * ContainerId * real * Material -> Tracker
Introduce(trk, cid, quan, mat) == ???

Somehow we must add a new maplet which relates the container identifier cid
to the information about the container. New elements are added to mappings by
using a mapping union operator written munion. For example, if we wanted to
add the mapping



148 8 Mappings

{5 |-> 22, 7 |-> 11}

to the mapping

{3 |-> -7, 12 |-> 0, 44 |-> -7}

we would write

{3 |-> -7, 12 |-> 0, 44 |-> -7} munion {5 |-> 22, 7 |-> 11}

and the expression would evaluate to

{3 |-> -7, 12 |-> 0, 44 |-> -7, 5 |-> 22, 7 |-> 11}

Mapping union is a partial operator. An expression using it is undefined if the
mapping union would lead to ambiguity about a domain element. For example,
the expression

{3 |-> -7, 12 |-> 0} munion {12 |-> 4}

is undefined because it is not clear what 12 would point to in the result: it could
be 0 or 4. Notice that we can add a new maplet {x |-> y} to a mapping m
even if x occurs in the domain of m, provided the x in m points to the value y.
Two mappings are said to be compatible if every element present in both of their
domains points to the same range value in both mappings.

Exercise 8.4 Define a Boolean function Compatible with the following
signature which returns true if two mappings m and n are compatible. Try out
your function in VDMTools Lite interpreter.

Compatible: (map nat to nat) * (map nat to nat) -> bool

�

Exercise 8.5 Evaluate the following by hand and then try evaluating them in
VDMTools:

{3 |-> 8, 7 |-> 4, 4 |-> 8} munion {1 |-> 3, 2 |-> 4}
{3 |-> 8, 7 |-> 4, 4 |-> 8} munion {3 |-> 8, 5 |-> 4}
{|->} munion {8 |-> true, 9 |-> false}

�

Returning now to the Introduce function, we can see that we need to take
the existing containers mapping and add a new maplet with cid pointing
to a new Container record made up of the quan and mat values given as
input:

trk.containers munion {cid |-> mk_Container(quan, mat)}



8.4 Modelling with mappings 149

The result of Introduce is a Tracker, so we need to complete the function
definition by making a Tracker from the new containers component and
the old, unchanged, phases component:

mk_Tracker(trk.containers munion
{cid |-> mk_Container(quan, mat)},
trk.phases)

This function requires a pre-condition: if the given container identifier cid has
already been used, it will appear in the domain of trk.containers and
the mapping union could be undefined. We add a pre-condition to ensure that
the new container identifier is indeed new (the operator used here is “not in
set” which stands for the negation of the “in set” membership operator).
The completed function definition is as follows:

Introduce: Tracker * ContainerId * real * Material -> Tracker
Introduce(trk, cid, quan, mat) ==

mk_Tracker(trk.containers munion
{cid |-> mk_Container(quan, mat)},
trk.phases)

pre cid not in set dom trk.containers

Permission to move a container The next function returns a Boolean value
which is true if permission is granted for a given container to move to a given
phase. This function needs to check that the Tracker invariant will be re-
spected by the move, i.e. that the destination phase has room to accommodate
an extra container, and that the container to be moved has a material type which
is expected for the destination phase. A first version of this function can be
defined as follows:

Permission: Tracker * ContainerId * PhaseId -> bool
Permission(mk_Tracker(containers, phases), cid, dest) ==

card phases(dest).contents < phases(dest).capacity and
containers(cid).material in set

phases(dest).expected_materials

Note one problem with this definition: mapping application is used several
times (phases(dest) and containers(cid)), so care must be taken to
ensure that each use is defined. We therefore add two more conjuncts to guaran-
tee this:

Permission: Tracker * ContainerId * PhaseId -> bool
Permission(mk_Tracker(containers, phases), cid, dest) ==

cid in set dom containers and
dest in set dom phases and
card phases(dest).contents < phases(dest).capacity and



150 8 Mappings

containers(cid).material in set
phases(dest).expected_materials

Removing a container The third function describes the removal of a container
from a phase. Given a container identifier and the identifier of the phase from
which it is to be removed, we modify the phases component of the tracker
to reflect the change. The signature and beginning of the function body are as
follows:

Remove: Tracker * ContainerId * PhaseId -> Tracker
Remove(mk_Tracker(containers, phases), cid, pid) == ???

The phases component is to be modified so that pid points to a phase record
which has cid deleted from the contents component and is otherwise un-
changed. The following maplet must be added to phases:

{pid |-> mk_Phase(phases(pid).contents \ {cid},
phases(pid).expected_materials,
phases(pid).capacity)}

If we use munion, the function will be undefined, because pid already occurs
in the domain of phases. In order to modify a mapping rather than just add
a brand new maplet, we need a new map operator: mapping override. This
operator, written ++, is total, unlike munion, and, where the domains of the
two mappings overlap, the mapping on the right of the ++ symbol prevails.
Thus

{3 |-> -7, 12 |-> 0} ++ {12 |-> 4} = {3 |-> -7, 12 |-> 4}

Where the domains do not overlap, the operator behaves in the same way as
munion.

Exercise 8.6 Evaluate the following by hand and then try evaluating them in
VDMTools Lite. Compare your answers with those of Exercise 8.5.

{3 |-> 8, 7 |-> 4, 4 |-> 8} ++ {1 |-> 3, 2 |-> 4}
{3 |-> 8, 7 |-> 4, 4 |-> 8} ++ {3 |-> 3, 5 |-> 4}
{8 |-> true, 9 |-> false} ++ {|->}

�

In the definition of Remove, we use the override operator. The new phases
mapping is the old mapping updated at pid:

phases ++ {pid |-> mk_Phase(phases(pid).contents \ {cid},
phases(pid).expected_materials,
phases(pid).capacity)}



8.4 Modelling with mappings 151

The overall function definition is as follows, including the pre-condition neces-
sary to ensure that the container is being removed from a known phase and that
the container is actually present in the phase:

Remove: Tracker * ContainerId * PhaseId -> Tracker
Remove(mk_Tracker(containers, phases), cid, source) ==
let pha = mk_Phase(phases(source).contents \ {cid},

phases(source).expected_materials,
phases(source).capacity)

in
mk_Tracker(containers, phases ++ {source |-> pha})

pre source in set dom phases and
cid in set phases(source).contents

Notice how we have used a let expression to make the function definition easier
to read.

Moving a container The fourth function describes the movement of containers
between phases. The movement involves both removing the container from its
current phase and adding it to its new phase. For the removal, the Remove
function can be used. For the addition, we can take over the structure of the
definition of Remove. The only difference is that instead of removing using the
set difference operator we must add using the set union operator. Here we get

Move: Tracker * ContainerId * PhaseId * PhaseId -> Tracker
Move(trk, cid, ptoid, pfromid) ==

let pha = mk_Phase(trk.phases(ptoid).contents union {cid},
trk.phases(ptoid).expected_materials,
trk.phases(ptoid).capacity)

in
mk_Tracker(trk.containers,

Remove(trk,cid,pfromid).phases ++
{ptoid |-> pha})

pre Permission(trk, cid, ptoid) and pre_Remove(trk,cid,pfromid)

The pre-condition ensures that there is permission to move the container into the
phase identified by ptoid and that the container can currently be found in the
phase identified by pfromid. The latter is done using the pre-condition quota-
tion technique introduced in Subsection 5.8.3. It is also worth noting that, in the
definition of Move, we have used record selection throughout rather than split-
ting the tracker value using a record pattern as was done for Remove. There is a
trade-off between these two different ways of formulating record manipulation.
In this case the function body had to refer several times to the entire record value
trk. It would seem therefore to be more economical to use a single variable to



152 8 Mappings

stand for the whole record and then use record selection when individual fields
were needed.

Deleting a container The final function to be considered deletes a container
from the plant entirely, given the container’s identifier and the identifier of the
phase in which it occurs. Two things need to be done: the containers map-
ping must be updated so that the container’s identifier is removed from the do-
main and the container’s record is removed from the range; and the phases
mapping must be updated so that the container is removed from the relevant
phase. We have seen how the removal of the container can be accomplished in
the definition of the Remove function, but the removal of the container from the
containers mapping allows us to introduce some new concepts.

The skeleton of the function definition is as follows, including the removal of
the container from the nominated phase:

Delete: Tracker * ContainerId * PhaseId -> Tracker
Delete(mk_Tracker(containers, phases), cid, source) ==

let pha = mk_Phase(phases(source).contents \ {cid},
phases(source).expected_materials,
phases(source).capacity)

in
mk_Tracker(containers with cid removed,

phases ++ {source |-> pha})
pre source in set dom phases and

cid in set phases(source).contents

The pre-condition is identical to the one from Remove.
We need to describe a mapping which is the same as containers, except

that the identifier cid is not in the domain. We can use a map comprehension
for this:

{c |-> containers(c) | c in set dom containers & c <> cid}

The function definition so far is therefore

Delete: Tracker * ContainerId * PhaseId -> Tracker
Delete(mk_Tracker(containers, phases), cid, source) ==

let pha = mk_Phase(phases(source).contents \ {cid},
phases(source).expected_materials,
phases(source).capacity),

con = {c |-> containers(c) | c in set dom containers &
c <> cid}

in
mk_Tracker(con, phases ++ {source |-> pha})

pre source in set dom phases and
cid in set phases(source).contents



8.4 Modelling with mappings 153

This appears rather unwieldy, but the following features in VDM-SL can be
used to simplify it. The domain subtraction operator, written “<-:”, reduces
a mapping to another mapping by removing maplets with designated elements
in their domain parts. Formally, given a mapping m: map A to B and a set
of elements as: set of A, the mapping obtained by subtracting as from the
domain of m is written using the domain subtraction as

as <-: m

and is defined as follows:

as <-: m = {x |-> m(x) | x in set dom m & x not in set as}

This is the mapping which is left when we have removed all the maplets from m
which have an element of as in their domain.

Instead of subtracting maplets from a mapping one can alternatively restrict a
mapping by moving the other entries. This mapping restriction operator, written
“<:”, reduces a mapping to a sub-mapping by removing the maplets which are
not identified in the restricting set. Thus

as <: m = {x |-> m(x) | x in set dom m & x in set as}

holds.
Exercise 8.7 Subtraction and restriction operators on the ranges of mappings

are also available. Thus, the range subtraction operator is written “:->” and
the range restriction operator is written “:>”. For example, the expression m
:-> as represents the mapping obtained by removing from m all maplets with
a range value in the set as. Define “m :-> as” and “m :> as” in the same
way as the domain operators are defined above. �

Domain subtraction is exactly what is required for the Delete function, giv-
ing the following definition:

Delete: Tracker * ContainerId * PhaseId -> Tracker
Delete(mk_Tracker(containers, phases), cid, source) ==
let pha = mk_Phase(phases(source).contents \ {cid},

phases(source).expected_materials,
phases(source).capacity)

in
mk_Tracker({cid} <-: containers,

phases ++ {source |-> pha})
pre source in set dom phases and

cid in set phases(source).contents

The update to the phases component has already been described in the
Remove function, so why not use that function instead of repeating its defi-



154 8 Mappings

nition? This gives us the final version of the Delete function, with the pre-
condition necessary to ensure the removal is defined:

Delete: Tracker * ContainerId * PhaseId -> Tracker
Delete(tkr, cid, source) ==

mk_Tracker({cid} <-: tkr.containers,
Remove(tkr, cid, source).phases)

pre pre_Remove(tkr,cid,source)

Note that we have made the definition easier to read by quoting the pre-condition
of the Remove function. Pre-condition quotation was introduced in Subsec-
tion 5.8.3.

Note also that we have extracted the phases component of the result of the
Remove function. A single variable tkr has been used instead of a pattern for
brevity.

8.5 Summary
• Mappings model function-like relationships between two finite sets of

values called the domain and range respectively.
• Mappings may be represented by enumeration or comprehension.
• Operators exist to extract the domain and range sets of a mapping, up-

date the mapping by mapping union (partial) or override (total), and
reduce the mapping by cutting the domain or the range.

Exercise 8.8 Locating a container The tracker model allows for the possi-
bility that some containers are recorded in the containers mapping but are
not present in any phase. How can you test that the opposite case is excluded by
the invariant using the debugger in VDMTools Lite? �

Exercise 8.9 The following implicit function finds a container, returning the
phase identifier where it is located, or the value <NotAllocated> if the con-
tainer is not allocated to a phase. Modify the function to return a further error
value if the container is not even known in the containers component.

Find(trk:Tracker, cid:ContainerId) p: PhaseId | <NotAllocated>
pre cid in set dom trk.containers
post if exists pid in set dom trk.phases &

cid in set trk.phases(pid).contents
then p in set dom trk.phases and

cid in set trk.phases(p).contents
else p = <NotAllocated>



8.5 Summary 155

�

Exercise 8.10 With the knowledge about how to model systems using map-
pings, revisit the extensions to the explosives example presented in Section 6.5.
Make use of the fact that the names of stores on the site are unique. Redefine
the Store and Site data types and redefine the functions. �

Exercise 8.11� Defining distributed override Define a distributed version
of map override, i.e. a function with the following signature:

Over: seq of (map A to B) -> map A to B

Hint: Use a recursive function definition. Use the interpreter from VDMTools
to evaluate

Over([{1 |-> -1}, {2 |-> 7,3 |-> 8}, {4 |-> -1, 2 |-> 6}])

�

Exercise 8.12� Defining distributed merge The distributed version of the
map union operator, Merge, has the following signature: it takes a set of map-
pings and merges them all into one map.

Merge: set of (map A to B) -> map A to B

Define distributed merge as a map comprehension. If s: set of ( map A to
B), state formally the condition required to ensure that Merge s is defined.
Hint: You need to use recursion here again. Try to use the interpreter from
VDMTools to evaluate

Merge({{1 |-> -1}, {2 |-> 7,3 |-> 8}, {4 |-> -1, 2 |-> 7}})

Compare the result of this with the result obtained by using the built-in operator
merge. �





9
Recursive Structures

Aims
Recursive structures are common in many applications, notably in com-

puter language processing. They present particular modelling challenges and so
we devote a chapter to them. The aim here is to show how recursive data struc-
tures such as trees and graphs are defined and used through recursive traversal.
We do not introduce new VDM language concepts at this stage, but consolidate
the reader’s knowledge and experience by showing how VDM copes with this
important class of system. We add further abstraction lessons by considering the
executability of functions.

9.1 Recursive data structures: trees
Recursion arises in many significant computing applications. In Chap-

ter 7 we introduced recursive functions as a means of traversing collections of
values, and illustrated their use on sequences. However, recursion is also cen-
tral to an understanding of other data structures, including trees and graphs,
that arise in many significant computing applications. This chapter explores
the modelling of such recursive structures further. We begin by examining tree
structures and illustrate their use by examining abstract syntax trees – an applica-
tion area that underpins many applications in design and programming support
environments, including VDMTools. We go on to examine more general graph
structures, using an application from machine code optimisation to illustrate re-
cursive traversal. The abstraction lesson in this chapter concerns the costs and
benefits of executable models.

We begin by considering a common data structure: a tree. A tree is a collec-
tion of points (termed nodes) connected to each other by links (termed arcs). An
example of such a tree (of natural numbers) is shown in Figure 9.1. Each node
may be connected to several other nodes (often called its children) and will itself
typically be a child of a parent node. Nodes with no children are often called
terminal nodes and nodes with no parents are often termed root nodes. Nodes

157



158 9 Recursive Structures

Figure 9.1 A binary tree of natural numbers

12 7

188 54 37

node

leaf

that are neither roots nor terminal nodes are called internal nodes. In Figure 9.1,
the internal nodes hold no data but the terminal nodes hold data.

Tree structures like that of Figure 9.1 are typically defined recursively. As
with all recursive definitions, we consider the simplest (base) case and then the
more complex recursive structure. The simplest kind of tree is a solitary terminal
node. The more complex kind of tree consists of an internal node with other
(sub)trees leading off it. As an example we consider a binary tree (one in which
each non-terminal node has exactly two children). In our example, the terminal
nodes will be natural numbers. This structure is expressed in the following type
definitions:

Tree = nat | Node

A node consists of two subtrees. These are themselves just trees – they could be
single terminal nodes or the roots of subtrees:

Node :: left : Tree
right: Tree

The definition of the type Node uses the type Tree. A Tree may contain a
Node which contains a Tree and so on. The data type definitions for Tree
and Node are mutually recursive.

As trees represent collections of values, we can define functions to traverse
them. Since the tree data structure is recursive, it is not surprising that traversal
functions are normally recursive too. Suppose we are asked to define a function



9.1 Recursive data structures: trees 159

Figure 9.2 Different binary trees can hold the same numbers
in the same order

7

188 54 37

12

12

7 188 54 37

MaxTree, which returns the largest data value present in a Tree. The function
has the following signature:

MaxTree: Tree -> nat

Within the function, given a tree t, we are immediately faced with a choice. If
t is an internal node, say mk Node(l,r), we will return the greater of the
two numbers given by MaxTree(l) and MaxTree(r). If t is just a leaf, we
return the number at the leaf, as this is certainly the greatest number in t. The
traversal function is therefore

MaxTree: Tree -> nat
MaxTree(t) ==
cases t:

mk_Node(l,r) -> max(MaxTree(l),MaxTree(r))
others -> t

end

where max is a simple auxiliary function defined as follows:

max: nat * nat -> nat
max(n1,n2) ==
if n1 > n2
then n1
else n2

Exercise 9.1 Define a similar function SumTree, which returns the sum of
the elements in a tree. �

Let us consider a more sophisticated example. Two trees with different shapes
may still store the same numbers in the same order, e.g. Figure 9.2. Suppose
we are to define a function TestTrees which returns true if the leaves of two
trees have the same values in the same order (following left to right traversal of



160 9 Recursive Structures

the trees). We can do this by converting each tree to a sequence of numbers and
then asking whether the sequences derived from the two trees are the same. The
TestTrees function would have the following definition:

TestTrees: Tree * Tree -> bool
TestTrees(t1,t2) ==

TreeToSeq(t1) = TreeToSeq(t2)

Given a tree, the function TreeToSeq reduces it to a sequence. In this case, we
need a recursion over the input tree, concatenating the sequences corresponding
to the subtrees as we go:

TreeToSeq: Tree -> seq of nat
TreeToSeq(t) ==

cases t:
mk_Node(l,r) -> TreeToSeq(l) ˆ TreeToSeq(r),
others -> [t]

end

Exercise 9.2 Using VDMTools, syntax and type check the definitions of the
functions TestTrees and TreeToSeq given above, and use the interpreter
to test them. �

Exercise 9.3� Many different trees can represent the same sequence of node
values. However, trees need not be binary in the sense that each node leads to
precisely two subtrees. We could generalise trees by allowing a node to point to
an entire collection of subtrees. This collection of subtrees must be ordered so
as to allow traversal in a given direction. Each node is therefore represented as
a (non-empty) sequence of subtrees. This is summarised in the following type
definitions. The type GenTree models generalised trees of natural numbers:

GenTree = nat | Node;
Node = seq of GenTree
inv node == node <> []

Define the functions MaxGenTree and SumGenTree which return the maxi-
mum number in a generalised tree and the sum of the numbers in a generalised
tree respectively.

Hint: The structure of the function definitions reflects the structure of the
data. We used binary operators such as max in the function MaxTree and +
in SumTree. Now, however, we have to obtain the maximum value or sum of
values from a sequence of numbers. Define auxiliary functions to perform these
computations and use them in your answer. �



9.2 Abstract syntax trees 161

Exercise 9.4� Define SetSum: set of nat -> nat as a recursive func-
tion which defines the sum of a set of elements.

Hint: Here you can make use of a let be expression to extract an element
from a set (instead of the hd operator for sequences). A let be expression is
structured as

let pattern in set set-expression be st predicate
in

use-expression

This expression is evaluated as follows:

1. evaluate the set-expression (which should result in a set value)
and match the elements of this set against the pattern;

2. evaluate the optional predicate, replacing each occurrence of the
identifiers from the pattern for each possible binding of elements from
the set;

3. evaluate use-expression, replacing each occurrence of the identi-
fiers from the pattern in use-expression with one of the values
obtained in the binding from 1. This construct can introduce looseness
in the sense that different functional implementations are valid. When
the interpreter from VDMTools Lite executes this construct, an arbi-
trary value is chosen (but the same one will be chosen each time the
same construct is evaluated).

�

9.2 Abstract syntax trees
One of the most significant applications of recursive data types is in

the design of software development environments and compilers. In such sys-
tems, the programs being developed or compiled are stored as abstract syntax
trees (ASTs). Given an AST for a computer program, we can traverse the tree to
check properties such as syntax- and type-correctness, or even to generate target
code. In this section, we will examine an example of the recursive definition
and traversal of an AST using the models that have been used in the design and
development of VDMTools themselves.

First, it is important to draw a distinction between concrete syntax and ab-
stract syntax. The concrete syntax of a language is a set of rules that define
the form that constructs of the language take on the page, including the special



162 9 Recursive Structures

symbols such as keywords used to flag particular language constructs. For ex-
ample, in VDM-SL, the symbol “ˆ” is part of the concrete syntax: it denotes
sequence concatenation. By contrast, the abstract syntax of a language defines
the form that it takes within a computer, regardless of the special symbols used
to indicate particular constructs on the page. For example, the abstract syntax of
a sequence concatenation expression is a tree with a root node containing a value
indicating that this is a concatenation, and two subtrees containing the abstract
syntax of the left and right arguments. We might change the concrete syntax for
sequence concatenation expressions, for example by using a symbol other than
“ˆ”, but the abstract syntax would unchanged: the expression still consists of
two sequences. The concrete syntax of a computer language is often described
using a special purpose notation called Backus Naur Form (BNF). For example,
we have used BNF to describe the syntax of the VDM-SL subset covered in this
book (in Appendix A.12). The abstract syntax may be defined conveniently in
VDM-SL or a similar language.

The VDMTools use abstract syntax trees to store the VDM-SL model that
is being analysed. The design of the tools makes extensive use of recursion to
describe the AST and the functions that manipulate it. For example, the abstract
syntax of VDM-SL expressions includes a large union type that covers the many
possible forms of expression in the language (let-expressions, if-expressions
etc.). This is defined as shown below:

types

Expr = LetExpr | IfExpr | BinaryExpr | UnaryExpr | ...

The abstract syntax of each kind of expression is then defined as a record type.
For example, the type of simple if-expressions (IfExpr) is defined as follows:

IfExpr :: test : Expr
cons : Expr
altn : Expr

Here the record fields represent the Boolean test, the consequence (“then”) part
and the alternative (“else”) part respectively (for simplicity we have omitted
the elseif syntax). Observe that we are modelling the abstract syntax, so
we abstract away from the particular symbols used to represent the conditional
expression, namely the keywords that separate the parts.

All the major components of VDMTools, including the type checker, integrity
checker and code generator introduced in Chapter 3, base their analysis on the
VDM abstract syntax. As an example, let us consider a simple piece of type



9.2 Abstract syntax trees 163

checking. The type checker calculates the type that each expression should have
according to its context. For example, in an if-expression, the test component
ought to be a well-formed Boolean expression. In some cases the actual type of
an expression may not match exactly the contextual requirement, but it ought to
at least be compatible (for example, a natural number would be compatible with
a contextual requirement for a real number).

The type compatibility checks in VDMTools are performed by well-formedness
functions. A function called wf Expr checks the type compatibility of any ex-
pression in the abstract syntax tree. It determines which kind of expression
it is dealing with and calls a more specialised checking function for that kind
of expression. For example, if wf Expr is presented with an if-expression, it
calls the specialised wf IfExpr, passing it the abstract syntax tree for the if-
expression, and the data type that the if-expression is required to match. The
wf IfExpr is defined as follows:

functions

wf_IfExpr: IfExpr * TypeRep -> bool * TypeRep
wf_IfExpr(mk_AS‘IfExpr(test,cons,altn),tp) ==
let btp = mk_BasicTypeRep(BOOLEAN>)
in

let mk_(wf_test, test_tp) = wf_Expr(i, test, btp),
mk_(wf_cons, cons_tp) = wf_Expr(i, cons, tp),
mk_(wf_altn, altn_tp) = wf_Expr(i, altn, tp)

in
let tcomp = IsCompatible(test_tp, btp),

ccomp = IsCompatible(cons_tp, tp),
ecomp = IsCompatible(altn_tp, tp)

in
let m_tp = MergeTypes(cons_tp, altn_tp)
in
mk_(wf_test and wf_cons and wf_altn and

tcomp and ccomp and ecomp,
m_tp)

The wf IfExpr function itself calls the wf Expr function to check the com-
ponent parts of the if-expression. The auxiliary function IsCompatible checks
compatibility of the expected type against the type derived from an expression.
The function MergeTypes merges two type representations together in the
event that different types are derived from the consequence part and the alter-
native part of the if-then-else expression. The Boolean result is true if the com-
ponent parts of the if-statement are all well formed and are of types that are
compatible with the required type.

In reality, the type checking function for an if-then-else expression is more



164 9 Recursive Structures

complicated than our example above because it also needs to provide meaningful
error messages and warnings to the user in cases where the type compatibility
conditions are not met. However, it nevertheless follows the structure given
above.

Exercise 9.5 In this exercise, you are asked to model a simple calculator for
basic arithmetic expressions represented as trees. First define a type for expres-
sions using a tree representation. An expression is a value (an integer), a binary
expression, or a unary expression. A binary expression has three components: a
binary operator, which can be addition, subtraction, multiplication or division,
and two subexpressions, which are themselves expressions. A unary expression
is a unary operator, either minus or plus, and an expression. The representation
used in these type definitions is called the abstract syntax. Where the concrete
syntax representation could be 3+2 the abstract syntax presentation could be
mk BinaryExpr(3,<PLUS>,2). Then define an evaluation function and
test your definition; for instance, try to evaluate the following expressions:

(+5 + (--3)) -(- 7 * (--2))
5*3 + (+10)/0

The first expression should evaluate to 22 and the second should be unde-
fined and give a run-time error. Remember to translate the expressions into your
abstract syntax in order to evaluate them. �

9.3 Directed graphs
We have concentrated so far on tree structures, but recursion is also used

to define more general graph structures. In this section we will see how a graph
can be modelled, and in Section 9.4 will examine an application in the area of
code optimisation that shows the use of recursion to traverse such a graph.

A graph describes a general binary relation between nodes. The arcs (links
between nodes) can be either directed or undirected. In this section we will
restrict ourselves to directed graphs where each node can have a collection of
successors (or children in the terminology for trees). In a tree, each child node
has exactly one parent. In a general graph, however, child nodes may have more
than one parent. For example, the network of roads in a town might be modelled
as a graph with nodes corresponding to intersections. Each node might have
many possible routes into it. A tree would not be appropriate as that only allows
for one route into each intersection. Graphs by contrast, allow the representation
of shared structures.



9.3 Directed graphs 165

If we were to approach the modelling of graphs in the same way as for trees,
we would begin by defining a record type for a node with a set of graphs rep-
resenting the children; these would have their own descendants and so on. The
VDM-SL type definitions would have the following form (ignoring the data to
be stored at internal nodes and leaves):

Graph = [Node];

Node :: children : set of Graph

The problem with this model is that we cannot readily describe the possibility
of shared structure: each node still just has one parent. Instead, recall that a
graph structure represents a binary relation between nodes. It is appropriate
to use a mapping to record that relation: each node requires an identifier and
the mapping records the relationship between a parent node and its set of child
nodes:

Graph = map Id to set of Id

In such a structure, we can represent leaf nodes as identifiers mapping to empty
sets of child nodes. Thus every node identifier in the range must itself occur in
the domain. We record this as an invariant:

Graph = map Id to set of Id
inv g == dunion rng g subset dom g;

Root nodes have children, and so appear in the domain, but do not appear in the
range, and the invariant permits this.

The type definition for a graph is not itself recursive in the sense that a type
name appears in the definition of its own representation, as was the case for the
tree structures described above. However, because they are highly structured
collections of values, graphs are often traversed by recursive functions. As an
example, we consider a function to determine whether or not a graph is acyclic.
A graph is said to be acyclic (free of loops) if it is not possible to get from a
node back to itself by following the arcs in the graph.

A graph is cyclic (there is a loop) if there is some node that is among its
own descendants, so first we calculate all the descendants of a given node. The
acyclicity property is then stated as a requirement that there should be no node
that is among its own descendants:

AcyclicGraph = Graph
inv acg ==

not exists id in set dom acg &
id in set Descendants(acg,id);



166 9 Recursive Structures

The descendants of a node are its children, and their descendants. If we have
defined a function Descendants as follows:

Descendants: Graph * Id -> set of Id

then we might suppose that the descendants of a node id in a graph g are given
by the expression

dunion {Descendants(g,c) | c in set g(id)}

Indeed, we might use this expression to define the function, along with a pre-
condition to ensure that id exists in the graph.

Descendants: Graph * Id -> set of Id
Descendants(g,id) ==

dunion {Descendants(g,c) | c in set g(id)}
pre id in set dom g;

The difficulty posed by such a definition is that termination cannot be guaranteed
if the graph is cyclic. Should a loop be present, we will carry on gathering nodes
that have already been visited. In order to ensure termination, we keep a record
of all the nodes visited so far and terminate when no new nodes are added on a
call. We redefine the Descendants function as follows:

Descendants: Graph * Id * set of Id -> set of Id
Descendants(g,id,reached) ==

if id in set reached
then {}
else {id} union

dunion {Descendants(g,c,reached union {id})
| c in set g(id)}

pre id in set dom g

The recursive collection of descendants can then be started off with an empty
set by a top-level function:

AllDesc: Graph * Id -> set of Id
AllDesc(g,id) ==

dunion {Descendants(g,c,{})| c in set g(id)}
pre id in set dom g;

Now the acyclicity constraint can be expressed as

AcyclicGraph = Graph
inv acg ==

not exists id in set dom acg &
id in set AllDesc(acg,id);

Exercise 9.6� In the model above the type Id represents unique identifiers
for the nodes of a graph. Many applications also require that the arcs connecting



9.4 An application of directed graphs: code optimisation 167

nodes also have unique identifiers. In order to model such a labelled graph, we
could use two identifier types, say NodeId and ArcId, to represent the labels
on nodes and arcs respectively. A type LabGraph representing labelled graphs
could then be defined as follows:

LabGraph = map NodeId to (map ArcId to NodeId)

Define new versions of all the functions given for Graphs above to work for
LabGraphs. Add an invariant to ensure that the ArcIds are unique in a
LabGraph. �

9.4 An application of directed graphs: code optimisation
Graphs are exploited in many areas of computer science. One interest-

ing application is in the optimisation of low-level machine code produced by
compilers. We can model the structure of a machine code program as a con-
trol flow graph in which the nodes correspond to blocks of instructions to be
executed in order. At the end of each block, a jump instruction determines the
address in memory of the next block to be executed and passes control on to that
block. In the control flow graph, arcs connect each block to its possible succes-
sors. By examining the graph’s structure, it is often possible to identify transfor-
mations that modify the structure of the code, optimising its performance. For
example, two or more blocks that form a linear path may be combined into a sin-
gle block, eliminating the computationally expensive jump instructions between
them.

The logic of code optimisation is sometimes intricate, so formal techniques
have been used to describe and validate such optimising transformations. In this
section we will look at an example optimisation based on the potential merging
of blocks. The purpose of the model is to describe just this optimisation, so the
abstraction retains the block and jump structure of the code being optimised but
suppresses detail of the individual instructions within blocks.

The structure of a program can be modelled as a graph with the nodes repre-
senting blocks and each arc representing a jump from the end of one block to
the start of another. Since two or more blocks might finish by jumping to the
start of the same subsequent block, this is a graph structure and not a tree.

For the optimisation in question, we identify linear paths in which each block
has only one parent and one child. In order to model this, we first define the lin-
ear path concept and then describe a function to detect linear paths in a control
flow graph, as candidates for merging. We will use the Graphmodel already in-



168 9 Recursive Structures

troduced, bearing in mind that the graph might be cyclic because loop structures
can occur in machine code programs.

A path is a non-empty sequence of node identifiers:

Path = seq1 of Id

We aim to identify all the paths that are linear, so we will first define a function
that returns the set of all paths in a given graph and then define the property of
being a linear path. We will call a linear path a chain. Ultimately, we will want
a function in the following form:

Chains: Graph -> set of Path
Chains(g) == {p | p : Path & IsLinear(g,p)}

We will return to the Chains function after looking at IsLinear in more
detail. A path p is linear in graph g if all the nodes except the last have the next
node in the path as their only child, and all the nodes except the first have their
predecessor as their only parent in the graph:

forall i in set inds p & i > 1 => g(p(i-1)) = {p(i)} and
i < len p => g(p(i)) = {p(i+1)}

For a path to be linear, it must have at least two nodes and all the node identifiers
in the path must exist in the graph, so a more comprehensive version of the
condition is as follows:

len p >= 1 and
elems p subset dom g and
forall i in set inds p & i > 1 => g(p(i-1)) = {p(i)} and

i < len p => g(p(i)) = {p(i+1)}

There is still a problem with this model. Recall that graphs may be cyclic.
Consequently, it is possible to have paths that contain any number of circuits
round a loop. This is eliminated by requiring that no identifier appears twice in a
linear path, hence the final conjunct and the following definition of IsLinear:

IsLinear: Graph * Path -> bool
IsLinear(g,p) ==

len p >= 1 and
elems p subset (dom g union rng g) and
(forall i in set inds p & i > 1 => g(p(i-1)) = {p(i)} and

i < len p => g(p(i)) = {p(i+1)}) and
not exists i,j in set inds p & i<>j and p(i) = p(j)

The Chains function returns all the linear paths in a control flow graph. One
interesting observation is that, where a graph contains long chains, the function
will return all the sub-chains of each chain, as well as the chain itself.



9.5 Abstraction lesson: executability 169

Exercise 9.7 Define a function SubPath that, given two paths, returns a
Boolean value indicating whether one path is a sub-path of the other. Use this
to define a version of the Chains function that returns the longest chains only,
and not their sub-chains. �

9.5 Abstraction lesson: executability

Although we have a clean characterisation of all the linear paths present
in a control flow graph, the Chains function uses a type binding and so is not
directly executable (see Section 4.5). In order to execute it as defined, we would
have to search through all the possible sequences of node identifiers (potentially
an unbounded collection) in order to find all the sequences that happen to be
linear paths in the graph. If we wish to execute this part of the model, we will
have to use a set binding at this point. This would lead to a Chains function of
the following form:

Chains: Graph -> set of Path
Chains(g) == {p | p in set AllPaths(g) & IsLinear(g,p)}

In order to define AllPathswe will need to traverse the graph g, generating all
the paths and taking account of the possibility of loops. The traversal functions
take the same form as the Descendants functions above. We use a set of
visited nodes as a mechanism for ensuring termination of the recursion:

Paths: Graph * Id -> set of Path
Paths(g,id) ==
PathsFromNode(g,id,{});

PathsFromNode: Graph * Id * set of Id -> set of Path
Paths(g,id,s) ==
let children = g(id)
in

if children = {}
then {[id]}
else dunion {{[id] ˆ p | p in set Paths(g, c, s union {id})}

| c in set children}
pre id in set dom g;



170 9 Recursive Structures

Executable or not?
There are many possible graph and tree traversal algorithms that
can be expressed using recursion. If the characteristics of the
algorithm are significant to the purpose of the model, it is ap-
propriate to express traversal that way. However, the directly
executable version is often less easy to comprehend and anal-
yse because of the algorithmic detail. The purpose of the model
derived above is to clarify the logic governing the optimisation
and so a clearer, but non-executable, model might be preferred.
The price paid for using a non-executable model is that it cannot
be readily tested. On occasion it may be possible to combine
implicit function definitions which use pre- and post-conditions
with explicit executable definitions. The VDMTools pre- and
post-condition checking facility allows the explicit version to be
tested, with the pre- and post-conditions being checked before
and after execution of the function. This technique is, however,
only a partial solution since it requires that the pre- and post-
conditions can themselves be executed, so this does not solve
the problem posed by type bindings.
The debate over whether the loss of abstraction is a price worth
paying for executability has been conducted in the scientific lit-
erature. It is well worth reading Hayes and Jones’ defence of
the non-executable model [Hayes&89] and the responses from
Fuchs [Fuchs92] and Andersen et al. [Andersen&92].

Summary
• Tree structures may be modelled by recursive type definitions. Graphs

with shared sub-structures are often modelled via mapping structures
expressing the relation between nodes and their successors. Recursive
functions are used to traverse trees and graphs.

• In defining traversal functions on potentially cyclic graphs, beware of
the need to keep a history of visited nodes. Without such a history, the
traversal function might not terminate.

• Executability is often in tension with abstraction because of the need for
algorithmic detail to be included in the model to facilitate execution. It
is necessary to trade the benefit of executability off against the possible
reduction in comprehensibility of the model.



10
Validating Models

Aims
An important aspect of the analysis of a model is gaining confidence

that the model is an accurate reflection of the informally stated requirements.
This chapter aims to provide an awareness of the techniques through which such
confidence can be gained. The idea of model validation is introduced: checks for
internal consistency are discussed; techniques of visualisation, integration with
legacy code, testing and proof are illustrated. On completion of this chapter,
the reader should be equipped to choose appropriate validation techniques for a
given modelling task.

10.1 Introduction
In previous chapters we have introduced a number of different models

in VDM-SL. In several cases (e.g. the alarm example in Chapter 2) we started
from an informal collection of requirements and built up a model in stages. But
just how confident can one be that the formal model really describes the sys-
tem the customer wanted? This problem arises continually in industry. When
the imprecision of the customer requirement is replaced by the precision of a
model, how can the modeller be sure that those areas of incompleteness and am-
biguity in the original requirement have been resolved in a way that satisfies the
customer? There is a further complication: requirement documents often state
the client’s intentions incorrectly. Such errors can only be resolved by somehow
presenting a model of the system to the client in order to obtain feedback which
may lead to modifying the model.

Any checks which can be performed on a formal model to improve the mod-
eller’s confidence in its soundness and the customer’s confidence that it has cap-
tured the real requirements would be of great benefit in resolving errors before
they become extremely expensive to correct. Models written in VDM-SL can, of
course, be subjected to inspection just as informal models or programs may be.
However, models in VDM-SL have the advantage of being written in a language
with a very clearly defined syntax and semantics, and are therefore amenable to

171



172 10 Validating Models

checking with the aid of a machine. Readers using VDMTools Lite will already
have some experience of investigating models using the debugger. However,
this is not the only way to get more confidence in a model.

This chapter presents techniques for the validation of formal models. We use
the term validation to mean those activities which increase the modeller’s and
customer’s confidence in a model. There are two aspects to this:

• checking that the model is internally consistent, i.e. that the definitions
are meaningful (for example, that expressions are not undefined and that
functions do not allow invariants to be broken);

• checking that the model accurately represents the required behaviour of
the system being modelled.

With respect to internal consistency, we have seen how machine support, such
as that available in VDMTools Lite, can be used for syntax and type checking.
Such facilities are very useful, but, just as with programming languages, they
do not allow us to detect all the errors – readers will know from experience how
easy it is to write a type-correct program which still crashes for some inputs!
There are still more subtle faults which we would like to be able to identify. For
example, functions should return results of the correct type. For a result to be
of the correct type, it must respect any invariant defined on the result type. As
another example, a function definition may use a partial operator, and therefore
risk being undefined for inputs, though if the function’s pre-condition prevents
inputs that cause undefinedness, the function is perfectly good.

In order to check automatically that an invariant is respected, we would have
to be able to construct a machine which could verify the invariant on all possible
result values from the function, and this is not possible in general. Likewise,
we cannot develop a machine which ensures that the application of any partial
operator is satisfactory for all possible input values satisfying a pre-condition. In
this “grey area”, in which it is difficult to decide automatically whether a model
contains such subtle errors or not, we use a technique based on proof obligations
to help us determine whether or not a model is sound. Much of the research in
tool support for modelling is aimed at reducing the size of this grey area by
developing tools that can perform more and more subtle checks automatically.
We introduce the concept of proof obligations in Section 10.2.

Besides checking internal consistency, the other important aspect of valida-
tion is determining whether the model accurately records the system’s intended
behaviour. So far, we have only used the interpreter in VDMTools Lite for this
purpose, but in Sections 10.3 to 10.6 we will present four different systematic
approaches which can be used to analyse whether the customer’s requirements



10.2 Internal consistency: proof obligations 173

for the system are captured by the VDM model. The first of these approaches
illustrates how models can be visualised for the benefit of people who are not
familiar with the VDM-SL notation. The second approach is only needed when
the VDM model needs to be integrated with existing legacy code that itself is
not modelled. In this case it is important to gain confidence in the feasibility of
the interface used for this integration. The third approach exploits mathematical
proof to ensure that the intended behaviour is captured. The fourth approach
utilises systematic testing with additional features such as test coverage and test
case generation. These four techniques provide different levels of confidence
and insight at different costs; the selection of a cost-effective validation tech-
nique is discussed in Section 10.7.

10.2 Internal consistency: proof obligations
Confirming the internal logical consistency of a model is far from triv-

ial. As an example, consider the use of partial operators. Partial operators (intro-
duced in Section 5.1) are defined only for aplication to certain inputs. Applying
such an operator to a value on which it is not defined (for example, perform-
ing a numeric division by zero) may yield any outcome, including nontermina-
tion. An important aspect of internal consistency checking is therefore ensuring
that all applications of partial operators are valid. In fact, we cannot develop a
completely general tool which, given any model, can automatically determine
whether all applications of partial operators are valid. To understand why this
is so, consider a recursive function SumSeq which calculates the sum of a se-
quence of integers:

SumSeq: seq of int -> int
SumSeq(l) ==
if l <> []
then hd l + SumSeq(tl l)
else 0

Two partial operators have been used in the example: hd and tl are both unde-
fined if applied to the empty sequence. The reader can see that they have both
been used safely in SumSeq because the test in the if-then-else expres-
sion acts as a guard, protecting these delicate partial operators from the possi-
bility of being applied to an empty sequence. A tool performing the same check
would need to look beyond the then expression to see enough of the context in
which hd and tl are used in order to confirm validity. In this example, the tool
would have to look to the guard in the if expression. In this example, the guard
expression is a simple comparison of the input l with the empty sequence, so it



174 10 Validating Models

is conceivable that a tool might be programmed to detect the guard and work out
that the operator use is valid. However, in general, the test could be an arbitrarily
complex logical formula, making it much more difficult to check automatically
whether the operator applications are always defined or not. In addition, there
are many other ways of protecting applications of partial operators: the sound-
ness of an operator application could rely on a pre-condition or on data type
invariants. In these cases, the tool would have to be very clever, looking well
beyond the application of the operator itself to the surrounding context of the
whole model, in order to spot relevant pre-conditions and invariants.

The expressiveness of VDM-SL is sufficient to ensure that a completely gen-
eral checker that discovers all the invalid uses of partial operators cannot be built,
although checkers for special cases can be constructed. The integrity-checking
feature in VDMTools Lite takes a conservative view: it detects all the uses of a
construct where there might be a risk of having an inconsistency, e.g. invariant
violation or a run-time error. In a proportion of cases these potential errors turn
out to be false positives because of guards. Nevertheless, the integrity checker
is a valuable tool for increasing confidence in a model’s internal consistency. In
the remainder of this section, we examine the full range of integrity checks that
can be performed on a VDM-SL model.

10.2.1 The idea of a proof obligation
The integrity checks to be performed on VDM models are called proof

obligations. A proof obligation is a logical expression which must be proved
to hold before a VDM model can be regarded as formally internally consistent.
Often simple inspection of such proof obligations may indicate situations which
have not yet been taken into account. If one wishes to be more rigorous it is also
possible to construct mathematical proofs that these obligations hold. We return
to the idea of proof in Section 10.6.

The following subsections will define proof obligations for models in VDM-
SL. The obligations largely ensure that function definitions do not break data
type invariants and that operators and user-defined functions are applied only
within their defined domains. We will use the tracker example from Chapter 8
to introduce these different kinds of proof obligations.

10.2.2 Domain checking
Although the Logic of Partial Functions (LPF) introduced in Section 4.6

allows us to reason with undefined values, the use of a partial operator outside its



10.2 Internal consistency: proof obligations 175

defined domain usually indicates an error on the part of the modeller. We should
therefore perform checks to identify potential cases of operator misapplication.
Two kinds of construct are impossible to check automatically:

• applications of functions having a pre-condition; and
• applications of partial operators.

The difference between these is that functions are defined by the user whereas
partial operators are built into the notation.

Functions with pre-conditions In the tracker example, the only time a function
is applied is within the definition of Delete (it is the case of the Remove
function):

Delete: Tracker * ContainerId * PhaseId -> Tracker
Delete(tkr, cid, source) ==

mk_Tracker({cid} <-: tkr.containers,
Remove(tkr, cid, source).phases)

pre pre_Remove(tkr,cid,source)

Since Remove does have a pre-condition it is the responsibility of the calling
function (in this case Delete) to ensure that its pre-condition is satisfied when
Remove is applied. In this example we would get a proof obligation like

forall tkr:Tracker, cid:ContainerId, source:PhaseId &
pre_Delete(tkr,cid,source) =>

pre_Remove(tkr,cid,source)

The obligation states that, for all possible combinations of input to Delete
which satisfy its pre-condition, it must be guaranteed that Remove is applied
within its defined domain.

In this particular case it is very easy to meet this proof obligation because
the pre-condition of Delete is defined to be identical to the pre-condition for
Remove.

Partial operators In the tracker example the only partial operators used are
mapping union and mapping application. The munion operator is used in the
Introduce function:

Introduce: Tracker * ContainerId * real * Material ->
Tracker

Introduce(trk, cid, quan, mat) ==
mk_Tracker(trk.containers munion

{cid |-> mk_Container(quan, mat)},
trk.phases)

pre cid not in set dom trk.containers



176 10 Validating Models

Here the proof obligation which would be generated is

forall trk:Tracker, cid:ContainerId, quan:real, mat:Material &
cid not in set dom trk.containers =>
forall c1 in set dom trk.containers,

c2 in set dom {cid |-> mk_Container(quan,mat)} &
c1 = c2 => trk.containers(c1) =

{cid |-> mk_Container(quan,mat)}(c2)

At first glance this may look very complicated, but it simply states that for
all possible inputs to Introduce satisfying its pre-condition we can ensure
that the two mappings used as arguments to the munion operator are compat-
ible, i.e. if they have overlapping domain elements they must map to the same
range values. In this case the pre-condition for Introduce is actually stronger
than strictly necessary: the use of the munion operator would still be valid if
cid did belong to the domain of the container map provided it mapped to the
mk Container(quan,mat) value already. However, it is often the case that
the pre-condition is intentionally more strict than required for the sound applica-
tion of the operators. In this case we would not like to introduce a new container
if it already exists in the system.

In the tracker example there are many places where a mapping is applied. For
each of these places there is a proof obligation on the modeller to ensure that the
mapping is applied to values belonging to its domain. This is ensured either by
including an explicit check in the body of the function that the value belongs to
the domain, or by recording this requirement as a part of the pre-condition for
the function. In Permission the first approach is taken, whereas the second
approach is taken, for example, in Move.

The Permission function is defined as follows:

Permission: Tracker * ContainerId * PhaseId -> bool
Permission(mk_Tracker(containers, phases), cid, dest) ==

cid in set dom containers and
dest in set dom phases and
card phases(dest).contents < phases(dest).capacity and
containers(cid).material in set

phases(dest).expected_materials

Here the mapping application expression “phases(dest)” is written three
times and one would expect to get a proof obligation like

forall mk_Tracker(containers, phases): Tracker,
cid: ContainerId, dest:PhaseId &
(cid in set dom containers and
dest in set dom phases) => dest in set dom phases



10.2 Internal consistency: proof obligations 177

However, the integrity checker of VDMTools Lite is able to see that this map-
ping application is carefully guarded by the “dest in set dom phases”
expression. Thus, trivial proof obligations like these are simply omitted in order
not to have the user waste time in inspecting trivially correct proof obligations.

Exercise 10.1 Proof obligation for Move The Move function is defined as
follows:

Move: Tracker * ContainerId * PhaseId * PhaseId -> Tracker
Move(trk, cid, ptoid, pfromid) ==
let cont = trk.phases(ptoid)
in
let pha = mk_Phase(cont.contents union {cid},

cont.expected_materials,
cont.capacity)

in
mk_Tracker(trk.containers,

Remove(trk,cid,pfromid).phases ++
{ptoid |-> pha})

pre Permission(trk, cid, ptoid) and
pre_Remove(trk,cid,pfromid)

What is the proof obligation automatically generated for the map application
expression trk.phases(ptoid)? �

It can be difficult to decide what conditions should be placed
in a pre-condition. Some conditions are determined by the
required functionality. Many, however, are present simply to
guard against misapplication of partial operators. We therefore
recommend systematically reading through each function body
and highlighting every use of a partial operator. In each case, it
is worth asking “Is this use protected, i.e. can one be certain that
the operator’s argument is in its domain?”. For uses of a partial
operator which is not protected, add a suitable conjunct to the
pre-condition.

10.2.3 Respecting invariants in explicit definitions
The proof obligation for a plain explicit function definition (without a

pre-condition) requires that the function should produce an output of the correct
type for any input of the correct type. Recall that a type’s definition may contain
an invariant of a function. For the output of a function to be of the correct type,
it must respect that type’s invariant. Much of the work in checking a function



178 10 Validating Models

definition lies in ensuring that the output respects the invariant. An explicit
function definition:

f: T1 * ... * Tn -> R
f(p1,...,pn) == expression defining result

is said to respect the invariant of R if, for all combinations of inputs

a1:T1,..., an:Tn

the function application

f(a1,...,an)

is of type R (and therefore obeys the invariant on R). Recall that membership of
a data type means that a value respects the invariant for that type; so the values
a1,...,an are known to respect any invariants on the types T1,...,Tn
respectively.

The obligation is stated formally as follows1:

forall a1:T1,...,an:Tn & f(a1,...,an):R

In the tracker example, all the functions which return a value of type Tracker
are required to respect the invariant on Tracker. They do this by having pre-
conditions. When a pre-condition is present, the proof obligation is the same as
before, except that the function is only required to return a value of the correct
type when applied to arguments which satisfy the pre-condition.

An explicit function definition with a pre-condition:

f: T1 * ... * Tn -> R
f(p1,...,pn) == expression defining result
pre logical expression

is said to respect the invariant of R if, for all combinations of arguments

a1:T1, ..., an:Tn

satisfying the pre-condition, the function application

f(a1,...an)

is of type R (and therefore obeys the invariant on R).
The obligation is stated formally as follows:

forall a1:T1,...,an:Tn &
pre_f(a1,...,an) => f(a1,...,an):R

1 Note that the proof obligation does not form part of the model – it is a logical formula
derived from the model. The modeller has to provide an argument that the obligation is
true.



10.2 Internal consistency: proof obligations 179

For example, the Remove function was defined as follows:

Remove: Tracker * ContainerId * PhaseId -> Tracker
Remove(mk_Tracker(containers, phases), cid, source) ==
let pha = mk_Phase(phases(source).contents \ {cid},

phases(source).expected_materials,
phases(source).capacity)

in
mk_Tracker(containers, phases ++ {source |-> pha})

pre source in set dom phases and
cid in set phases(source).contents

Here the proof obligation would be stated as follows:

forall tkr:Tracker, cid:ContainerId, source:PhaseId &
pre_Remove(tkr,cid,source) =>

is_(Remove(tkr,cid,source),Tracker)

The is (Remove(tkr,cid,source),Tracker) is a generalised form
of an is-expression called a type judgement. The expression is (e,t) is equal
to true if and only if e is of type t.

The type checker is able to confirm that the body of Remove has the correct
structure for a Tracker value but it cannot guarantee that the data type invari-
ant for Tracker is satisfied. Thus, it is the modeller’s responsibility to ensure
this, whether by inspection, testing or proof.

10.2.4 Satisfiability of implicit definitions
So far, we have concentrated on explicit definitions of functions. There

are proof obligations for implicit function definitions as well. Remember that
an implicit function definition does not define how to compute a result for a
function: it simply characterises the result by giving its essential properties.

The syntax for an implicitly defined function is as follows:

f(p1:T1,...,pn:Tn) r:R
pre logical expression
post logical expression

The implicit function definition states that, for any inputs satisfying the pre-
condition, the result of the function application is any value r which satisfies
the post-condition.

The proof obligation for an implicit definition is given a special name: the
satisfiability proof obligation. This obligation defines two checks. For any set
of arguments satisfying the pre-condition, the writer of the model must show
that there exists at least one result and the result is of type R, and therefore that



180 10 Validating Models

it respects the invariant on R, if any. Recall that, for the first definition made for
the ExpertToPage from Section 2.9, there did not exist any results in certain
situations.

The implicit function definition of f is said to be satisfiable if, for all argu-
ments a1,...,an of types T1,...,Tn for which pre f(a1,...,an) is
true, there is some value r of type R (respecting the invariant), such that the
logical expression post f(a1,...,an,r) is true.

Presented formally:

forall a1:T1,...,an:Tn &
pre_f(a1,...,an) => exists r:R & post_f(a1,...,an,r)

In the tracker example the Find function is defined implicitly in Exercise 8.9.
The definition is

Find(trk:Tracker, cid:ContainerId) p: (PhaseId |
<NotAllocated>)

pre cid in set dom trk.containers
post if exists pid in set dom trk.phases &

cid in set trk.phases(pid).contents
then p in set dom trk.phases and

cid in set trk.phases(p).contents
else p = <NotAllocated>

Here the proof obligation for its satisfiability can be expressed as

forall trk:Tracker, cid:ContainerId &
pre_Find(trk,cid) =>
exists p:PhaseId | <NotAllocated> & post_Find(trk,cid,p)

Suppose the post-condition of Find had simply been defined as

post p in set dom trk.phases and
cid in set trk.phases(p).contents

In this case it would not have been possible to meet the proof obligation above
because it is not guaranteed that a phase p satisfying this post-condition can be
found for all input values satisfying the pre-condition. However, the way the
function has been defined using an if-then-else structure takes care of this
situation. Without this, we would have the same situation as for ExpertToPage
because no phase identification can be returned if the container is not allocated
to any phase.

10.3 Visualisation of a model
Remember that the goal of validating a formal model is to increase con-

fidence that the model accurately reflects the customer’s stated or unstated inten-



10.3 Visualisation of a model 181

Figure 10.1 User interface for the tracker example

New
containers

Storage

Unpacking

Assay

Sorting

Compaction

Delete

Removal

Move

Introduce

Permission
ContainerId

Move container to phase 

Quit

WEP1776B
WEP1776D
WEP93359
EXT2131X
EXT3434X

Phase Empty

MEP1771D

MEP1771D

WEP21123
WEP21145
MEP1771A
MEP1771C
EXT1993A

OK Cancel

From

PhaseId Compaction

Assay

tions. Checking for internal consistency of the model is not enough on its own
to achieve this. It is possible to write a perfectly syntax- and type-correct, inter-
nally consistent model which describes something other than what the customer
actually wanted!



182 10 Validating Models

In order to check this correspondence with the customer’s wishes, we as-
sess the system behaviour described by the model in collaboration with the cus-
tomer and/or other domain experts. One valuable approach is visualisation of
the model. The model is usually expressed in a special notation, be it mathemat-
ics, UML diagrams or VDM-SL, with which the customer may be unfamiliar.
One way of communicating the content of the model is to execute it, using an
interface which hides the details of the model, but which allows the functions to
be invoked in an intuitive way. This allows the customer to assess the behaviour
described in the model and give feedback leading to its improvement.

The full version of VDMTools has an Application Programmer Interface (API)
based on CORBA [OMG&96] that supports visualisation. However, this feature
is not available in VDMTools Lite. VDMTools provide an Object Request Bro-
ker (ORB) [omniORB3] for both C++ and Java, enabling an external program
written in one of these languages to interact with VDMTools as a separate pro-
cess. This feature enables a prototype of the system to be demonstrated using a
heterogeneous model. Typically the part which is implemented in Java or C++
is a relatively simple piece of code used to visualise the system in the form of a
user interface.

For the tracker example we can imagine creating a simple user interface di-
rectly in C++ or Java. This might be as presented in Figure 10.1.

10.4 Interfacing to legacy code
The dynamic link feature of VDMTools (not available in VDMTools

Lite) supports interfacing to external (e.g. legacy) code. This feature enables
the modeller to interpret a model where parts are described using VDM-SL as
usual and parts are described directly in C++ code. This code is compiled into
a library which is dynamically linked into the interpreter for VDMTools and
the parts of the system described in VDM-SL. This enables a combination of a
VDM-SL model with legacy code that the VDM model must extend in one way
or another.

In the tracker example it could, for example, be required that the new ap-
plication to be developed using VDM-SL should be integrated with an existing
database already used for initialising containers. In this case it would be possible
to define a dynamic link module of the following form:

dlmodule DB
exports
operations

OpenDB: () ==> bool;



10.5 Systematic testing 183

CloseDB: () ==> bool;
SetContainerInfo: seq of char ==> ();
ExecuteSqlCom: seq of char ==>

seq of seq of (char | real | bool | token)

uselib "db.so"

end DB

Note that interfacing to legacy code must be done in the context of a modular
model (modular structuring is described in Chapter 12). In this example, the
information about the database interface is presented in a dynamic link mod-
ule which exports the functionality that constitutes the interface to the legacy
code. The actual compiled code is placed in a shared object file whose name is
indicated with the uselib keyword.

10.5 Systematic testing
Validation through visualisation involves executing scenarios on the for-

mal model through the dynamically linked interface. The confidence gained in
the model is only as good as the particular scenarios used. We can gain confi-
dence that a model accurately reflects informally stated requirements by more
systematic testing on the formal model itself. For each test case the result ob-
tained by interpreting the formal model can be inspected. If the result is not as
expected the model must be adjusted. Otherwise our confidence in its correct-
ness is increased whenever new test cases are applied.

The production of separate test cases can be done manually or automatically.
The main problem with automating the generation of test cases is keeping their
number sufficiently low to allow the tests to be carried out within a reasonable
time and cost.

Given a test environment with a collection of inputs and a script that automat-
ically executes them and compares the results with those expected, it is possible
to obtain information about the coverage provided by the tests. Techniques for
assessing test coverage are widely known for programming languages but can
also be used on the executable subset of VDM-SL.

Suppose we would like to test the Permission function. We could, for
example, run the following:

Permission(mk_Tracker({|->},{|->}),mk_token(1),mk_token(2))

This test yields false. The test coverage information available for this function



184 10 Validating Models

after evaluating this single argument shows which subexpressions have not yet
been evaluated (indicated by the boxes below):

Permission: Tracker * ContainerId * PhaseId -> bool
Permission(mk_Tracker(containers, phases), cid, dest) ==
cid in set dom containers and

dest in set dom phases and

card phases(dest).contents < phases(dest).capacity and

containers(cid).material in set phases(dest).expected materials

Users of VDMTools Lite will also be able to see how expressions such as this
are evaluated. Because the first conjunct cid in set dom containers
yields false the other parts of the function are never evaluated.

Exercise 10.2 Test coverage of Permission Define test inputs for the
Permission function which cover the first two conjuncts, the first three con-
juncts and finally the entire Permission function. Debug each of the applica-
tions to convince yourself that all parts have been evaluated and use the test cov-
erage feature to display the coverage. Note that in order to appropriately display
test coverage information one must either use the .rtf format with Microsoft
Word or mix the VDM model inside a LATEX document. See the VDMTools user
manual for details [UserMan]. �

10.6 Using proofs

While systematic testing provides a thorough way of exercising a model,
the confidence gained is only as good as the particular test sets used. Proof is
a technique which allows the modeller to assess the behaviour of the model for
whole classes of inputs at once. When using proof to determine whether a model
reflects the informally expressed intentions, the customer must express certain
properties he or she wishes to hold for the system. Each property must then be
formalised in terms of a logical expression. A logical expression describing a
property which is expected to hold in a model is called a validation conjecture.
The techniques of mathematical proof allow the property to be verified as a
consequence of the definitions in the model.

Proofs can be time-consuming. Machine support for formal proof is rather
limited at present, and some considerable additional skill is required to construct
a proof. However, a successful proof does give a high degree of confidence that
all the possible cases have been considered.



10.6 Using proofs 185

A proof based on a formal model can be carried out at various levels of rigour.
Three are identified in particular:

“Textbook” Proof: This is the level of rigour found in most general mathemat-
ics texts. The argument is made in English, supported by formulae, justifica-
tions for steps in the reasoning often appealing to human insight. This is the
easiest of the three styles of proof to read, but the reliance on intuition means
that such proofs can only be checked by other human beings.

Formal Proof: At the other extreme, a fully formal proof (of the kind discussed
in [Bicarregui&94]) is a highly structured sequence of assertions in a well-
defined logical language. Each step is justified by appealing to a formally
stated rule of inference. A formal proof is so detailed that it can be checked
or even constructed mechanically. It is possible to be very confident about
such a proof, but construction of one can be very laborious. Formal proof is
most frequently employed in safety- or security-critical applications.

Rigorous Proof: This refers to a proof which borrows the ideas of careful struc-
turing and line-by-line justification from formal proof, but relaxes some of
the strictures which make the production of a formal proof so costly. Ob-
vious hypotheses may be omitted, abbreviations may be used, justifications
may appeal to general theories rather than to specific rules of inference.

For the tracker example we can consider a validation conjecture which states
that any phase holds only those containers which contain the correct kind of
material for that phase. When this requirement is formalised it has the following
form:

forall trk: Tracker &
forall phase in set rng trk.phases &

forall cid in set phase.contents &
trk.containers(cid).material in set
phase.expected_materials

This expression contains three universal quantifications nested inside each other.
It states that for any tracker phase inside the tracker’s phases mapping, and
any container identifier inside the contents of that phase, the material inside the
container identified must be a kind of material expected from the phase.

A “textbook” proof of the validation conjecture could be formulated as

The invariant for the Tracker type includes a call of the auxiliary function

MaterialSafe and Consistent and these two ensure that the validation

conjecture holds. MaterialSafe is formulated in exactly the same way as the



186 10 Validating Models

body of the outermost universal quantified expression. Consistent ensures

that the containers inside a phase are known in the containers mapping.

A rigorous proof of the same validation conjecture could take the following
form:

from trk:Tracker
1 from phase in set rng trk.phases, cid in set phase.contents
1.1 inv_Tracker(trk) Tracker-defn(h)
1.2 Consistent(trk.containers,trk.phases) and-E(Unfold(1.1))
1.3 phase.contents subset dom trk.containers

forall-E(Unfold(1.2),1.h1)
1.4 MaterialSafe(trk.containers,trk.phases)

and-E(Unfold(1.1))
1.5 cid in set dom trk.containers and

trk.containers(cid).material in set
phase.expected_materials forall-E(Unfold(1.4),1,h1,1.h2)

infer trk.containers(cid).material in set
phase.expected_materials and-E(1.5)

infer forall phase in set rng trk.phases &
forall cid in set phase.contents &

trk.containers(cid).material in set
phase.expected_materials forall-forall-I(1)

A fully formal proof would be too long and detailed to include here. Indeed,
detailed discussion of the form and content of proofs is beyond the scope of this
book. However, note the main characteristics of the proof presented above. Each
line is numbered and a justification of each step in the proof is given by referring
to different proof rules (e.g. and-E). Proof rules describe the inferences which
are permitted from previous lines in a proof.

It is possible to increase confidence that a validation conjecture holds true by
applying tests, for example using the debugger in VDMTools Lite. However,
there are limitations to testing. For example, using the debugger one would
quickly discover that it is impossible to create a tracker value (satisfying
the invariant) which does not satisfy this validation conjecture. However, one
cannot conclude from a finite number of tests that the property would always
hold. Proof, which uses symbols to stand for arbitrary values instead of selected
test cases, gives a higher degree of confidence in the truth of the conjecture
provided, of course, that the proof is itself correct!



10.7 Choosing a validation technique 187

10.7 Choosing a validation technique
The validation techniques discussed in this chapter each have their own

costs and benefits. For a given modelling problem, the developer faces a choice
about which technique, or combination of techniques, to use.

To some extent, the choice of technique is related to the level of confidence
required in the model and this in turn is related to the purpose for which the
model is developed. If a model has been developed in an ad hoc way to serve
as a means of clarifying some small aspect of a system, it may be sufficient
merely to inspect the model visually. At the other extreme, the model might
be developed in order to provide an analysis of operating rules related to the
safety of a system. In this case, rigorous or even formal proof may be desirable.
In some cases, where the production of a formal model is an integral part of the
development process, the validation mechanism may be mandated by an external
design authority.

The desired level of confidence must be tempered with an appreciation of
the costs of particular approaches. Proof, at whatever level of rigour, requires
specialist skills and can be time-consuming, whereas testing can be, to a large
extent, automated. The cost of a validation technique is in turn determined to
a large degree by the quality of available tool support. Tool support for proof
for VDM is still limited, while the execution and coverage of tests are better
supported. This situation is continually changing as new forms of tool support
are developed. For example, in areas of hardware design, fast search techniques
have made automated model-checking a widely used technique in industrial ap-
plications.

Summary
• A number of checks can be performed to help improve confidence that

a formal model is internally consistent and does indeed describe the
customer’s original requirements. Performing these checks is a process
called model validation.

• Some of the internal consistency checks can be performed by software
tools while others require human-guided proof. All the checks are called
proof obligations.

• The main proof obligation for an explicit definition is to show that it
respects data type invariants.

• The main proof obligation for partial operators is to show that they are
applied within their defined domain.



188 10 Validating Models

• The main proof obligation for an implicit definition of a function is
called the satisfiability proof obligation.

• There are at least four techniques for increasing confidence that a model
accurately records the behaviour desired by the customer: visualisation,
interfacing to legacy code, systematic testing and proof of validation
conjectures.

• Models can use legacy code through use of dynamic link modules which
can be valuable when customers wish to extend an existing system.

• Models can be visualised through use of an Application Programmer
Interface which can be valuable when customers do not understand the
modelling notation.

• Systematic testing can be exploited in conjunction with generation of
test cases and measuring of test coverage of the models.

• Proofs can be used both for proof obligations and for validation conjec-
tures to improve the confidence in a model.

Exercise 10.3 There is no initialisation or “setup” button in the tracker inter-
face shown in Figure 10.1. Define a function Setup for the tracker which pro-
duces an initialised tracker. Choose your own values for the initialised tracker’s
components. �



11
State-Based Modelling

Aims
The aim of this chapter is to show how systems with a “persistent state”

can be modelled. On completion of the chapter, the reader should be able to
develop models of systems which contain persistent state components. The dif-
ference between this style and the functional modelling style used so far in this
book will be highlighted by revisiting the explosives controller and the trusted
gateway examples.

11.1 Introduction
Using formal modelling techniques, computing systems may be de-

scribed at many different levels of abstraction. The models presented so far
in the book have been set at a relatively high level of abstraction. This is re-
flected both in the data types used and in the way functionality is described
through mathematical functions that take some data representing the system as
input parameters and return a result which describes the system after the compu-
tation has been performed. In some cases, the function can be described without
explicitly constructing its result (e.g. see Subsection 6.4.3).

This functional modelling style has its limitations. Few computing systems
are actually implemented via pure functions. More often, they have variables
that hold data which are modified by operations invoked by some outside user.
These variables are persistent in the sense that they continue to hold data be-
tween operation invocations. If the purpose of a model is to document design
decisions about the split between ordinary parameters to functions and persistent
variables it is necessary to use operations in VDM-SL. These operations take in-
puts and return results, but they also have some effect (often called a side-effect)
on the persistent variables. For example, in a C++ class, the persistent data
is represented by the private variables. The “member functions” act as opera-
tions, taking inputs and returning results while possibly modifying the private
variables. We will refer to the persistent variables as the state of the system.

189



190 11 State-Based Modelling

Our modelling formalism allows for the representation of persistent states
and operations on state variables. It is quite natural to model many computing
systems in a state-based way, including some of those already used as examples
in this book. This chapter introduces the facilities for state-based modelling in
VDM-SL and illustrates them by revisiting the explosives store example from
Chapter 6 and the trusted gateway from Chapter 7.

11.2 State-based modelling
If a model obviously has a system state, then it may be appropriate to

make this clear by differentiating that state from other definitions and the state-
modifying operations from other, auxiliary, function definitions. A state-based
model, in addition to definitions of values, types and functions, contains the
following:

A state definition: a collection of variables which represent the state of the sys-
tem, each variable having a type. The state represents the persistent data:
the information that is stored between occurrences of operations and which
is read or modified by operations.

Operations: The operations on the system are those procedures which can be
invoked by the system’s users (humans or other systems). In this book, they
will always be defined implicitly (via pre- and post-conditions), although the
full VDM-SL language provides facilities for explicit operation definition.

Auxiliary definitions: These are local definitions of types and functions which
are used in the definitions of the state and operations. They follow the syntax
for type and function definitions used in the functional models introduced so
far.

This structure is reflected in those VDM-SL models containing value defi-
nitions, type definitions, function definitions, the state definition and operation
definitions. These need not appear in any particular order (apart from the re-
striction on value definitions mentioned in Subsection 5.3.3), but a model may
not have more than one state definition.

The explosives storage controller from Chapter 6 is one example of a system
which could be described via a state-based model, and this forms the subject of
Section 11.3, which introduces state and operation definitions in VDM-SL. The
choice of state variables and operations is often an important factor in develop-
ing a state-based model and this is examined in Section 11.4, where the model
of the trusted gateway from Chapter 7 is discussed.



11.3 A state-based model of the explosives store controller 191

11.3 A state-based model of the explosives store controller
Chapter 6 described a model of the controller for an explosives store.

Recall that the model represented a store as a collection of objects (its contents)
with physical bounds in the x and y directions. A type Point modelled points
in the store, with each Object being located at a point and having dimen-
sions. Functions were defined to express the condition that objects fit within
store bounds and do not overlap one another. These functions were then used
to express the invariant on a store. The main functionality involved defining
functions which returned the number of objects in the store, suggested positions
free for placement of new objects, placed objects in a store and removed objects
from a store. Notice the terminology here: a function would “place” an object
in a store or “remove” objects. In both cases, the function returns a new store,
but it would appear more natural to view this as an operation which modifies
some persistent store.

Examining the functionality in order to determine which data items can be
viewed as persistent state variables leads to the state-based model discussed
below.

11.3.1 A state-based data model
The persistent data in the system is the description of the store and its

contents. The state of the controller therefore consists of variables modelling the
contents and bounds of the store. In VDM-SL a model’s state is defined using
the following syntax:

state Name of
component-name : type
component-name : type
...
component-name : type

inv optional-invariant
init initial-state-definition
end

Each component-name is a state variable which can be accessed and mod-
ified by the operations. The invariant records restrictions on the permitted com-
binations of state values while the init part describes the initial value of the
state variables.

In the explosives store controller the state would be defined as follows:

state Store of
contents : set of Object
xbound : nat



192 11 State-Based Modelling

ybound : nat
inv mk_Store(contents, xbound, ybound) ==

(forall o in set contents & InBounds(o,xbound,ybound))
and
not exists o1, o2 in set contents & o1 <> o2

and Overlap(o1,o2)
init s == s = mk_Store({},50,50)
end

The invariant records the restrictions that all the objects in the store are within
bounds and that there is no overlapping. Note that the components of the state
are referred to via a record pattern in the same way as components of a record
type.

A state definition introduces a new type (in this case Store) which is treated
as a record type whose fields are the state variables.

An initial value for the state is defined, using the init clause, which in this
book will always have the standard form

init variable == variable = mk_StateName(...)

where variable is a variable of the record type StateName. In the state-
based model of the explosives store controller, the init state is an empty store
of dimensions 50 by 50 units.

11.3.2 Modelling functionality via operations
The functionality described in the original store controller model was

1. return the number of objects in a given store;
2. suggest a position where a given object may be accommodated in a

given store;
3. update a store to record that a given object has been placed in a given

position;
4. update a store to record that all the objects at a given set of positions

have been removed.

These should now be recorded as operations having “side-effects” on the state.
Operations in a VDM-SL model are preceded by the keyword “operations”.
Each operation definition has the following components:

The header with operation name, the names and types of input parameters and
any result.

The externals clause which lists the state components to be used by the oper-



11.3 A state-based model of the explosives store controller 193

ation and indicates whether each component may be read (rd) only or both
read and written to (wr).

The pre-condition which is a logical expression using the input variables and
state variables. It records the conditions which are assumed to hold when the
operation is applied. The pre-condition may be omitted, in which case it is
assumed to be true.

The post-condition which is another logical expression relating the state and
result value after the operation to the state and inputs before the operation: it
describes the essence of the computation.

The syntax for an operation definition is as follows:

OpName(param:type, param:type, ...) result:type
ext wr/rd state-variable : type

wr/rd state-variable : type
...
wr/rd state-variable : type

pre logical-expression
post logical-expression

An operation definition can be thought of as a definition for a piece of code
which has input and output parameters and a side-effect on the state components
(global variables). The pre-condition records assumptions that are made about
the conditions in which the operation may be used. The post-condition records
the effect of applying the operation.

Returning now to the model of the explosives store controller, consider the
operation to calculate the number of objects in the store, taking each section of
the operation definition in turn:

The header Let the operation name be NumObjects. This operation must
count the number of elements of the contents state components and so
requires no input parameters. However, it does return a result, which we will
call r, giving the completed header

NumObjects() r: nat

The externals clause Access is required to only one state component. In this
case, the component will not be modified, only read, so read-only access
(represented by the keyword rd) is all that is required:

ext rd contents : set of Object

The pre-condition This operation will operate on any set of contents. As usual,
we take care to consider the empty case, but here we will simply return zero,
so the pre-condition can be omitted.



194 11 State-Based Modelling

The post-condition The returned number r is simply the cardinality of contents,
so the post-condition is straightforward:

post r = card contents

The completed operation definition is therefore

NumObjects() r: nat
ext rd contents : set of Object
post r = card contents

The next operation in the explosives store example suggests a vacant position
at which there is enough room to accommodate a new object. Here the object is
supplied as input and a point is returned as a result, unless no suitable point is
available in the store, in which case the value nil is returned. The header is as
follows:

SuggestPos(o:Object) p:[Point]

What access to state components will be required? The operation needs to read
the contents to check for possible overlapping, and also needs to read the
bounds to ensure that the returned point is within them. This operation makes
no modifications to the store, so read-only access is again sufficient:

ext rd contents : set of Object
rd xbound : nat
rd ybound : nat

The operation, once again, can be applied to any input and any state, so the pre-
condition is omitted. The post-condition must say (as does the implicit function
version in Chapter 6) that, if there exists a point where there is room for the
object o, then the result r must be such a point. Otherwise, the result must
be nil. To determine whether there is room at a point, the auxiliary function
RoomAt may be used but the signature of RoomAt is modified slightly to take
the contents and bounds of the store as arguments directly. We could continue
to define a function over the type Store, but this modification simply makes it
easier to see how the function is used. The modified version of RoomAt is

RoomAt: Object * set of Object * nat * nat * Point -> bool
RoomAt(o,contents, xbound, ybound, p) ==

let new_o = mk_Object(p,o.xlength,o.ylength) in
InBounds(new_o,xbound,ybound) and
not exists o1 in set contents & Overlap(o1,new_o)

and the completed definition of the SuggestPos operation is

SuggestPos(o:Object) p:[Point]
ext rd contents : set of Object



11.3 A state-based model of the explosives store controller 195

rd xbound : nat
rd ybound : nat

post if exists pt:Point & RoomAt(o,contents,xbound,ybound,pt)
then p <> nil and RoomAt(o,contents,xbound,ybound,p)
else p = nil

The operation Place, which places an object at a position in the store, in-
volves some modification to the state: the store’s contents are to be updated with
the new item. The operation will take the object and position as input, and will
require read and write access (indicated by the keyword wr) to the contents
state component. Since it is also necessary to check that there is room at the pro-
posed point, the bounds of the store will also be read. This gives the following
header and externals clause:

Place(o:Object, p:Point)
ext wr contents : set of Object

rd xbound : nat
rd ybound : nat

The pre-condition should record the assumption that sufficient space exists at
the proposed point:

pre RoomAt(o,contents,xbound,ybound,p)

The post-condition describes the modification to the state resulting from placing
the object at the point. The contents state component after the operation is
applied is equal to the contents component before the operation, with the ob-
ject added. In order to record this formally, we will require a means of referring
to the state before and after the operation. The convention in VDM-SL is that
a state component name is decorated with a “˜” after the name to indicate the
component before application. Thus, the modification to contents could be
described as follows:

contents = contents˜ union {new_o}

where new o is the object with the new coordinates added as its position. The
completed operation is as follows:

Place(o:Object, p:Point)
ext wr contents : set of Object

rd xbound : nat
rd ybound : nat

pre RoomAt(o,contents,xbound,ybound,p)
post let new_o = mk_Object(p,o.xlength,o.ylength) in

contents = contents˜ union {new_o}



196 11 State-Based Modelling

The final operation, Remove, given a set of points, removes the objects at
those points from the store. Note that this operation does not require access
to the bounds of the store, since no objects are being added. The operation is
presented in its entirety:

Remove(sp:set of Point)
ext wr contents : set of Object
post let os = {o | o in set contents & o.position in set sp} in

contents = contents˜ \ os

11.4 A state-based model of the trusted gateway
Recall that the trusted gateway receives a stream of messages as an in-

put and sends each message to one of two output streams depending on whether
or not it finds strings from a special category in the input message. In the func-
tional model developed in Chapter 7, types were defined to model character
strings (sequences of characters), messages (strings with a certain maximum
size), classifications of messages (either <HI> or <LO>) and the category (a set
of strings).

The functionality of the gateway was defined first by a recursive function
which directed one message at a time to the correct output port, and also by a
function which used sequence comprehension to describe the processing of a
sequence of inputs. Here we will consider the following operations:

1. ProcessMessage, which describes how a single given message could
be processed;

2. Gateway, which describes the overall functionality, where messages
are handled as an input stream.

First, what will go into the state? The gateway contains one input port and
two output ports, along with a category. The operations process the inputs,
write messages to the outputs and examine the category, so these all seem to
be sensible state components. The resulting type and state definitions are given
below:

types

String = seq of char
inv s == s <> [];

Message = String
inv m == len m <= 100;



11.4 A state-based model of the trusted gateway 197

Classification = <HI> | <LO>;

Category = set of String;

state TrustedGateway of
input : seq of Message
cat : Category
outHi : seq of Message
outLo : seq of Message

init gate == gate = mk_TrustedGateway([],{},[],[])
end

Notice that an initialisation clause has been added to the state definition, indi-
cating that the gateway starts with empty streams of messages at its ports and an
empty category. The operations in the model should allow a system to progress
from its initial state. In practical terms, this means that there should be at least
one operation whose pre-condition is implied by the init clause in the state
definition, otherwise no progress will be possible. Operations to add and re-
move messages and category strings are considered in the exercises below.

Consider now an operation which takes a message as an input parameter and
adds it to the appropriate output port. The operation header will give the input
parameter and the operation returns no result:

ProcessMessage(m:Message)

The operation will need to be able to read the category in order to determine the
classification of the message m, so the externals clause will require read-only
access to cat:

ProcessMessage(m:Message)
ext rd cat : Category

The operation will also be writing values to the output ports. We cannot tell
which output port will be modified, because that depends on what particular
values are passed in m. The externals clause will therefore give read/write access
to both output ports:

ProcessMessage(m:Message)
ext rd cat : Category

wr outHi : seq of Message
wr outLo : seq of Message

It is often best to begin sketching the post-condition before defining the pre-
condition. The form of the post-condition helps to determine what assumptions
must be recorded in the pre-condition to ensure that uses (partial) operators are
defined and that invariants are respected. The ProcessMessage operation is



198 11 State-Based Modelling

intended to add the message m to the head end of the appropriate output port. If
the classification of m is <HI> then

outHi = [m]ˆoutHi˜

and if the classification of m is <LO> then

outLo = [m]ˆoutLo˜

The auxiliary functions Occurs and Classify as previously defined do not
have side-effects and so can continue to be defined as functions. A first draft of
the operation ProcessMessage is as follows:

ProcessMessage(m:Message)
ext rd cat : Category

wr outHi : seq of Message
wr outLo : seq of Message

post if Classify(m,cat) = <HI>
then outHi = [m]ˆoutHi˜
else outLo = [m]ˆoutLo˜

This definition suffers from an interesting but common deficiency. Consider the
case where

Classify(m,cat) = <HI>

The post-condition says that the high-classification port must be updated with
m added at the head end. However, we also have write access to the low-
classification output port and the post-condition says nothing about what should
happen to this port in the case where the message is high-classification. Re-
call that the operation definition could be seen as a definition for a piece of
code which satisfies the post-condition under the assumptions stated in the pre-
condition. Here, the operation definition could be satisfied by code which writes
anything at all to the low-classification port, as long as the high-classification
port is updated correctly! In more general terms, the following two operation
specifications achieve the same thing:

OP(in:A) r:R OP(in:A) r:R
ext wr s : SomeType ext rd s : SomeType
pre ... pre ...
post ... and s = s˜ post ...

The question of how state components not explicitly mentioned should be mod-
ified is known from artificial intelligence research and is called the frame prob-
lem. The lesson for the author of a VDM-SL formal model is simply to ensure
that updates to all write-access state components are correctly described in the
post-condition.



11.5 Validation of state-based models 199

The post-condition of the operation ProcessMessage should be revised
to say that, in each case, the output port which is not modified is itself left
unchanged:

ProcessMessage(m:Message)
ext rd cat : Category

wr outHi : seq of Message
wr outLo : seq of Message

post if Classify(m,cat) = <HI>
then outHi = [m]ˆoutHi˜ and outLo = outLo˜
else outHi = outHi˜ and outLo = [m]ˆoutLo˜

No pre-condition is required for this operation: the post-condition is sensible for
all possible states and input parameters.

Recall from the functional model of the trusted gateway that it is possible to
describe the gateway’s behaviour as it processes a whole series of input mes-
sages. The ProcessMessage function was incorporated into a recursive
function Gateway which handled the sequence of messages at the input one-
by-one. Alternatively, sequence comprehension can also be used to describe the
same behaviour without needing recursion.

Within the limited notation introduced in this book, recursion within opera-
tions appears clumsy, so we will generally prefer comprehension in operation
definitions. The overall functionality of the gateway can be described by an
operation using sequence comprehension as follows:

Gateway()
ext rd input : seq of Message

rd cat : Category
wr outHi : seq of Message
wr outLo : seq of Message

post outHi = [input(i) | i in set inds input &
Classify(input(i),cat) = <HI>]

and
outLo = [input(i) | i in set inds input &

Classify(input(i),cat) = <LO>]

11.5 Validation of state-based models
The validation of state-based models proceeds in a very similar way to

that of models written using only functions. However, the introduction of the
state and operations brings with it some additional proof obligations.

Consider a state definition as follows:

state NewState of
component-name : type



200 11 State-Based Modelling

component-name : type
...
component-name : type

inv optional-invariant
init ns == ns = mk_NewState(...)
end

The initialisation only makes sense provided the initial state satisfies the invari-
ant, so we have an additional obligation to show that

inv_NewState(mk_NewState(...))

The satisfiability obligation for operations is much the same as for implicitly
defined functions, except that we must include the “before” and “after” states
as well as the inputs and results. Consider an operation specification OP of the
form

OP(p1:T1,...,pn:Tn) r:R
ext ...
pre ...
post ...

working on a state s of type NewState. The obligation involves showing that

forall a1:T1, ..., an:Tn, s˜:NewState &
pre_OP(a1,...,an,s˜) =>

exists r:R, s:NewState & post_OP(a1,...,an,s˜,s,r)

The same validation techniques are available for operations as for implicit func-
tions, including testing (by evaluating the post-condition) and proof.

Summary
• In many cases it is appropriate to model a system and its functionality as

a collection of state variables representing persistent data and operations
which take inputs, produce a result and have side-effects on the state
variables. A state-based model in VDM-SL contains a state definition,
which lists the state variables, and a number of operation definitions.

• Although a state-based model has extra complexity in the definition of
the state and operations, it often reflects more closely the nature of the
computing system being modelled. A state-based model is appropriate
when a functional model would involve passing large data structures
as inputs to functions, especially when the functions return an output
which differs from the input in only a small number of components.
State-based modelling is appropriate if the purpose of a model is to
document the design of a software system which uses global variables.



11.5 Validation of state-based models 201

• The state definition lists the state variables, along with their representing
types. The variables may be restricted by an invariant. The initial values
of the state variable are determined by an init clause.

• The operation specifications covered in this book have all been implicit,
with a header giving the inputs and result, and an externals clause defin-
ing the access (read-only or read/write) which the operation may have
to the state variables. The functionality of the operation is described
by means of a post-condition which relates the result and “after” values
of the state variables to the inputs and the “before” values. The post-
condition must respect the restrictions in the externals clause. It is im-
portant to ensure that the post-condition defines all the “after” values of
write-accessible state variables. The operation may have a pre-condition
restricting its application.

• Explicit operation definitions are possible in VDM-SL, but are not cov-
ered in this book.

Exercise 11.1 We have omitted some important operations from the trusted
gateway model. Extend the model with the following, using Toolbox Lite to test
your answers:

1. Add a new string to the category. Return a special error value if the
string is already present in the category.

2. Remove a given string from the category if it is present. If the given
string is not in the category, leave it unchanged.

3. Add a new input message to the tail end of the input stream.

�





12
Large-Scale Modelling

Aims
In this chapter, we aim to provide an awareness of the issues involved

in constructing and analysing large-scale models. We will introduce modular
structuring facilities in VDM-SL as an illustration of the features required in a
structuring mechanism. On completion of this chapter, the reader should be able
to exploit modular structuring and the potential for re-use in large models.

12.1 Introduction
In any course on modelling, one is naturally limited in the size of model

which can be developed and presented. However, in any realistic application
of modelling technology, questions of scale must be addressed. How can one
manage the complexity of developing and analysing a model which contains
many related parts?

Before answering this question, it is worth remembering that models should
be kept as simple as possible while still capturing the aspects of the system
which are felt to be relevant to the analysis. Careful use of abstraction means
that many systems can be usefully modelled without encountering problems of
scale. However, for some applications, particularly where the product is safety-
related, a formally defined language such as VDM-SL must be applied to the
production of a substantial model, and so the management of the model’s size
and complexity becomes a significant issue.

In programming languages, the management of complexity has led to the
adoption of modular structuring mechanisms for programs, and this approach
has also been applied to VDM-SL. All the models presented so far have been
flat in the sense that they have consisted of a series of definitions in a single
document. In order to understand part of the model, one might possibly have to
read the whole document. In contrast, a modular model consists of a number of
separate modules, each of which contains a collection of definitions just as in a
flat model. Given a good division of a model into separate modules, it should be

203



204 12 Large-Scale Modelling

possible to complete the analysis of the modules relatively independently. Ul-
timately, the separate modules are brought together into a “top-level” unit. The
task of analysing the whole model, whether by visualisation, testing or proof,
can then be split into analyses of the component modules.

The remainder of this chapter presents the modular structuring facilities avail-
able in VDM-SL. These are illustrated on the tracker model introduced in Chap-
ter 8. The facilities are those supported by VDMTools. The ISO Standard for
VDM-SL does not mandate any particular modular structuring mechanism. In
the ISO standard there is an informative annex defining a module mechanism on
similar lines to that presented here.

12.2 A structure for the tracker model
The tracking system presented in Chapter 8 is a greatly simpli-
fied version of the model developed in the real project on which
the example was based. The “real” tracker model contained over
2000 lines of VDM-SL. The engineers and consultants involved
in the project felt afterwards that its monolithic structure hin-
dered both its construction and its review. Their opinion was
that a modular structuring approach could have assisted greatly
in the analysis of the model. In this section we illustrate via
the smaller example how modular structuring might have been
applied to the larger model.

First, we consider the overall division of the model into component modules.
The model presented in Chapter 8 has three main aspects: containers, phases
and the overall tracker. We might consider a structure for the model which puts
each of these concepts in a separate module:

• The Containers module would hold information relating to the mod-
elling of containers and material they contain.

• The Phases module would model the structure of the plant and define
properties such as safety of materials stored in phases. In order to do
this, it will need to use some of the types defined in the Containers
module.

• The Tracker module brings together the Containers and Phases mod-
ules, providing a definition of the information held by the tracker and
the functions which may be applied to the tracker, such as granting per-
mission for containers to move between phases.



12.2 A structure for the tracker model 205

Figure 12.1 Modular structure for the tracker model

Containers & Material

Phase Structure

Tracker

provides
definitions

provides definitions

provides definitions

Figure 12.1 shows the general structure suggested here. Many alternatives are
possible. For example, materials might be defined in a separate module. How-
ever, this would lead to a structure where several modules have little content.

There comes a point where the ratio between the size of a mod-
ule’s interface definition and its content is too heavily weighted
towards the interface for the module to be useful. The ad-
vantages and disadvantages of each possible modular structure
should be weighed up before a commitment is made.

The Containers module
This module will hold the definitions of the types and functions relating

to containers and materials. The relevant type definitions from the flat model are
as follows:

ContainerInfo = map ContainerId to Container;

Container :: fiss_mass : real
material : Material;

ContainerId = token;



206 12 Large-Scale Modelling

Material = token

To place these definitions in a module, we first have to name the module. For
brevity, we will call the module CTRS. The basic definitions are enclosed in
module . . . end keywords:

module CTRS
...
types

ContainerInfo = map ContainerId to Container;

Container :: fiss_mass : real
material : Material;

ContainerId = token;

Material = token
end CTRS

Notice that so far no functions are included in this module. This is because all
the functions we require in the model use types like PhaseInfo and Tracker
which are defined in other modules. Our intention in producing a modular ver-
sion is to make it possible to understand the overall model as the sum of its
constituent modules, with each individual module being separately defined and
analysed. Thus each function must be defined in a context in which its input and
result types are available.

Since each module represents a separate part of the overall model, we should
provide interfaces between modules. Each module’s interface says which con-
structs (types, functions etc.) it will supply to, and which it will require from,
the other modules. This information is given in an interface section of the mod-
ule, separate from the definitions of types and functions. The definitions are
separated from the interface by a definitions keyword:

module CTRS
...

definitions

types

ContainerInfo = map ContainerId to Container;

Container :: fiss_mass : real



12.2 A structure for the tracker model 207

material : Material;

ContainerId = token;

Material = token
end CTRS

This module requires nothing from the other modules, but makes the types it
defines available to the others. We say that it exports all its defined constructs.
This is represented by the keywords exports all in the interface section of
the module definition:

module CTRS

exports all

definitions

types

ContainerInfo = map ContainerId to Container;

Container :: fiss_mass : real
material : Material;

ContainerId = token;

Material = token

end CTRS

The Phases module
The phases module defines the phases, the PhaseInfo type and the

auxiliary functions Consistent which checks that the contents of containers
in the phases of the plant are known; PhasesDistinguished, which checks
that no containers occur in more than one phase; and MaterialSafe, which
checks that all containers in all phases contain only those kinds of material ex-
pected for that phase.

Recall from the flat model that the type definitions relevant to phases were as
follows:

PhaseInfo = map PhaseId to Phase;

Phase :: contents : set of ContainerId
expected_materials: set of Material



208 12 Large-Scale Modelling

capacity : nat
inv p == card p.contents <= p.capacity;

PhaseId = token

When placed in the phases module, these definitions will require the use of types
defined in the containers module CTRS. The interface part of the phases module
should record this dependence. We say that the phases module will import all
the definitions from CTRS. Suppose it is decided that this module should also
export all of its defined types and functions. If the phases module is called PHS
for brevity, this yields the following skeleton module definition:

module PHS
imports from CTRS all
exports all

definitions

types

PhaseInfo = map PhaseId to Phase;

Phase :: contents : set of ContainerId
expected_materials: set of Material
capacity : nat

inv p == card p.contents <= p.capacity;

PhaseId = token

end PHS

There remains a problem with this definition. Suppose we were analysing the
type- or syntax-correctness of PHS. The types ContainerId and Material
could be imports from CTRS, or they could be locally defined types whose def-
initions have been omitted. In order to make the origin of each construct clear,
we prefix the use of imported constructs by the name of the module from which
they have been imported, and we separate the prefix from the construct’s name
by the backtick character (‘). Thus

module PHS
imports from CTRS all
exports all

definitions

types



12.2 A structure for the tracker model 209

PhaseInfo = map PhaseId to Phase;

Phase :: contents : set of CTRS‘ContainerId
expected_materials: set of CTRS‘Material
capacity : nat

inv p == card p.contents <= p.capacity;

PhaseId = token

end PHS

The functions defined in this module also make use of the types imported from
CTRS. The full module definition is as follows:

module PHS

imports from CTRS all
exports all

definitions

types

PhaseInfo = map PhaseId to Phase;

Phase :: contents : set of CTRS‘ContainerId
expected_materials: set of CTRS‘Material
capacity : nat

inv p == card p.contents <= p.capacity;

PhaseId = token

functions

Consistent: CTRS‘ContainerInfo * PhaseInfo -> bool
Consistent(containers, phases) ==
forall ph in set rng phases &

ph.contents subset dom containers;

PhasesDistinguished: PhaseInfo -> bool
PhasesDistinguished(phases) ==
not exists p1, p2 in set dom phases &

p1 <> p2 and
phases(p1).contents inter phases(p2).contents <> {};

MaterialSafe: CTRS‘ContainerInfo * PhaseInfo -> bool
MaterialSafe(containers, phases) ==
forall ph in set rng phases &

forall cid in set ph.contents &



210 12 Large-Scale Modelling

cid in set dom containers and
containers(cid).material in set ph.expected_materials

end PHS

Notice that PHS exports all its constructs. However, the modular structuring
facility in the VDMTools is defined so that it does not automatically re-export
the constructs it imported from CTRS.

The Tracker module
The final module in this hierarchy is the Tracker module, which we will

call TRACKER. It requires the types and functions from PHS, but also the types
exported by CTRS, since it uses the ContainerInfo type. The module is
presented in full below. Note again that the names of imported constructs are
qualified.

module TRACKER

imports from PHS all,
from CTRS all

exports all

definitions

types

Tracker :: containers : CTRS‘ContainerInfo
phases : PHS‘PhaseInfo

inv mk_Tracker(containers,phases) ==
PHS‘Consistent(containers,phases) and
PHS‘PhasesDistinguished(phases) and
PHS‘MaterialSafe(containers,phases);

functions

-- introduce a new container to the plant (map union)

Introduce: Tracker * CTRS‘ContainerId * real * CTRS‘Material ->
Tracker

Introduce(trk, cid, quan, mat) ==
mk_Tracker(trk.containers munion

{cid |-> mk_CTRS‘Container(quan, mat)},
trk.phases)

pre cid not in set dom trk.containers;



12.2 A structure for the tracker model 211

-- permission to move (simple Boolean function)

Permission: Tracker * CTRS‘ContainerId * PHS‘PhaseId -> bool
Permission(mk_Tracker(containers, phases), cid, dest) ==
cid in set dom containers and
dest in set dom phases and
card phases(dest).contents < phases(dest).capacity and
containers(cid).material in set phases(dest).expected_materials;

-- assign a known container to a given phase

Assign: Tracker * CTRS‘ContainerId * PHS‘PhaseId -> Tracker
Assign(mk_Tracker(containers, phases), cid, pid) ==
let pha = mk_PHS‘Phase(phases(pid).contents union {cid},

phases(pid).expected_materials,
phases(pid).capacity)

in
mk_Tracker(containers, phases ++ {pid |-> pha})

pre Permission(mk_Tracker(containers, phases), cid, pid);

-- remove a container from the contents of a phase

Remove: Tracker * CTRS‘ContainerId * PHS‘PhaseId -> Tracker
Remove(mk_Tracker(containers, phases), cid, source) ==
let pha = mk_PHS‘Phase(phases(source).contents \ {cid},

phases(source).expected_materials,
phases(source).capacity)

in
mk_Tracker(containers, phases ++ {source |-> pha})

pre source in set dom phases and
cid in set phases(source).contents;

-- delete a container from the plant

Delete: Tracker * CTRS‘ContainerId * PHS‘PhaseId ->
Tracker

Delete(tkr, cid, source) ==
mk_Tracker({cid} <-: tkr.containers,

Remove(tkr, cid, source).phases)
pre pre_Remove(tkr,cid,source)

end TRACKER



212 12 Large-Scale Modelling

On a much larger scale, a similar modular structuring could have
been effectively applied to the “real” tracker model. It is likely
that there would have been many more modules. Some mod-
ules would also have contained much larger definitions sections
than those shown here. When one has a structure in which mod-
ules contain a great deal of detail which may change as individ-
ual modules are developed, it may be advisable to limit the use
which can be made by other modules of the constructs defined
in a given module. This is the subject of the following section.

12.3 Information hiding
In the example presented so far, we have exported all the constructs

defined in each module. However, it may sometimes be appropriate to define a
more restricted interface to a module. For example, if one defines an auxiliary
function which is not meant to be exported, but is used in the definition of an
exported function, then the auxiliary function should not be used by any other
module. This means that the auxiliary function can be replaced by an equivalent
new version at a later stage without any other module being affected.

Support is available for this means of limiting exports. Instead of using all
in the exports list, we can list the individual types and functions which we do
wish to export. For example, we could have defined the following version of
TRACKER which has the same definitions section, but makes only some of the
defined functions available to other modules:

module TRACKER_LIMITED

imports from PHS all,
from CTRS all

exports
types Tracker;
functions Permission: Tracker * CTRS‘ContainerId *

PHS‘PhaseId -> bool;
Assign: Tracker * CTRS‘ContainerId * PHS‘PhaseId

-> Tracker;
Remove: Tracker * CTRS‘ContainerId * PHS‘PhaseId

-> Tracker
definitions
...

module TRACKER_LIMITED

This would allow the authors of other modules to use the tracker functions to



12.3 Information hiding 213

move existing containers through the plant, but would not allow them to intro-
duce or delete containers, because those functions are missing from the export
list.

The authors of a module can impose self-discipline by restricting imports as
well. The imports list can contain individual types or functions from a module
rather than importing all. For example, suppose that, instead of restricting
exports, the TRACKERmodule exports all its functions. The authors of a module
that describes control of container introduction might use the following imports
list:

imports from CTRS types ContainerId, Material
from TRACKER
types Tracker
functions Introduce: Tracker * CTRS‘ContainerId *

real * CTRS‘Material -> Tracker

This would allow them only to use the Introduce function from TRACKER.
Notice that all the types in the signature of the imported function must also
be available, otherwise it would not be possible to construct values to which
the function can be applied. Hence we import types from CTRS as well as
TRACKER.

A further kind of restriction is available on export. The authors of a module
may choose to export a type with or without its representation. This is indi-
cated by the use of a keyword struct. Suppose TRACKER exports the type
Tracker with struct, written as follows:

module TRACKER

imports ...

exports types struct Tracker,
functions all

definitions
...
Tracker :: containers : CTRS‘ContainerInfo

phases : PHS‘PhaseInfo
inv mk_Tracker(containers,phases) ==

...
...
end TRACKER

Now any module which imports TRACKER has access to the type Tracker and
its definition. The importing module can use the fact that Tracker is a record
type with two fields called containers and phases. This could cause dif-



214 12 Large-Scale Modelling

ficulties where separate teams of developers are responsible for their own mod-
ules. For example, if the authors of the TRACKER module added another field
to record the history of container movements, the users of the TRACKER mod-
ule would have to update all their uses of mk Tracker expressions to ensure
that they now had three arguments. To guard against the consequences of such
change, it is often advisable to export types without struct. The use of the
all keyword on export implies export of types with their representations.

Finally in this section, a note on renaming. The prefixed names used for
imported types and functions can become cumbersome. It is possible to rename
constructs on import. For example, we could have avoided the use of prefixed
names in the PHS module by renaming them as follows. Renaming is indicated
by the use of the renamed keyword:

module PHS

imports from CTRS types ContainerInfo renamed CtrInfo,
Container renamed Ctr, ...

exports all

definitions
...
Consistent: CtrInfo * PhaseInfo -> bool
Consistent(containers, phases) ==

forall ph in set rng phases &
ph.contents subset dom containers

...

12.4 Object-oriented structuring
Modular structuring provides a basic means of organising large-scale

models. The approach nevertheless requires some care in deciding what should
be included in each module. Object-oriented modelling approaches such as
Universal Modelling Language (UML) [Booch&97, UML20] provide support
for structuring models of complex systems by basing structures around objects
which may have local states and which interact through methods at their inter-
faces. Classes of objects share common properties and may inherit properties
from super-classes.

Although object-oriented methods play a major role in system modelling,
they could benefit from exploiting the combination of abstraction and rigour
which comes from the use of a formally defined modelling language. VDM++
[Fitzgerald&05] is an extension of VDM-SL that supports object-oriented de-
sign principles including notions of classes and inheritance. A version of VDM-



12.4 Object-oriented structuring 215

Tools has been designed to support VDM++, providing coupling between UML
class diagrams and their formal VDM++ counterparts. Using VDM++ notation,
the tracker model would at least include classes for the main modules so here
the only syntactic difference would be the use of the class keyword instead
of the module keyword. However, visibility outside a class is controlled using
access modifiers instead of import and export sections. Such access modifiers
can be private, public and protected and the default is private in case
the access modifier is omitted. So for example the TRACKER class could be
defined as

class TRACKER

types

public
Tracker :: containers : CTRS‘ContainerInfo

phases : PHS‘PhaseInfo
inv mk_Tracker(containers,phases) ==

...
...

functions

Consistent: ContainerInfo * PhaseInfo -> bool
Consistent(containers, phases) ==

forall ph in set rng phases &
ph.contents subset dom containers

...

end TRACKER

In this case the Tracker type would be publicly available outside the class
whereas the Consistent function does not have an access modifier and thus
would be private. In the case where a class was made for each kind of phase this
could be done using inheritance. So if we had a PHS class one could define a
Sorting phase in its own class as

class Sorting is subclass of PHS

...

end Sorting

In this case any definition from the PHS class defined using the protected
access modifier would also be visible inside the Sorting class.



216 12 Large-Scale Modelling

Summary
The construction and analysis of large-scale models necessitate a struc-

turing mechanism. A modular structuring mechanism provides for

• separation of models into syntactic units;
• information hiding through restrictions on imported and exported con-

structs and the provision of an option to export types with or without
their representations;

• the ability to rename imported modules so as to maintain “readability”
of modules.

The extension of modular structuring methods to object-oriented structuring is
achieved in VDM++.



13
Using VDM in Practice

Aims

This final chapter concerns the use of VDM in industrial practice. We
aim to equip the reader to apply VDM technology cost-effectively in industrial
software development processes, and to stay abreast of the state of the art in
VDM and formal modelling. We aim to introduce the contribution that formal
modelling can make to the tasks that are at the core of commercial develop-
ment processes. We will illustrate this with several real industrial applications
of VDM. Finally, we aim to provide information on the recent extensions to
VDM and VDMTools, and how to gain the most from the VDM and formal
methods communities.

13.1 Introduction

Modelling in a formal language is not a panacea for every problem in
system and software development but, if used thoughtfully, it can yield signifi-
cant benefits. The deciding factor in using VDM technology (the combination of
VDM-SL and VDMTools) has to be cost-effectiveness. The cost of developing
a system model during the early stages of design should be recouped when the
improved understanding of system functionality reduces the reworking required
to deal with defects that are uncovered during later activities such as testing and
maintenance.

In this chapter we discuss a range of software development activities, some
of the problems that can arise during their execution and the ways in which the
use of VDM can address some of these (Sections 13.2 to 13.4). Some hints
on how to start using VDM are presented (Section 13.5). We illustrate the ap-
proach by describing recent industrial applications of VDM and its extended
forms (Sections 13.6 and 13.7). Finally, we describe further sources of informa-
tion for readers interested in using VDM in industrial applications, research or
teaching (Section 13.8).

217



218 13 Using VDM in Practice

13.2 Development activities and processes
Every development project has particular needs that lead to it follow-

ing a process that suits prevailing business conditions. A process is a way of
organising development activities such as requirements analysis, design, coding
and testing into time-bounded phases. Classical “waterfall” and “V” processes
allocate a single activity to each phase, and this activity is applied to the whole
product at once. Thus, a requirements analysis phase attempts to deliver a fixed
requirements document which is passed on to a design phase which delivers de-
signs to an implementation phase, and so on. Errors uncovered in phases may
force iteration back through preceding phases in order to correct them. Recent
years have seen a move away from such approaches on the grounds that they
lack the flexibility to assimilate changes in requirements, business needs or ca-
pabilities of hardware and software. More flexible “agile” processes tend to
take an evolutionary or iterative approach in which an initial implementation or
prototype is enhanced through successive versions, each version realising more
functional or performance requirements than its predecessors. In contrast with
classical approaches, each phase involves more than one development activity.

Formal modelling encourages developers to focus on significant architectural
decisions, regardless of how those decisions are organised as a development
process. We therefore focus on development tasks, rather than phases:

Requirements Analysis: Initial requirements are expressed in notations and nat-
ural language that are familiar to the customer and experts in the application
domain. The challenge is to identify areas of incompleteness, ambiguity and
inconsistency in the requirements so that they can be resolved before they
pose problems to design and implementation. The primary outcome of this
activity is normally an improved set of requirements, but an initial draft sys-
tem architecture may also be drawn up. This may, for example, allow de-
velopers to assess the feasibility of meeting requirements with the available
system resources.

Design: Design bridges the gap between requirements expressed in natural lan-
guage and domain-specific notations understood by clients and domain ex-
perts, and their realisation expressed in notations closer to the level of ab-
straction of code, including architectural description languages and pseudo-
code. Outputs include a software design describing the software architecture
in terms of modules and their functionality as well as a test plan for each of
the modules. Typically the software design is expressed with pseudo-code
and various diagrammatic notations supported by Computer Aided Software
Engineering (CASE) and Software Development Environment (SDE) tools.



13.3 Common development problems 219

Implementation: The software design is realised as code in a programming lan-
guage. Unit testing activities often accompany implementation.

Unit Testing: Each function in the implementation is tested separately by its
developers. Certain test coverage criteria may have to be met. Errors in
coding discovered at this stage are comparatively straightforward and cheap
to correct.

Module Testing: This involves the execution of pre-specified tests on groups of
functions. Errors may be due to faults in requirements analysis, design or
unit testing. In any case, such errors must be corrected at the right level of
description. Modules that may have been developed by different teams are
also integrated. Errors discovered here are often caused by a misunderstand-
ing of the required functionality of modules and significant rework may be
required to rectify this.

System Testing: All the tests accumulated from requirements analysis activities
are performed against an integrated system implementation. In this phase the
errors discovered are often due to misunderstandings at the system design
level, and major rework may be required to correct these. Typically, errors
stem from a misunderstanding of the services to be supplied by one system
component to another, or deficiencies in the definitions of component inter-
faces.

Maintenance: For successful systems the maintenance phase, in which the sys-
tem is put into practical use, is normally the longest in the life-cycle. Main-
tenance includes correcting reported defects and enhancing the system in re-
sponse to new requirements. Rectifying defects typically involves the (ex-
pensive) design, implementation, testing and release of a software patch.

13.3 Common development problems
Every development process has its strengths and weaknesses. Here we

focus on the problems that VDM technology can help to alleviate. Thus, we will
not go into problems with staffing, scheduling, cost estimation and configuration
management.

Premature coding: Implementation is often begun before the functional require-
ments have been sufficiently analysed and without a full consideration of
which requirements will have the greatest influence over the final architec-
ture. Indeed, if design errors stemming from an erroneous understanding of
the functionality are found late in the process their correction can be very
costly in terms of required rework.



220 13 Using VDM in Practice

Lack of confidence in descriptions: The system descriptions used in early de-
velopment phases often use notations such as natural language and pseudo-
code that are not suited to automated analysis. Confidence in such descrip-
tions is typically gained through manual review. This is a labour-intensive
approach and its success rate in uncovering defects depends on the skills and
experience of the reviewers. The difficulty of validating informally expressed
descriptions is compounded by the diversity in background and terminology
of customers, domain experts, system engineers and software developers.

Errors discovered too late: Misunderstandings between developers tend to be
uncovered in integration test activities, leading to a significant volume of re-
work. This is particularly problematic in multidisciplinary developments, for
example where mechanical and electronic engineers are present in the same
project. Since integration testing is often done close to a delivery deadline,
documentation may not be updated to reflect the changes made at this late
stage of development.

Late feedback from customer: Customers cannot always provide feedback on
system requirements specifications or designs early enough to have a ma-
jor impact on an implementation that may already be well under way. As a
result, deficiencies in the expression or interpretation of requirements are ei-
ther corrected at great expense or have to be deferred to a patch or upgrade. A
solution chosen by some organisations is to develop prototypes rapidly, using
these to gain earlier feedback from the customer. Such prototypes sometimes
evolve into the final product.

Overly late delivery: In an innovation-led business, achieving a short time to
market is often key to a product’s success. However, development timescales
are often rendered unpredictable by the possibility of late error discovery. It
is desirable to get a more predictable route to a product.

Misunderstanding a design during maintenance: The engineers maintaining a
system have rarely taken part in its development; if documentation is not
accurate there is an increased risk that bug fixes simply introduce other errors.
Without an understanding of the design principles of the system the level of
abstraction is simply so low that bug fixing can become a “trial and error”
process.

13.4 Advantages of VDM technology
In this section, we discuss the ways in which formal modelling tech-

niques such as those in VDM can be used to address the causes of some of the
development problems listed above.



13.4 Advantages of VDM technology 221

Improved clarification of requirements
VDM-SL provides a medium in which requirements can be systemati-

cally formulated and analysed. Developing a model involves capturing require-
ments and clarifying them through the questions and proof obligations that arise
during the formulation of the model. Indeed, in several industry applications
of VDM, the overriding purpose of formal modelling has been to improve the
requirements specification rather than to derive models that form the basis of
subsequent design. Once the model is developed, it can serve as an initial proto-
type allowing the exploration of alternative requirements and design decisions.

Rapid feedback from customers and domain experts
The ability to execute models allows developers to demonstrate intended

functionality to a customer or domain expert (see Section 10.3). This is done by
building a hybrid executable model with a core part in VDM-SL and a user in-
terface programmed in a conventional language. The VDM-SL core executes
on the VDMTools interpreter while the dynamic link facility allows the user in-
terface to interact with it. The interface can be designed to present the state of
the core model in a way that is meaningful to the domain expert. This makes it
possible to gain rapid feedback on the model without requiring familiarity with
VDM-SL on the part of domain experts. In this respect VDM models act as a
common communication medium used for early prototyping and evaluation of
initial ideas.

Raising confidence in descriptions
Models in VDM-SL are formal in the sense that their semantics are

defined so precisely that it is possible to analyse them using a full range of tech-
niques from static checking and testing up to full mathematical proof. In order to
take full advantage of this formality, powerful analysis tools are required. Au-
tomatically generated proof obligations provide an indication of places where
run-time errors could occur. In addition, it is possible to check conformance to
restrictions such as invariants, pre-conditions and post-conditions dynamically.
Formulating such restrictions is an excellent way to document the limitations
and assumptions made by the different components of a system. As we in-
dicated in Chapter 10 different analysis techniques provide different levels of
insight at different costs.

In Chapter 10 we considered the ability to test VDM models systematically at
the early stages of design as another way to increase confidence. Illustration of



222 13 Using VDM in Practice

test coverage with an ability to show test coverage directly in the VDM model is
important to documenting the level of trust one can have in a model. The ability
to test the model during the system analysis phase may be a productive way to
ensure that system tests have a high level of coverage.

Shorter time to market

The production of a model is usually accompanied by an improvement
in the developer’s understanding of the functional requirements, reducing the
risk of late-stage discovery of errors, with the attendant rework costs. Thus, the
use of VDM technology helps to provide a safer route to the development of the
system.

If the product performance requirements are not especially high, the time to
market can also be shortened by the use of automatic code generation. However,
in cases where optimised code is to be produced it is still essential to have a good
understanding of the required functionality; otherwise the rework is likely to be
particularly costly. Testing times can also be reduced by re-using tests on the
model as oracles against which the outcomes of implementation tests can be
assessed.

Reducing maintenance costs

Requests for incorporation of new features need to be considered during
maintenance. Such requests can be treated by first adding the feature to the
VDM model and testing the modified model before modifying the production
code. This approach makes it easier to keep the documentation up to date with
the system. In addition, it will be easier to analyse the impact of the change
request on the rest of the system. This can also be advantageous in estimating
the efforts required to incorporate the desired change.

The maintenance phase also entails handling bug reports for the delivered
system. Using VDM it is natural to try to reproduce the error at the VDM
level first. If the error can be reproduced within the model, it is usually easier
to identify the causes of an error this way, rather than working directly with an
implementation. When the fault is understood, the VDM model can be corrected
and the test environment at the VDM level re-used in the manner of regression
testing.



13.5 Getting started 223

13.5 Getting started

If the arguments for using VDM technology are so strong, why is it not
already being used by everybody? There are both technical and socio-technical
reasons for this. In this section we discuss them and suggest how they can
be addressed by organisations seeking to introduce VDM technology into an
established development process.

The organisation and people involved

Whatever the size of organisation, several people are usually involved in
deciding whether or not to use these techniques as part of a trial or real product
development. Apart from engineers who have a technical view on the benefits
of applying formal modelling, managers will have concerns about changes to
the development process and the cost-effectiveness of the technology. All these
concerns have to be addressed, and experience suggests that the introduction of
a new technology of the kind discussed in this book is greatly assisted if it has
“champions” within the organisation: people who have some experience of its
application, even if only on a small scale.

Champions need to be aware of the costs and benefits of the technology they
support. The costs of applying formal modelling techniques include investment
in training, initial consultancy and tool support, as well as handling the change
in development cost profile that accompanies a longer design phase. However,
this has to be considered alongside the effort required to address the problems
identified in Section 13.3. When the cost-effectiveness has been justified this
must be used to convince individuals at different levels in the company about
the feasibility of introducing the technology.

One viable approach is to undertake some small initial pilot projects apply-
ing formal techniques experimentally to the development of subsystems. The
purpose of a pilot needs to be clear and the criteria for success need to be well
understood in advance, so that the appropriate development characteristics (e.g.
costs, cost profile, defect densities) are assessed.

The pilot project should be selected so that, if it is not a success, it will not
cause too much damage to the organisation. On the other hand the project should
not be so small that, even if it is a success, there is doubt about the technology’s
ability to scale up. It is often a good idea to take a complex challenge and be
able to show that the use of VDM brings new and valuable insight, enhancing
the solution.



224 13 Using VDM in Practice

The development process
The most important advice with respect to the development process is

to change by evolution rather than revolution. Many industrial organisations
already have sophisticated development processes that have been the subject of
considerable investment (e.g. to achieve qualification to a specified level of the
Capability Maturity Model, CMM). Thus, it is important to investigate how to
fit modelling technology and its products into the existing process and assess the
impact of the technology on the level of qualification.

The discussion above suggests that it is not difficult to embed VDM technol-
ogy in either a classical or an iterative process. The embedding of VDM can be
done at relevant points in any standardised software development process such
as IEC 61508, ESA PSS-05 or MIL-STD-882. Some standards mandate or rec-
ommend the use of formal modelling technology for certain critical applications.

Often the result will be to designate VDM or some other modelling technol-
ogy as a viable technique for some tasks. The way it is used, and the life-cycle
products to which it is contributing, depend on the development activities in
which it is used.

Effects on development profile
It is worth providing some guidance about what can be expected in

terms of the time spent in the different phases of development. Our experience
has generally been that the use of modelling and test-based validation leads to
around 25% additional effort during early analysis phases. However, this is more
than recouped in reduced rework after test and maintenance if applied appropri-
ately.

Model size is a poor progress measure. We find that it is when the size of a
formal model starts to decrease that a full understanding of the functionality of
the system has emerged in the development team. This is because a deep un-
derstanding leads to the recognition of patterns, and the identification of better
abstractions. Reduction in model size should therefore be seen as an indication
that the formal model soon will be finished, and that a much better mental un-
derstanding of the requirements exists as implementation proceeds. The code is
then likely to be written more quickly and be better structured.

Integration with other tools
The evolutionary introduction of modelling technology into an organ-

isation means that new modelling tools must integrate with the tools that are



13.5 Getting started 225

already in use in design and programming support environments. At least ini-
tially, it is advisable to aim for relatively loose integration since this is likely
to be easier to achieve. When more experience has been gained using the tools
in harness together, tighter integration can be investigated. For example, it is
possible to continue to use graphical approaches such as the Unified Modelling
Language (UML) and Structured Analysis (SA), and then use VDM-SL to add
rigour to the products produced using the conventional tools – for example by
enhancing data dictionary entries with type definitions, and process specifica-
tions with function or operation definitions. Special forms of VDM have been
developed for tighter integration with object-oriented designs and UML (see
Section 13.6).

VDM technology can be integrated with version and revision control systems.
Most of these systems simply operate at the file level and since the VDM-SL
version of VDMTools also operates on files it is easy to apply the existing tech-
nology for this purpose. The same holds for requirements traceability tools.

Applying formal modelling

Although we have concentrated on early development phases, formal
methods can be used beneficially in other arenas. In software design activities,
VDM models can replace pseudo-code. When VDM is used at this more de-
tailed level it is typically combined with structured methods supporting a graph-
ical overview of the system such as data flow or object-oriented design tech-
niques. Here the VDM models are used to define formally the data being passed
between processes and the functionality of the methods or functions within pro-
cesses.

Many organisations have large volumes of legacy code to maintain and further
develop. VDM can play a valuable role in reverse engineering and in the devel-
opment of new components to be integrated into existing systems. It may be
worth developing models for inadequately documented components, especially
those that have the highest defect densities. These new models serve as abstract
descriptions for future maintenance and for component renewal. When a brand
new component is to be developed, it is also possible to model its interface to
the existing system. The dynamic link facility in VDMTools can then be used
to validate the interaction between the new component and the existing code.

Another application domain is in the modelling of components whose devel-
opment will be outsourced to other companies. Here it is important to be able
to supply a precise descriptions of the required functionality and the interface



226 13 Using VDM in Practice

required. Abstract formal models can also serve as test oracles for the delivered
subsystems, or as a basis for test set design.

Finally, VDM can play a role in testing. Here the benefits will be in being
able to automate a larger part of the test case selection process. Testing is a
very expensive part of the development of critical systems; it has already been
demonstrated how effort can be reduced by automating parts of this phase.

Training
Before a project is started it is vital to obtain training in abstraction

using a notation such as VDM-SL and get hands-on experience in tool support.
In essence this is exactly what this book is trying to provide, but if it has been
used for self-study it would be advisable to take at least a short course given
by a VDM expert. In addition, one should not forget that, in order to carry out
reviews satisfactorily, it is important that quality assurance personnel involved
with the project are at least trained to read and understand the formal models
being developed.

Following training, we advocate a project-specific workshop, where the parts
of the system to be formally modelled are selected and their structure is de-
scribed in outline. It requires some experience with formal modelling technol-
ogy to identify the parts of a system that will benefit from formal modelling. It is
important to have an experienced modeller or consultant present to help decision
making. After the workshop we advocate use of consultancy from an internal or
external source for reviewing models and in helping choose appropriate abstract
representations.

13.6 VDM and its extensions
Throughout this book, we have concentrated on VDM-SL, a language

that supports modelling of computing systems using abstractions for data and
functionality that are quite far removed from those present in the program-
ming languages in which such systems are often implemented. This has al-
lowed us to concentrate on describing the functionality to be delivered with-
out making design decisions prematurely. At some point, and in some appli-
cations, those design decisions have to be made explicit, and the modelling
language should support this. Several extensions to basic VDM-SL allow the
modelling of features of design and programming frameworks. The VDM++
language supports object-oriented modelling, with systems described in terms



13.7 Industrial applications of VDM 227

of objects that belong to specified classes. The familiar data types from VDM-
SL are present, as are implicit and explicit techniques for describing function-
ality. VDM++ additionally provides support for describing concurrent compu-
tations. This extended language and its tool support are described in detail in
another text [Fitzgerald&05]. In some applications, particularly in embedded
systems, the timing behaviour of computations is significant enough to require
modelling at a very early stage. The VICE VDM extensions deal both with
the description of real-time deadlines and with the allocation of functionality
to computing resources in networks [Verhoef&06, Verhoef&07a, Verhoef&07b,
Fitzgerald&08]. Many of the more recent applications of VDM technology have
used VDM++ or the VICE extensions.

13.7 Industrial applications of VDM
VDM and VDMTools have been applied in a wide variety of application

domains, and it is this experience that leads to our claims that the effort expended
on formal modelling and analysis can be recovered in reduced cost of rework
arising from design errors [Fitzgerald&07a, Fitzgerald&07b]. Some of the best
documented applications that are in the public domain are listed below:

CDIS: A development of an air traffic management system with a central con-
trol function (CCF). The CCF Display Information System (CDIS) was de-
veloped using a combination of an earlier variant of VDM called VVSL and
CCS [Hall96].

ConForm: An experiment at British Aerospace comparing the conventional de-
velopment of a trusted gateway with a development using VDM [Larsen&96,
Brookes&96], described in Chapter 7.

Dust-Expert: A safety-related advisory system supporting the design of indus-
trial vessels containing potentially explosive dust [Clement&99, Vadera&01].

The development of VDMTools: Most components of the VDMTools tool suite
were themselves developed using VDM, first by IFAD A/S in Denmark and
more recently by CSK Systems in Japan [Larsen01, Fitzgerald&08].

SIC2000: A project carried out by GAO in Germany for integrating sensor soft-
ware and hardware in a banknote processing machine [Smith&99].

ISEPUMS: In a project from the space systems domain, VDM was used to
model the processing of messages communicated to the SPOT4 satellite
[Puccetti&99].

Below we review two relatively recent industrial applications of VDM, both in
Japan and both using VDM++. The first, TradeOne, is in the financial sector, and



228 13 Using VDM in Practice

the second is in embedded chip design. In each case, we describe the application
and the metrics gathered during the project.

The TradeOne project
TradeOne is a back-office system aiming to lower operating costs in

trading securities. A description of the use of VDM++ in TradeOne has been
provided elsewhere ([Fitzgerald&05], Chapter 11) but here we will give a flavour
of the development and discuss some of the metrics from the VDM development.

The users of the TradeOne system are securities companies and brokerage
houses trading in securities. A security is a certificate attesting credit or the
ownership of stocks, options, bonds, etc. An option is a contract that entitles its
owner to either buy or sell a security or an index at a certain price before a cer-
tain date. The dates at which securities should be exercised, cancelled or agreed
are critical to successful business in this domain. TradeOne’s functionality cov-
ers several areas, two of which have been developed using VDM++: the tax
exemption subsystem and the option subsystem. The former automates the han-
dling of Japanese tax regulations, previously a manual and error-prone task. The
latter is responsible for handling the business process related to trading options.
This kind of automated support is necessary to accommodate business process
change, for example, to reduce the securities transaction settlement date.

The tax exemption subsystem was developed by a small team of six develop-
ers, averaging four people per month for three and a half months. In an initial
design phase a system architect derived a framework for the VDM++ models.
After this, four VDM++ experts developed the models, all of which were re-
viewed by all the members of the project team. Finally two expert programmers
implemented the subsystem manually from the VDM++ models.

Each member of the development team had more than 20 years’ experience
in software development. However, for all of them it was their first development
using C++ and Java. For all but one, it was also their first application in the
financial domain. Four members of the team had some basic prior knowledge of
formal methods and so had little difficulty applying VDM++ on this subsystem.
An external consultant was also used for the development of this subsystem.

The option subsystem was developed by a larger team of ten developers. On
average, 9.5 person-months were spent per calendar month. Initially, domain
experts wrote functional requirements for the subsystem in Japanese. In par-
allel, one of the VDM experts from the tax exemption subsystem taught three
new programmers VDM++ (in less than one week). It is worth remarking that
VDMTools support for Japanese language identifiers was used in the option



13.7 Industrial applications of VDM 229

Table 13.1 Size of TradeOne

System DSI (C++)
Total TradeOne 1,342,858
Tax exemption subsystem 18,431
Option subsystem 60,206

Table 13.2 Productivity in the TradeOne project

Subsystem COCOMO estimate Real time Time saving
Tax exemption Effort: 38.5 PM Effort: 14 PM Effort: 74%

Schedule: 9 M Schedule: 3.5 M Schedule: 61%
Option Effort: 147.2 PM Effort: 60.1 PM Effort: 60%

Schedule: 14.3 M Schedule: 7 M Schedule: 51%

subsystem development to make tools use more natural for the larger group of
engineers involved at this stage.

Metrics gathered Standard measuring principles based on the constructive cost
model (COCOMO) [Boehm81] were followed, so as to permit comparisons be-
tween TradeOne and other projects. In COCOMO the size of an application
can be measured in “delivered source instructions” (DSI). Sizes for the C++
implementations of the overall TradeOne system and the parts modelled using
VDM++ are given in Table 13.1.

The sizes of the corresponding VDM++ models were 11,757 DSI for the tax
exemption subsystem and 68,170 DSI for the option subsystem. These figures
include a test bed, test cases and informal comments explaining the VDM++
models. In total 3000 test cases were produced covering 100% of the VDM++
model. In the option subsystem model more than 30,000 lines are dedicated to
test cases alone.

On the productivity side, the COCOMO estimates for person-months (PM)
as well as duration are compared against the real effort spend and duration in
Table 13.2.

From a quality perspective, the defect rates measured at integration testing
were 0.65 defects/kDSI for the tax exemption subsystem and 0.71 defects/kDSI
for the option subsystem. The defects were readily fixed and are believed to have



230 13 Using VDM in Practice

originated in the requirement gathering phase. No defects have been identified
in the running implementations of these subsystems. The TradeOne product as a
whole had a defect rate of 1.12 defects/kDSI at integration test and 0.67 defect-
s/kDSI in the running implementation. This is in itself better than normal indus-
trial standards. To compare with defect rates elsewhere, the order of defects in
high-integrity space systems software is reputed to be around 0.1 defects/kDSI,
and at least 10 times normal development costs are required to reach this level of
correctness. For normal-quality commercial released code, the figure is around
30 defects/kDSI. This comparison suggests that the correctness reached in the
two subsystems developed using VDM++ is impressive.

The FeliCa Networks project
FeliCa Networks applied VDM in the development of operating system

software for a new generation of an integrated circuit for payment using elec-
tronic purse and contactless card technology [Kurita&08]. The incorporation
of additional functionality makes this new chip more complex than previous
generations. In spite of this, it must continue to operate to the strict timing
requirements met by its predecessors.

Over fifty people have been involved in the development of the product, with
an average age of a little over 30 years. No members of the team had previ-
ous knowledge or experience of VDM at the time of project launch. Training
was provided for the development team by CSK Systems and was delivered in
Japanese. In addition, an external VDM consultant from CSK Systems was used
throughout the project. This version of the firmware took approximately three
years to develop. It was delivered on schedule and, to date, more than 50 million
of the chips have been distributed.

Project teams and metrics gathered The development team was divided into
groups: one responsible for validation and verification, and one for implemen-
tation. Subsequently the members of each group completed questionnaires giv-
ing their impression of the use of VDM++. In addition an interview was held
with the twelve team members who had worked most closely with the VDM++
model. This feedback showed that none of the groups had negative reactions
to using VDM++ but the members of the implementation team did not see the
benefit of it as much as the others. VDM++ was felt to be an efficient com-
munication tool between the group members and between the groups. They all
acknowledged that new knowledge was required but also that there is a substan-
tial difference between the skills required in writing and reading a formal model.



13.7 Industrial applications of VDM 231

In general it was felt that advanced mathematics was not necessary for writing
or validating the VDM++ model.

The main results related to specification development were:

• A 383 page protocol manual written in natural language (Japanese).
This is a manual for other departments within the company as well as
for outside customers.

• A 677 page external specification document written in VDM++ (ap-
proximately 100 kDSI including comments). Approximately 60% of
that can be considered as test cases formulated in VDM.

The specification includes the specification of 86 different commands in the
firmware and the file system security specification. From this VDM++ model a
C/C++ code implementation of approximately 110 kDSI, including comments,
was implemented by hand as firmware for a single IC chip.

The validation team developed a high volume of VDM++ test cases that were
executed using the VDMTools interpreter. Using the VDMTools test cover-
age analysis facility, it was possible to display test coverage information on the
VDM++ model after executing the entire test suite. Here 82% of the VDM++
model was covered, and the remaining parts of the model were manually in-
spected. In order to support this development with an extremely high number of
test cases, the speed of the interpreter was improved by CSK Systems by more
than a factor of 100.

Looking at the results from the perspective of software quality, more errors
were found in the early phases of the development than in other similar projects
at FeliCa Networks. In total, 440 defects were detected in the requirements
and the specifications. Of these, 278 were detected directly as a result of the
use of VDM++. Of these, 162 were found by review of the model whereas
116 were discovered using the VDMTools interpreter with test cases against
the executable VDM++ model. It is important also to note that, at the time of
writing, no defect has been discovered since release.

Concluding remarks
The figures derived using the COCOMO model productivity metrics in

the TradeOne project are impressive. From a cost perspective these results are
outstanding from a first project using formal methods, in particular since most of
the people involved had only limited practical experience of formal techniques.
In addition, the metrics for defect rates are also very encouraging. In the Fe-
liCa Networks project it is felt that the first application using VDM++ did not



232 13 Using VDM in Practice

change the overall cost expectations for the product. However, the period for the
specification development became longer than in any similar project in FeliCa
Networks. It is important to manage the expectations of project management in
this regard. FeliCa Networks feels that their main advantage in this project has
been the improved quality and they expect that long-term productivity gains will
follow later.

Communication is the key to software development, in particular between
specification, implementation and validation teams, and in these studies VDM++
appears to have become a valuable communication tool. It is important that
management, project owners and project members are fully aware of this and
that they understand that VDM complements but does not replace existing tech-
niques. Finally, it is important that various methods and improvements are com-
bined and established as part of the corporate and organisational culture. The
next generation of the FeliCa Networks firmware is also currently being devel-
oped using VDM++. This is being done primarily because of the improvements
in communication between the different teams as well as the high quality result-
ing from this approach.

Several characteristics of the VDM technology have, we believe, contributed
to its success in recent applications. These include the emphasis placed on devel-
oping robust tools which are open to linkages with existing tool sets supporting,
for example, UML design. We have also focussed on analysis approaches, such
as the use of test scenarios and test coverage, that provide a route into the use
of a formalism without presenting a high initial hurdle to users. Our expecta-
tion is that this will lead on to the use of tools supporting more advanced static
analysis, proof support and test generation.

13.8 Moving on: information resources
VDM is fortunate in having an active and friendly international com-

munity of users and researchers. For those wishing to use modelling technology
of the kind described in this book, there is a wide range of available sources of
information. These include

• reports on industrial applications of formal techniques;
• guidelines for the application of modelling technology (such as the NASA

Guide Book);
• bibliographies on a range of formal modelling techniques;
• technical descriptions of models;
• electronic mailing lists;



13.8 Moving on: information resources 233

• industrial seminars and courses;
• conferences on industrial use and research in modelling technology.

Most of these resources are accessible electronically. Rather than risk giving
addresses which could soon become out of date, we refer the reader to the web
site accompanying this text, where full details and links to these resources are
available. The URL is http://www.vdmbook.com/.

Summary
The modelling techniques set out in this book aim to address some of

the problems which beset development of software in the commercial context.
The kind of benefits one can expect from using modelling technology such as
VDM can be characterised as follows:

Better clarification of requirements: A high-level abstract VDM model encour-
ages systematic analysis of requirements. The complexity of a full system
model or prototype is avoided by using abstractions relevant to the model’s
purpose.

Earlier feedback from customer: Constructing a high-level model makes it pos-
sible to get feedback from customers and/or domain experts about the initial
capture and understanding of the requirements. The feedback can be obtained
through a range of validation techniques, including visualisation, testing and
proof.

Raising confidence in descriptions: The rigour of the notation makes it possi-
ble, when desired, to automatically carry out a number of consistency checks
which raise the level of confidence one can have in the description.

Shorter time to market: Early analysis of requirements helps to reduce rework
in the late stages of the development, improving time to market. Formal
techniques assist this process by making available a full range of analysis
techniques.

Reducing maintenance costs: An abstract formal model of the software devel-
oped can help in predicting the consequences of changes in requirements dur-
ing maintenance and evolution.





Appendix A
Language Guide

A model written in VDM-SL is a collection of the following:

• modular structuring mechanisms;
• data type definitions;
• function definitions;
• operation definitions;
• value (constant) definitions; and
• a state definition.

Each collection of definitions is prefixed by a keyword (e.g. types). Individual
definitions are separated by semicolons. Such definitions may be structured
inside modules.

This appendix provides an overview of the constructs in the subset of VDM-
SL treated in this book. Finally there is a BNF grammar for the subset of VDM-
SL covered in this book.

A.1 Identifiers

The different kinds of definitions which can be made in VDM-SL are
named using identifiers. The naming conventions used in this book are as fol-
lows:

• Functions, operations and types begin with an upper-case letter for each
word or abbreviation of which the name is composed.

• Constant values begin with lower-case characters and use underscores
between words or abbreviations of which these are composed.

• Local identifiers are always sequences of lower-case characters and usu-
ally rather short names are used.

However, this is only a convention and is not mandatory.

235



236 Appendix A Language Guide

A.2 Type definitions
As in traditional programming languages it is possible to define data

types in VDM-SL and give them appropriate names. For example,

Amount = nat

Hereby we have defined a data type with the name “Amount” and stated that
the values which belong to this type are natural numbers (nat is one of the basic
types described below). One general point about the type system of VDM-SL
which is worth mentioning at this point is that equality and inequality can be
used between any values. In programming languages it is often the case that it
is required that the operands have the same type. Because of a construct called
a union type (described below) this is not the case for VDM-SL.

It is also possible to define record types in VDM-SL. As can be seen from
Subsection A.4.8 this is done using a :: notation rather than the equality sign
used in the type definition of Amount above.

Invariants
In VDM-SL it is possible to attach invariants to a type definition.

Type-name = type-expression
inv pattern == logical-expression

The pattern can be a single identifier or a more complex pattern if the in-
variant is attached to a complex type. In the latter case the pattern must match
the structure of all values belonging to the type denoted by the type expression.
Invariants can be used both for types defined using the equality sign and with
the double colon notation (::).

A.3 Basic data types and type constructors
In VDM-SL there is a distinction between types (which can contain

infinitely many values) and sets of values (which always are finite). The basic
types from VDM-SL are

• The positive natural numbers starting from 1 written as nat1;
• The natural numbers starting from 0 written as nat;
• The integers written as int;
• The real numbers written as real;
• The Booleans written as bool;
• The characters written as char;



A.4 Data type operator overview 237

• The token type written as token;
• The quote types written as ordinary identifiers surrounded by angle

brackets, e.g. <Red>.

In addition VDM-SL contains type constructors to produce

• sets constructed by the set of operator;
• sequences constructed by the seq of operator;
• mappings constructed by the map to operator;
• tuples constructed by the * operator;
• unions constructed by the | operator;
• optional types constructed by the [ ] operator;
• records which can be constructed using a :: notation in the type defi-

nition as shown in Subsection A.4.8.

A.4 Data type operator overview
This section provides an overview of all the basic operators for each of

the basic types and all the types which can be constructed. The basic construc-
tors are also presented here. The basic constructors for the compound types are
all explained informally. For each type a table shows each operator in use, its
name and its signature.

A.4.1 The Boolean type
The operations on the Boolean type are explained in Chapter 4.

Operator Name Signature
not b Negation bool→ bool
a and b Conjunction bool * bool→ bool
a or b Disjunction bool * bool→ bool
a => b Implication bool * bool→ bool
a <=> b Biimplication bool * bool→ bool
a = b Equality bool * bool→ bool
a <> b Inequality bool * bool→ bool

See also Subsection A.5.3.

A.4.2 The numeric types
The operators on the numeric types are not explained in detail anywhere

because they are well-known from most programming languages.



238 Appendix A Language Guide

Operator Name Signature
-x Unary minus real→ real
abs x Absolute value real→ real
x + y Sum real * real→ real
x - y Difference real * real→ real
x * y Product real * real→ real
x / y Division real * real→ real
x div y Integer division int * int→ int
x mod y Modulus int * int→ int
x**y Power real * real→ real
x < y Less than real * real→ bool
x > y Greater than real * real→ bool
x <= y Less or equal real * real→ bool
x >= y Greater or equal real * real→ bool
x = y Equal real * real→ bool
x <> y Not equal real * real→ bool

A.4.3 The character, quote and token types

Characters, quotes and token values can only be compared with each
other. The characters from VDM-SL are presented in Table A.4.3. Quote literals
are written by the use of angle brackets around an identifier as described in
Subsection 5.3.1. Token values are written with a token constructor mk token
preceeding a value surrounded by parentheses as shown in Subsection 5.3.3.

Operator Name Signature
c1 = c2 Equal char * char→ bool
c1 <> c2 Not equal char * char→ bool

A.4.4 Set types

The use of sets is described in Chapter 6. In this section the set con-
structors and set operators are described.

Set enumeration: {e1, e2, ..., en} constructs a set of the enumerated ele-
ments. The empty set is represented as {}.

Set comprehension: {e | bd1, bd2, ..., bdm & P} constructs a set by eval-
uating the expression e on all the bindings for which the predicate P evaluates



A.4 Data type operator overview 239

Table A1: Character set

plain letter:
a b c d e f g h i j k l m
n o p q r s t u v w x y z
A B C D E F G H I J K L M
N O P Q R S T U V W X Y Z

delimiter character:
, : ; = ( ) | - [ ]
{ } + / < > <= >= <> .
* -> +> ==> || => <=> |-> <: :>
<-: :-> & == ** ˆ ++

digit:
0 1 2 3 4 5 6 7 8 9

other characters:
‘ ’ " @ ˜

newline:

white space:

The separators have no graphical form, but are a combination of white space and
line break. There are two separators: without line break (white space) and with
line break (newline).

to true. A binding is either a set binding or a type binding1. A set binding
bdn has the form pat in set s, where pat is a pattern (normally sim-
ply an identifier), and s is a set constructed by an expression. A type binding

1 Notice that type bindings cannot be executed by the interpreter because they in general
are not executable.



240 Appendix A Language Guide

is similar, in the sense that “in set” is replaced by a colon and s is replaced
with a type expression.

Set range: The set range expression is a special case of a set comprehension. It
has the form {e1, ..., e2}, where e1 and e2 are numeric expressions.
The set range expression represents the set of integers from e1 to e2 inclu-
sive. If e2 is smaller than e1 the set range expression represents the empty
set.

Operator Name Signature
e in set s1 Membership A * set of A → bool
e not in set s1 Not membership A * set of A → bool
s1 union s2 Union set of A * set of A → set of A
s1 inter s2 Intersection set of A * set of A → set of A
s1 \ s2 Difference set of A * set of A → set of A
s1 subset s2 Subset set of A * set of A → bool
s1 = s2 Equality set of A * set of A → bool
s1 <> s2 Inequality set of A * set of A → bool
card s1 Cardinality set of A → nat
dunion ss Distributed set of set of A → set of A

union
dinter ss Distributed set of set of A → set of A

intersection

Operator Name Semantics Description

Membership tests whether e is a member of the set s1.
Not membership tests whether e is not a member of the set s1.

Union yields the union of the sets s1 and s2, i.e. the
set containing all the elements of both s1 and
s2.

Intersection yields the intersection of sets s1 and s2, i.e.
the set containing the elements that are in both
s1 and s2.

Difference yields the set containing all the elements from
s1 that are not in s2. s2 need not be a subset
of s1.

Subset tests whether s1 is a subset of s2, i.e.
whether all elements from s1 are also in s2.
Notice that any set is a subset of itself.

Cardinality yields the number of elements in s1.



A.4 Data type operator overview 241

Operator Name Semantics Description

Distributed union the resulting set is the union of all the ele-
ments (these are sets themselves) of ss, i.e.
it contains all the elements of all the ele-
ments/sets of ss.

Distributed intersection the resulting set is the intersection of all the
elements (these are sets themselves) of ss,
i.e. it contains the elements that are in all the
elements/sets of ss. ss must be non-empty.

A.4.5 Sequence types

The use of sequences is described in Chapter 7.

Sequence enumeration: [e1,e2,..., en] constructs a sequence of the enu-
merated elements. A text literal is a shorthand for enumerating a sequence
of characters (i.e. "csk" = [’c’,’s’,’k’]). The empty sequence will
be represented as [].

Sequence comprehension: [e | id in set S & P] builds a sequence by
evaluating the expression e on all the bindings for which the predicate P eval-
uates to true. The expression e can use the identifier id. S is a set of num-
bers and id will be matched to the numbers in the normal order (the smallest
number first).

Subsequence: A subsequence of a sequence l is a sequence formed from con-
secutive elements of l; from index n1 up to and including index n2. It has
the form: l(n1, ..., n2), where n1 and n2 are positive integer expres-
sions (less than the length of l). If the lower bound n1 is smaller than 1 (the
first index in a non-empty sequence), the subsequence expression will start
from the first element of the sequence. If the upper bound n2 is larger than
the length of the sequence (the largest index which can be used for a non-
empty sequence), the subsequence expression will end at the last element of
the sequence.



242 Appendix A Language Guide

Operator Name Signature
hd l Head seq1 of A → A
tl l Tail seq1 of A → seq of A
len l Length seq of A → nat
elems l Elements seq of A → set of A
inds l Indices seq of A → set of nat1
l1 ˆ l2 Concatenation (seq of A) * (seq of A) → seq of A
conc ll Distributed seq of seq of A → seq of A

concatenation
l ++ m Sequence seq of A * map nat to A → seq of A

modification
l(i) Sequence seq of A * nat1→ A

index
l1 = l2 Equality (seq of A) * (seq of A) → bool
l1 <> l2 Inequality (seq of A) * (seq of A) → bool

Operator Name Semantics Description

Head yields the first element of l. l must be a non-
empty sequence.

Tail yields the subsequence of l where the first el-
ement is removed. l must be a non-empty
sequence.

Length yields the length of l.
Elements yields the set containing all the elements of l.

Indices yields the set of indices of l, i.e. the set
{1,...,len l}.

Concatenation yields the concatenation of l1 and l2, i.e. the
sequence consisting of the elements of l1 fol-
lowed by those of l2, in order.

Distributed concatenation yields the sequence where the elements (these
are sequences themselves) of ll are concate-
nated: the first and the second, and then the
third, etc.

Sequence modification the elements of l whose indices are in the do-
main of m are modified to the range value that
the index maps into. dom m must be a subset
of inds l

Sequence index yields the element of index i from l. The
index i must be in the indices of l.



A.4 Data type operator overview 243

A.4.6 Mapping types
The use of mappings is described in Chapter 8.

Mapping enumeration: {a1 |-> b1, a2 |-> b2, ..., an |-> bn}
constructs a mapping of the enumerated maplets. The empty mapping will be
represented as {|->}.

Mapping comprehension: {ed |-> er | bd1, ..., bdn & P} const-
ructs a mapping by evaluating the expressions ed and er on all the possible
bindings for which the predicate P evaluates to true. bd1, ..., bdn
are bindings of free identifiers from the expressions ed and er to sets or
types.

Operator Name Signature
dom m Domain (map A to B) → set of A
rng m Range (map A to B) → set of B
m1 munion m2 Map union (map A to B) * (map A to B) → map A to B
m1 ++ m2 Override (map A to B) * (map A to B) → map A to B
merge ms Distributed set of (map A to B) → map A to B

merge
s <: m Domain (set of A) * (map A to B) → map A to B

restrict to
s <-: m Domain (set of A) * (map A to B) → map A to B

restrict by
m :> s Range restrict to (map A to B) * (set of B) → map A to B
m :-> s Range restrict by (map A to B) * (set of B) → map A to B
m(d) Mapping apply (map A to B) * A → B
m1 = m2 Equality (map A to B) * (map A to B) → bool
m1 <> m2 Inequality (map A to B) * (map A to B) → bool

Two mappings m1 and m2 are compatible if any common element of dom m1
and dom m2 is mapped to the same value by both mappings.

Operator Name Semantics Description

Domain yields the domain (the set of keys) of m.
Range yields the range (the set of information val-

ues) of m.
Map union yields a mapping combined by m1 and m2

such that the resulting mapping maps the el-
ements of dom m1 as does m1, and the ele-
ments of dom m2 as does m2. The two map-
pings must be compatible.



244 Appendix A Language Guide

Operator Name Semantics Description

Override overrides and merges m1 with m2, i.e. it is
like a map union except that m1 and m2 need
not be compatible; any common elements are
mapped as by m2 (so m2 overrides m1).

Distributed merge yields the mapping that is constructed by
merging all the mappings in ms. The map-
pings in ms must be compatible.

Domain restricted to creates the mapping consisting of the ele-
ments in m whose key is in s. The set s need
not be a subset of dom m.

Domain restricted by creates the mapping consisting of the ele-
ments in m whose key is not in s. The set
s need not be a subset of dom m.

Range restricted to creates the mapping consisting of the ele-
ments in m whose information value is in s.
The set s need not be a subset of rng m.

Range restricted by creates the mapping consisting of the ele-
ments in m whose information value is not in
s. The set s need not be a subset of rng m.

Mapping apply yields the information value whose key is d.
The value d must be in the domain of m.

A.4.7 Tuple types
Values belonging to a tuple type are called tuples and they can only be

constructed using a tuple constructor written as mk (a1,a2,...,an), where
the different as are arbitrary values.

Operator Name Signature
t1 = t2 Equality T * T → bool
t1 <> t2 Inequality T * T → bool

A.4.8 Record types
Values belonging to a record type are called records and they can only be

constructed using a record constructor written as mk TagId(a1,a2,...,an)



A.4 Data type operator overview 245

where the different as are arbitrary values and TagId is a tag incorporated into
all values from the type with this name such that the origin is known.

Record types are often used as alternatives in union type definitions such as

MasterA = A | B | ...

where A and B are defined as record types themselves. In this situation the is
predicate can be used to distinguish the alternatives.

Operator Name Signature
r.i Field select A * Id → Ai
r1 = r2 Equality A * A → bool
r1 <> r2 Inequality A * A → bool
is A(r1) Is Id * MasterA→ bool

Record types are defined as

Type :: component name : type
component name : type
...
component name : type

For example, for a type defined

Date :: day : Day
month : Month
year : Year

the record constructor for Date is

mk_Date(_,_,_)

The field selectors are

_.day
_.month
_.year

A.4.9 Union and optional types
Union types are written as

MasterA = A | B | ...

The types used with the union type constructor A and B should either be basic
types or record types. This makes it easy to detect which (component) type
an element of a union type belongs to using either pattern matching or the is-
expression.



246 Appendix A Language Guide

An optional type is written as

[T]

where the brackets indicate a union between the elements from the type T and
the special value nil.

Operator Name Signature
t1 = t2 Equality A * A → bool
t1 <> t2 Inequality A * A → bool

A.5 Expressions
Where the previous section presented all basic operators, constructors

(using enumeration and comprehension) and selectors, this section will provide
an overview of the more complex expressions used for structuring large con-
structs conveniently.

A.5.1 Let expressions
A let expression has the form

let p1 = e1, ..., pn = en in e

where p1, ..., pn are patterns, e1, ..., en are expressions which match
the corresponding pattern pi and e is an expression, of any type, involving the
pattern identifiers of p1, ..., pn. The value of the entire let expression is
the value of the expression e in the context in which the patterns p1, ...,
pn are matched against the corresponding expressions e1, ..., en.

A let-be-such-that expression has the form

let b be st e1 in e2

where b is a binding of a pattern to a set value (or a type), e1 is a Boolean
expression and e2 is an expression, of any type, involving the pattern identifiers
of the pattern in b. The be st e1 part is optional. The value of the let-be
expression is the value of the expression e2 in the context in which the pattern
from b has been matched either against an element in the set from b or against
a value from the type in b2. If the be st e1 expression is present, only such
bindings where e1 evaluates to true in the matching context are used.

2 Remember that only the set bindings can be executed by means of the interpreter from
VDMTools.



A.5 Expressions 247

A.5.2 Conditional expressions

The if-expression has the form

if e1
then e2
else e3

where e1 is a Boolean expression, while e2 and e3 are expressions of any
type. The value of the if-expression is the value of e2 evaluated in the given
context if e1 evaluates to true in the given context. Otherwise the value of the
if-expression is the value of e3 evaluated in the given context.

The cases-expression has the form

cases e :
p11, p12, ..., p1n -> e1,
... -> ...,
pm1, pm2, ..., pmk -> em,
others -> emplus1

end

where e is an expression of any type, and all pijs are patterns which are
matched one by one against the expression e. The eis are expressions of any
type, and the keyword others and the corresponding expression emplus1
are optional. The value of the cases expression is the value of the ei expres-
sion evaluated in the context in which one of the pij patterns has been matched
against e. The chosen ei is the first entry where it has been possible to match
the expression e against one of the patterns. If none of the patterns match e an
others clause must be present, and then the value of the cases expression is
the value of emplus1 evaluated in the given context.

A.5.3 Quantified expressions

There are three forms of quantified expressions: namely universal (writ-
ten as forall), existential (written as exists) and unique existential (written
as exists1). Each give a Boolean value true or false, as explained in the
following.

The universal quantification has the form

forall bd1, bd2, ..., bdn & e

where each bdi is either a set binding of the form pi in set s or a type
binding of the form pi:type, and e is a Boolean expression involving the
pattern identifiers of the bdis. The universal quantified expression has the value



248 Appendix A Language Guide

true if e is true when evaluated in the context of every choice of bindings
from bd1, bd2, ..., bdn and false otherwise.

The existential quantification has the form

exists bd1, bd2, ..., bdn & e

where the bdis and the e are as for a universal quantification. It has the value
true if e is true when evaluated in the context of at least one choice of
bindings from bd1, bd2, ..., bdn and false otherwise.

The unique existential quantification has the form

exists1 bd & e

where bd is either a set bind or a type bind and e is a Boolean expression
involving the pattern identifiers of bd. It has the value true if e is true when
evaluated in the context of exactly one choice of bindings and false otherwise.

All quantified expressions have the lowest possible precedence. This means
that the longest possible constituent expression is taken. The expression is con-
tinued to the right as far as it is syntactically possible.

A.6 Patterns
A pattern is always used in a context where it is matched to a value of a

particular type. Matching consists of checking that the pattern can be matched to
the value, and binding any pattern identifiers in the pattern to the corresponding
values, i.e. ensuring that the identifiers are bound to those values throughout
their scope. In some cases where a pattern can be used, a binding can be used as
well (see the next section).

Matching is defined as follows:

1. A pattern identifier fits any type and can be matched to any value. If
it is an identifier, that identifier is bound to the value; if it is the “don’t
care” symbol -, no binding occurs.

2. A match value can only be matched against the value of itself; no bind-
ing occurs. If a match value is not a literal like e.g. 7 or <RED> it must
be an expression enclosed in parentheses in order to discriminate it from
a pattern identifier.

3. A set enumeration pattern is written as {p1,p2,...,pn} and it fits
only set values with n elements. The patterns p1,p2,...,pn are
matched to distinct elements of a set; all elements must be matched.

4. A set union pattern is written as p1 union p2 and it fits only set values.
The two patterns, p1 and p2, are matched to a partition of two subsets



A.7 Bindings 249

of a set. In VDMTools the two subsets will always be chosen so that
they are disjoint.

5. A sequence enumeration pattern is written as [p1,p2,...,pn] and
it fits only sequence values with length n. Each pattern is matched
against its corresponding element in the sequence value; the length of
the sequence value and the number of patterns must be equal.

6. A sequence concatenation pattern is written as p1ˆp2 and it fits only
sequence values. The two patterns are matched against two subse-
quences which together can be concatenated to form the original se-
quence value.

7. A tuple pattern is written as mk (p1,p2,...,pn) and it fits only tu-
ples with the same number of elements. Each of the patterns is matched
against the corresponding element in the tuple value.

8. A record pattern is written as mk TagId(p1,p2,...,pn) and it
fits only record values with the same tag TagId. Each of the patterns is
matched against the field of the record value. All the fields of the record
must be matched.

A.7 Bindings
A binding matches a pattern to a value. In a set binding the value is

chosen from the set defined by the set expression of the binding. In a type
binding the value is chosen from the type defined by the type expression. Notice
that type bindings cannot be executed by the interpreter from VDMTools. This
would require the interpreter to potentially have to search through an infinite
number of values such as the natural numbers.

A.8 Explicit function definition
An explicit function definition has the form

f: T1 * T2 * ... * Tn -> R1 * R2 * ... Rm
f(a1,a2,...,an) ==
expr

pre preexpr(a1,a2,...,an)

This definition has four parts, each shown on a separate line above:

The signature with the function name, the types of input parameters and the
type of the result;



250 Appendix A Language Guide

A parameter list naming the parameters to the function using patterns which
usually are simply names;

The body which is an expression stating the value of the result in terms of the
values of the inputs (here expr);

The pre-condition which is a logical expression stating the assumptions made
about the inputs. If a pre-condition is absent, the default is true.

A.9 Implicit functions
An implicit function definition has the form

f(a1:T1,a2:T2,...,an:Tn) res:R
pre preexpr(a1,a2,...,an)
post postexpr(a1,a2,...,an,res)

This definition has three parts, each shown on a separate line above:

The function heading with the function name, the names and types of input and
the result identifier;

The pre-condition which is a logical expression stating the assumptions made
about the inputs. If omitted, the default pre-condition is true.

The post-condition which is a logical expression stating the property relating
the inputs and result.

A.10 Operations
An implicit operation definition has the form

op(a1:T1,a2:T2,...,an:Tn) res:R
ext wr s1: ST1

rd s2: ST2
...

wr sn: STm
pre p(a1,a2,...,an,s1,s2,...,sm)
post q(a1,a2,...,an,res,s1˜,...sm˜,s1,s2,...,sm)

This definition has the following components:

The header with the operation name, the names and types of input parameters,
and any result. The header is shown on the first line above. Note that the
result is optional.

The externals clause indicated by the ext keyword. The clause lists the state
components to be used by the operation and indicates whether each compo-
nent may be read (rd) or both read and written (wr).



A.11 The state definition 251

The pre-condition indicated by the pre keyword. The pre-condition is a logical
expression stating the conditions that are assumed to hold when the operation
is applied. The pre-condition may be omitted, in which case it defaults to
true.

The post-condition indicated by the post keyword. The post-condition is a
logical expression relating the state and result value after the operation with
the state and inputs before: it describes the essence of the computation.

In the post-condition, the value of a state component in wr mode maybe deco-
rated with a “˜” symbol to refer the value of the state component immediately
before the operation was performed.

A.11 The state definition

The state definition has the form

state ident of
id1 : T1
...
idn : Tn

inv pat1 == inv
init id == id = mk_ident(expression list)
end

A state component identifier idi is declared of a specific type typei. The
invariant inv is a Boolean expression describing a property which must hold for
the state ident at all times. The init part describes a condition which must
hold initially. It should be noticed that, in order to use the VDMTools interpreter,
it is necessary to have an initialisation predicate (if any of the operations using
the state are to be executed). The body of this initialisation predicate must be
a binary equality expression with the name (which also must be used as the
pattern) of the entire state on the left-hand side of the equality and the right-
hand side must evaluate to a record value of the correct type as shown above.
This enables the interpreter to evaluate the init condition.

In the definition of both the invariant and the initial value the state must be
manipulated as a whole, and this is done by referring to it as a record tagged with
the state name. When a field in the state is manipulated in some operation, the
field must, however, be referenced directly by the field name without prefixing
it with the state name.



252 Appendix A Language Guide

A.12 Syntax overview
Wherever the syntax for parts of the language is presented in the doc-

ument it will be described in a BNF dialect. The BNF notation which is used
employs the following special symbols:

, the concatenate symbol
= the define symbol
| the definition separator symbol (alternatives)

[ ] enclose optional syntactic items
{ } enclose syntactic items which may occur zero or

more times
‘ ’ single quotes are used to enclose terminal symbols
meta identifier non-terminal symbols are written in lower-case let-

ters (possibly including spaces)
; terminator symbol to represent the end of a rule.

A.12.1 Module structuring
document = module, { module }

| definition block, { definition block } ;

module = ‘module’, identifier, interface,

[ module body ], ‘end’, identifier ;

interface = [ import definition list ],

export definition ;

import definition list = ‘imports’, import definition,

{ ‘,’, import definition } ;

import definition = ‘from’, identifier, import module signature ;

import module signature = ‘all’

| import signature, { import signature } ;

import signature = import types signature

| import values signature
| import functions signature
| import operations signature ;

import types signature = ‘types’, type import,

{ ‘;’, type import }, [ ‘;’ ] ;



A.12 Syntax overview 253

type import = name, [ ‘renamed’, name ]

| type definition, [ ‘renamed’, name ] ;

import values signature = ‘values’, value import,

{ ‘;’, value import }, [ ‘;’ ] ;

value import = name, [ ‘:’, type ], [ ‘renamed’, name ] ;

import functions signature = ‘functions’, function import,

{ ‘;’, function import }, [ ‘;’ ] ;

function import = name, [ [ type variable list ], ‘:’, function type ],

[ ‘renamed’, name ] ;

import operations signature = ‘operations’, operation import,

{ ‘;’, operation import }, [ ‘;’ ] ;

operation import = name, [ ‘:’, operation type ], [ ‘renamed’, name ] ;

export definition = ‘exports’, export module signature ;

export module signature = ‘all’

| export signature,
{ export signature } ;

export signature = export types signature

| values signature
| export functions signature
| operations signature ;

export types signature = ‘types’, type export,

{ ‘;’, type export }, [ ‘;’ ] ;

type export = [ ‘struct’ ], name ;

values signature = ‘values’, value signature,

{ ‘;’, value signature }, [ ‘;’ ] ;

value signature = name list, ‘:’, type ;

export functions signature = ‘functions’ function export,

{ ‘;’, function export } ;

function export = name list, [ type variable list ], ‘:’,

function type ;



254 Appendix A Language Guide

functions signature = ‘functions’ function signature,

{ ‘;’, function signature }, [ ‘;’ ] ;

function signature = name list, ‘:’, function type ;

operations signature = ‘operations’ operation signature,

{ ‘;’, operation signature }, [ ‘;’ ] ;

operation signature = name list, ‘:’, operation type ;

module body = ‘definitions’, definition block, { definition block } ;

A.12.2 Definitions
definition block = type definitions

| state definition
| value definitions
| function definitions
| operation definitions ;

Type definitions
type definitions = ‘types’, type definition, { ‘;’, type definition } ;

type definition = identifier, ‘=’, type, [ invariant ]

| identifier, ‘::’, field list, [ invariant ] ;

type = bracketed type

| basic type
| quote type
| union type
| tuple type
| optional type
| set type
| seq type
| map type
| type name ;

bracketed type = ‘(’, type, ‘)’ ;

basic type = ‘bool’ | ‘nat’ | ‘nat1’ | ‘int’ | ‘real’ | ‘char’ | ‘token’ ;

quote type = quote literal ;



A.12 Syntax overview 255

union type = type, ‘|’, type, { ‘|’, type } ;

tuple type = type, ‘*’, type, { ‘*’, type } ;

optional type = ‘[’, type, ‘]’ ;

set type = ‘set of’, type ;

seq type = ‘seq of’, type ;

map type = ‘map’, type, ‘to’, type ;

function type = discretionary type, ‘->’, type ;

discretionary type = type | ‘(’, ‘)’ ;

type name = name ;

field list = { field } ;

field = [ identifier, ‘:’ ], type ;

State definition
state definition = ‘state’, identifier, ‘of’, field list,

[ invariant ], [ initialisation ], ‘end’ ;

invariant = ‘inv’, invariant initial function ;

initialisation = ‘init’, invariant initial function ;

invariant initial function = pattern, ‘==’, expression ;

Value definitions
value definitions = ‘values’, value definition, { ‘;’, value definition } ;

value definition = name, [ ‘:’, type ], ‘=’, expression ;

Function definitions
function definitions = ‘functions’, function definition,

{ ‘;’, function definition } ;

function definition = explicit function definition |
implicit function definition ;



256 Appendix A Language Guide

explicit function definition = identifier, ‘:’, function type,

identifier, parameters,

‘==’, expression,

[ ‘pre’, expression ], ;

implicit function definition = identifier, parameter types ,

identifier type pair,

[ ‘pre’, expression ],

‘post’, expression ;

identifier type pair = identifier, ‘:’, type ;

parameter types = ‘(’, [ pattern type pair list ], ‘)’ ;

pattern type pair list = pattern list, ‘:’, type,

{ ‘,’, pattern list,‘:’, type } ;

parameters = ‘(’, [ pattern list ], ‘)’ ;

Operation definitions
operation definitions = ‘operations’, operation definition,

{ ‘;’, operation definition } ;

operation definition = identifier, parameter types, [ identifier type pair ],

[ externals ],

[ ‘pre’, expression ],

‘post’, expression ;

operation type = discretionary type, ‘==>’, discretionary type ;

externals = ‘ext’, var information, { var information } ;

var information = mode, name list, [ ‘:’, type ] ;

mode = ‘rd’ | ‘wr’ ;

Expressions
expression list = expression, { ‘,’, expression } ;

expression = bracketed expression

| let expression
| let be expression



A.12 Syntax overview 257

| if expression
| cases expression
| unary expression
| binary expression
| quantified expression
| set enumeration
| set comprehension
| set range expression
| sequence enumeration
| sequence comprehension
| subsequence
| map enumeration
| map comprehension
| tuple constructor
| record constructor
| apply
| field select
| is expression
| name
| old name
| symbolic literal ;

Bracketed expressions
bracketed expression = ‘(’, expression, ‘)’ ;

Local binding expressions
let expression = ‘let’, pattern, ‘=’, expression,

{ ‘,’, pattern, ‘=’, expression }, ‘in’, expression ;

let be expression = ‘let’, bind, [ ‘be’, ‘st’, expression ], ‘in’, expression ;

Conditional expressions
if expression = ‘if’, expression, ‘then’, expression, { elseif expression },

‘else’, expression ;

elseif expression = ‘elseif’, expression, ‘then’, expression ;



258 Appendix A Language Guide

cases expression = ‘cases’, expression, ‘:’, cases expression alternatives,

[ ‘,’, others expression ], ‘end’ ;

cases expression alternatives = cases expression alternative,

{ ‘,’, cases expression alternative } ;

cases expression alternative = pattern list, ‘->’, expression ;

others expression = ‘others’, ‘->’, expression ;

Unary expressions
unary expression = unary operator, expression ;

unary operator = ‘+’

| ‘-’
| ‘abs’
| ‘not’
| ‘card’
| ‘dunion’
| ‘dinter’
| ‘hd’
| ‘tl’
| ‘len’
| ‘elems’
| ‘inds’
| ‘conc’
| ‘dom’
| ‘rng’
| ‘merge’ ;

Binary expressions
binary expression = expression, binary operator, expression ;

binary operator = ‘+’

| ‘-’
| ‘*’
| ‘/’
| ‘div’
| ‘mod’



A.12 Syntax overview 259

| ‘<’
| ‘<=’
| ‘>’
| ‘>=’
| ‘=’
| ‘<>’
| ‘or’
| ‘and’
| ‘=>’
| ‘<=>’
| ‘in set’
| ‘not in set’
| ‘subset’
| ‘union’
| ‘\’
| ‘inter’
| ‘ˆ’
| ‘++’
| ‘munion’
| ‘<:’
| ‘<-:’
| ‘:>’
| ‘:->’ ;

Quantified expressions
quantified expression = all expression

| exists expression
| exists unique expression ;

all expression = ‘forall’, bind list, ‘&’, expression ;

exists expression = ‘exists’, bind list, ‘&’, expression ;

exists unique expression = ‘exists1’, bind, ‘&’, expression ;

Set expressions
set enumeration = ‘{’, [ expression list ], ‘}’ ;

set comprehension = ‘{’, expression, ‘|’, bind list, [ ‘&’, expression ], ‘}’ ;



260 Appendix A Language Guide

set range expression = ‘{’, expression, ‘,’, ‘...’, ‘,’, expression, ‘}’ ;

Sequence expressions
sequence enumeration = ‘[’, [ expression list ], ‘]’ ;

sequence comprehension = ‘[’, expression, ‘|’, set bind,

[ ‘&’, expression ], ‘]’ ;

subsequence = expression, ‘(’, expression, ‘,’, ‘...’, ‘,’, expression, ‘)’ ;

Mapping expressions
map enumeration = ‘{’, maplet, { ‘,’, maplet }, ‘}’ | ‘{’, ‘|->’, ‘}’ ;

maplet = expression, ‘|->’, expression ;

map comprehension = ‘{’, maplet, ‘|’, bind list, [ ‘&’, expression ], ‘}’ ;

Tuple constructor expression
tuple constructor = ‘mk ’, ‘(’, expression, expression list, ‘)’ ;

Record expressions
record constructor = ‘mk ’,3 name, ‘(’, [ expression list ], ‘)’ ;

Apply expressions
apply = expression, ‘(’, [ expression list ], ‘)’ ;

field select = expression, ‘.’, identifier ;

Generalised is-expressions
general is expression = is expression

| type judgement ;

is expression = ‘is ’,4 name, ‘(’, expression, ‘)’

| is basic type, ‘(’, expression, ‘)’ ;

3 Note: no delimiter is allowed.



A.12 Syntax overview 261

is basic type = ‘is ’, ( ‘bool’ | ‘nat’ | ‘nat1’ | ‘int’ | ‘real’ | ‘char’
| ‘token’ ) ;

type judgement = ‘is ’, ‘(’, expression, ‘,’, type, ‘)’ ;

Names
name = identifier, [ ‘‘’, identifier ] ;

identifier = ( plain letter ),

{ ( plain letter ) | digit | ‘’’ | ‘ ’ } ;

name list = name, { ‘,’, name } ;

old name = identifier, ‘˜’ ;

Literals
symbolic literal = numeric literal | boolean literal | nil literal

| character literal | text literal | quote literal ;

numeral = digit, { digit } ;

numeric literal = numeral, [ ‘.’, digit, { digit } ], [ exponent ] ;

exponent = ( ‘E’ | ‘e’ ), [ ‘+’ | ‘-’ ], numeral ;

boolean literal = ‘true’ | ‘false’ ;

nil literal = ‘nil’ ;

character literal = ‘’ ’, character – newline, ‘’ ’ ;

character = plain letter

| digit
| delimiter character
| other character
| separator ;

separator = newline | white space ;

text literal = ‘" ’, { ‘"" ’ | character – ( ‘" ’ | newline ) }, ‘" ’ ;

quote literal = distinguished letter, { ‘ ’ | distinguished letter | digit } ;

4 Note: no delimiter is allowed.



262 Appendix A Language Guide

Patterns
pattern = pattern identifier

| match value
| set enum pattern
| set union pattern
| seq enum pattern
| seq conc pattern
| tuple pattern
| record pattern ;

pattern identifier = identifier | ‘-’ ;

match value = ‘(’, expression, ‘)’ | symbolic literal ;

set enum pattern = ‘{’, [ pattern list ], ‘}’ ;

set union pattern = pattern, ‘union’, pattern ;

seq enum pattern = ‘[’, [ pattern list ], ‘]’ ;

seq conc pattern = pattern, ‘ˆ’, pattern ;

tuple pattern = ‘mk ’, ‘(’, pattern, ‘,’, pattern list, ‘)’ ;

record pattern = ‘mk ’,5 name, ‘(’, [ pattern list ], ‘)’ ;

pattern list = pattern, { ‘,’, pattern } ;

Bindings
pattern bind = pattern | bind ;

bind = set bind | type bind ;

set bind = pattern, ‘in set’, expression ;

type bind = pattern, ‘:’, type ;

bind list = multiple bind, { ‘,’, multiple bind } ;

multiple bind = multiple set bind | multiple type bind ;

multiple set bind = pattern list, ‘in set’, expression ;

multiple type bind = pattern list, ‘:’, type ;

5 Note: no delimiter is allowed.



Appendix B
Solutions to Exercises

This appendix contains solutions to the majority of exercises in the book. How-
ever, solutions for exercises generating large files or requiring extensive use of
VDMTools are given on the book’s web site.

B.1 Solutions for Chapter 2 Exercises
2.1 1. It is correct that the Data field is not used in any of the functions

defined so far. However, the engineer may envisage that the data will
be needed for other functions to be defined later. Thus, for the model
presented, the Data could be entirely abstracted away. In this case
no definition is present at all so one may wonder whether the engineer
has carried out a type check of the model.

2. This is ensured by the pre-condition of Request. This states that
forall t1 in set dom ans & t1 < t, i.e. all requests made
since the system was started should be at a time earlier than (i.e. less
than) the current time t.

3. Clear is to be used for initialisation of the system.
4. RaiseAlarm would have to be changed to reflect such a change.

B.2 Solutions for Chapter 3 Exercises
3.1 See VDMTools Lite.
3.2 See VDMTools Lite.
3.3 1. 1

2. 3
3. {mk token("Monday day"),mk token("Tuesday day")}
4. {}
5. {mk token("Tuesday day")}

3.4

ChangeExpert: Plant * Expert * Expert * Period -> Plant
ChangeExpert(mk_Plant(plan,alarms),ex1,ex2,peri) ==

263



264 Appendix B Solutions to Exercises

mk_Plant(plan ++ {peri |-> plan(peri)\{ex1} union {ex2}},alarms)
pre peri in set dom plan and

ex1 in set plan(peri) and
ex2 not in set plan(peri) and
forall a in set alarms &

QualificationOK(plan(peri)\{ex1} union {ex2},a.quali)

B.3 Solutions for Chapter 4 Exercises
4.1 1. true

2. false
3. true

4.2 1. true
2. false
3. false

4.3

((false and false) or true) => false
(false or true) => false
true => false
false

4.4 1. forall i in set inds temp & temp(i) < 400 and temp(i)
> 50

2. forall i in set inds temp\{1} & temp(i - 1) > temp(i)
and temp(i - 1) + 10 <= temp(i)

3. exists i,j in set inds temp & i <> j and temp(i)
> 400 and temp(j) > 400

4.5 See VDMTools Lite.
4.6

functions
OnePeak2: TempRead -> bool
OnePeak2(temp) ==

PeakAt(temp,1) or PeakAt(temp,2) or
PeakAt(temp,3) or PeakAt(temp,4) or
PeakAt(temp,5);

PeakAt: TempRead * nat1 -> bool
PeakAt(temp,i) ==

(temp(1) > 400 => i = 1) and
(temp(2) > 400 => i = 2) and
(temp(3) > 400 => i = 3) and
(temp(4) > 400 => i = 4) and
(temp(5) > 400 => i = 5)



B.4 Solutions for Chapter 5 Exercises 265

pre i in set inds temp

4.7

functions
ExistsUnique: (nat -> bool) * set of nat -> bool
ExistsUnique(pred,s) ==

exists x in set s & pred(s) and Unique(pred,s)

4.8

functions

Xor: bool * bool -> bool
Xor(a,b) ==

not (a <=> b);

Nand: bool * bool -> bool
Nand(a,b) ==

not (a and b)

4.9 This is identical to the truth table for A => B.

B.4 Solutions for Chapter 5 Exercises
5.1

forall con in set conflicts & inv_Conflict(con)

5.2

Controller :: lights : map Path to Light
conflicts : set of Conflict

inv mk_Controller(ls,cs) ==
forall c in set cs &

mk_Conflict(c.path2,c.path1) in set cs and
c.path1 in set dom ls and
c.path2 in set dom ls and
(ls(c.path1) = <Red> or ls(c.path2) = <Red>)

5.3

ToRed: Path * Controller -> Controller
ToRed(p,mk_Controller(lights,conflicts)) ==

mk_Controller(lights ++ {p |-> <Red>},conflicts)

and

ToAmber: Path * Controller -> Controller
ToAmber(p,mk_Controller(lights,conflicts)) ==

mk_Controller(lights ++ {p |-> <Amber>},conflicts)



266 Appendix B Solutions to Exercises

5.4 The consequence is that we get a Run-Time Error informing us that the pre-
condition is broken. This check is only performed when the pre-condition
option is switched on.

5.5 It is not possible to change the light for path p1 at all using the defined
values for controller. This means that the light for path p1 cannot be
changed in the current state. Using path p3, it is observed that the pre-
condition for ToAmber yields true, indicating that the light on this path
could be changed to amber.

5.6 For example,

print ToColour(p3,kernel,8,<Amber>)
print ToColour(p4,$$,10,<Amber>)
print ToColour(p4,$$,15,<Red>)
print ToColour(p3,$$,19,<Red>)
print ToColour(p1,$$,24,<Green>)
print ToColour(p2,$$,28,<Green>)

5.7 For example ToAmber(p1,controller,-9) will break the Time in-
variant.

B.5 Solutions for Chapter 6 Exercises
6.1 A singleton set e.g. {12} and an empty set {}.
6.2 1. {1,2,3,4}

2. {2,4,6}
3. {2,3,4,5,6,7,8}

6.3 1. {5}
2. {}
3. {10000000000,285311670611,8916100448256}

6.5 1. 4
2. 0
3. 6

6.6 1. {{1,3},{7,12},{1,5,6}}
2. {2,3}
3. {2,3,4,5,6,7,8,9,10}

6.7 1. {89, 33}
2. {89, 33}
3. {21,23,25,27,29,31,33,35,37,39}

6.8

SetDiff: set of nat * set of nat -> set of nat
SetDiff(s1,s2) ==



B.5 Solutions for Chapter 6 Exercises 267

{e | e in set s1 & e not in set s2}

6.9 1. false
2. true
3. false

6.10 See VDMTools Lite.
6.11 1. {1,3,4,5,11,12}

2. {}
3. {1,2,3,4,5,6}
4. {1,2,{1}}

6.12

ListBigItems: Site * nat * nat -> Inventory
ListBigItems(site,xmin,ymin) ==

{inve | inve in set SiteInventory(site) &
inve.item.xlength > xmin and
inve.item.ylength > ymin}

6.13 1. {3,4,5}
2. {5}
3. {1,2,3,4,5,6}
4. {}

6.14

forall s1,s2 in set s & s1 <> s2 => s1 inter s2 = {}

6.15 The entire solution is placed on the web page for the book as explo3.vdm.
1. Class = <Expl> | <Fuse>
2.

Object :: class : Class
position : Point
xlength : nat
ylength : nat

3.

SafeSpace: Object -> set of Point
SafeSpace(o) ==

{mk_Point(x,y)
| x in set {Bottom(o.position.x),...,o.position.x + 10},

y in set {Bottom(o.position.y),...,o.position.y + 10}}

4.

Overlap: Object * Object -> bool
Overlap(o1,o2) ==

Points(o1) inter Points(o2) <> {} or
(o1.class <> o2.class and



268 Appendix B Solutions to Exercises

SafeSpace(o1) inter Points(o2) <> {});

B.6 Solutions for Chapter 7 Exercises
7.1 1. [5, 3, 3, 9]

2. [9, 3, 2, 3]
3. [9]
4. []

7.2

FilterBig: seq of int * int -> seq of int
FilterBig(s,n) ==

[s(i) | i in set inds s & s(i) <= n]

7.3 The call stack expands to

SeqSum([2,8,5,6])
SeqSum([8,5,6])
SeqSum([5,6])
SeqSum([6])
SeqSum([])

7.4

Indices: seq of int -> set of nat1
Indices(l) ==

{1,...,len l}

7.5 1. {<Red>}
2. {2,5,4}
3. {}
4. {[5,4,5]}

7.6 1. [<Green>]
2. [5,4,6]
3. [8,8,8,2,3,4]

B.7 Solutions for Chapter 8 Exercises
8.1 1. {1 |-> 2,2 |-> 4,3 |-> 6,4 |-> 8}

2. {2 |-> true,4 |-> true,6 |-> true}
3. {2 |-> 2,3 |-> 3,4 |-> 4,5 |-> 5,6 |-> 6}

If subtraction is used instead of addition for this exercise a run-time error will
occur because the mapping is no longer unique. One should always be careful
about this when one is defining mappings using comprehensions.



B.7 Solutions for Chapter 8 Exercises 269

8.2 1. {3, 4, 7}
2. {4, 8}
3. {}

8.3 1. {9,10,11,12,13,14,15}
2. {1,4,27,256,3125}

8.4

Compatible: (map nat to nat) * (map nat to nat) -> bool
Compatible(m,n) ==

forall a in set dom m inter dom n & m(a) = n(a)

8.5 1. {1 |-> 3,2 |-> 4,3 |-> 8,4 |-> 8,7 |-> 4}
2. {3 |-> 8,4 |-> 8,5 |-> 4,7 |-> 4}
3. {8 |-> true, 9 |-> false}

8.6 1. {1 |-> 3,2 |-> 4,3 |-> 8,4 |-> 8,7 |-> 4}
2. {3 |-> 3,4 |-> 8,5 |-> 4,7 |-> 4}
3. {8 |-> true, 9 |-> false}

8.7

m :-> as = {x |-> m(x) | x in set dom m & m(x) not in set as}
m :> as = {x |-> m(x) | x in set dom m & m(x) in set as}

8.8 By debugging calls of the inv Tracker function with values violating
this.

8.9

Find(db:Tracker, cid:ContainerId) p: PhaseId | <NotAllocated>
| <UnknownContainer>

post if cid not in set dom db.containers
then p = <UnknownContainer>
elseif exists pid in set dom db.phases &

cid in set db.phases(pid).contents
then p in set dom db.phases and

cid in set db.phases(p).contents
else p = <NotAllocated>

8.10 Note that the invariant for Site no longer is needed:

types

Site = map StoreName to Store;

Store :: contents : set of Object
xbound : nat
ybound : nat

inv mk_Store(contents, xbound, ybound) ==
forall o in set contents & InBounds(o,xbound,ybound)
and



270 Appendix B Solutions to Exercises

not exists o1, o2 in set contents &
o1 <> o2 and Overlap(o1,o2)

Inventory = set of InventoryItem;

InventoryItem :: store : StoreName
item : Object

functions

SiteInventory: Site -> Inventory
SiteInventory(site) ==

dunion {StoreInventory(name,site(name).contents)
| name in set dom site};

StoreInventory: StoreName * set of Object -> Inventory
StoreInventory(name,objects) ==

{mk_InventoryItem(name,o) | o in set objects}

8.11

Over: seq of (map A to B) -> map A to B
Over(map_seq) ==

if map_seq = []
then {|->}
else hd map_seq ++ Over(tl map_seq)

8.12

Merge: set of (map A to B) -> map A to B
Merge(map_s) ==

if map_s = {}
then {|->}
else let m in set map_s

in
m munion Merge(map_s \ {m})

pre forall m1, m2 in set map_s &
forall d in set (dom m1 inter dom m2) &

m1(d) = m2(d)

B.8 Solutions for Chapter 9 Exercises
9.1

SumTree: Tree -> nat
SumTree(t) ==

cases t:
mk_Node(l,r) -> SumTree(l) + SumTree(r),
others -> t

end



B.8 Solutions for Chapter 9 Exercises 271

9.2 See using VDMTools.
9.3

MaxGenTree: GenTree -> nat
MaxGenTree(t) ==

cases t:
mk_Node(l) -> MaxSeq([MaxGenTree(l(i)) | i in set inds l]),
others -> t

end;

MaxSeq: seq of nat -> nat
MaxSeq(s) ==

cases s:
[n] -> n,
others -> max(hd s, MaxSeq(tl s))

end
pre s <> [];

SumGenTree: GenTree -> nat
SumGenTree(t) ==

cases t:
mk_Node(l) -> SumSeq([SumGenTree(l(i)) | i in set inds l]),
others -> t

end;

SumSeq: seq of nat -> nat
SumSeq(s) ==

if s = []
then 0
else hd s + SumSeq(tl s)

9.4

SetSum: set of nat
SetSum(s) ==

if s = {}
then 0
else let e in set s

in
e + SetSum(s \ {e})

9.5

types

Expr = Value | BinaryExpr | UnaryExpr;

Value = int;

BinaryExpr :: left : Expr
op : BinaryOp



272 Appendix B Solutions to Exercises

right : Expr;

BinaryOp = <Add> | <Sub> | <Mult> | <Sub>;

UnaryExpr :: op : UnaryOp
operang : Expr;

UnaryOp = <Minus> | <Plus>

functions

Eval: Expr -> int
Eval(e) ==

cases e:
mk_BinaryExpr(l,op,r) -> EvalBinaryOp(op,Eval(l),Eval(r)),
mk_UnaryOp(op,expr) -> EvalUnaryOp(op,Eval(expr)),
others -> e

end
pre is_BinaryExpr(e) =>

pre_EvalBinaryOp(e.op,Eval(e.left),Eval(e.right));

EvalBinaryOp: BinaryOp * int * int -> int
EvalBinaryOp(op,l,r) ==

cases op:
<Add> -> l + r,
<Sub> -> l - r,
<Mult> -> l * r,
<Div> -> l div r

end
pre op = <Div> => r <> 0;

EvalUnaryOp: UnaryOp * int -> int
EvalUnaryOp(op,r) ==

cases op:
<Minus> -> -r,
<Plus> -> r

end

9.6

types

LabGraph = map NodeId to (map ArcId to NodeId)
inv g ==

UniqueArcIds(g) and
forall m in set rng g & rng m subset dom g;

AcyclicLabGraph = LabGraph
inv acg ==

not exists id in set dom acg &



B.9 Solutions for Chapter 10 Exercises 273

id in set AllLabDesc(acg,id);

NodeId = nat;

ArcId = nat

functions

AllLabDesc: LabGraph * NodeId -> set of NodeId
AllLabDesc(g,id) ==

dunion {LabDescendants(g,c,{})| c in set rng g(id)}
pre id in set dom g;

LabDescendants: LabGraph * NodeId * set of NodeId -> set of NodeId
LabDescendants(g,id,reached) ==

if id in set reached
then {}
else {id} union

dunion {LabDescendants(g,c,reached union {id})
| c in set rng g(id)}

pre id in set dom g;

UniqueArcIds: map NodeId to (map ArcId to NodeId) -> bool
UniqueArcIds(g) ==

let m = {nid |-> dom g(nid) | nid in set dom g}
in
forall nid1, nid2 in set dom m &

nid1 <> nid2 => m(nid1) inter m(nid2) = {}

9.7

SubPath: Path * Path -> bool
SubPath(p1,p2) ==

exists i,j in set inds p1 & p2 = p1(i,...,j);

Chains2: Graph -> set of Path
Chains2(g) ==

{p | p : Path & IsLinear(g,p) and
forall p2 : Path & p <> p2 => not SubPath(p2,p)}

B.9 Solutions for Chapter 10 Exercises
10.1

(forall trk : Tracker, cid : ContainerId,
ptoid : PhaseId, pfromid : PhaseId &

Permission(trk, cid, ptoid) and
pre_Remove(trk, cid, pfromid) =>
ptoid in set dom (trk.phases))



274 Appendix B Solutions to Exercises

10.2 Assume the following value definitions:

values
cid = mk_token(1);
pid = mk_token(2);
mid = mk_token(5);
cinfo = {cid|->mk_Container(3.5,mid)};
pinfo1 = {pid|->mk_Phase({cid},mid,1)});
pinfo2 = {pid|->mk_Phase({cid},mid,6)})

Permission(mk_Tracker(cinfo,{|->}),cid,pid)

Permission(mk_Tracker(cinfo,pinfo1,cid,pid)

Permission(mk_Tracker(cinfo,pinfo2,cid,pid)

10.3

values

glass = mk_token("Glass");

liquid = mk_token("liquid");

metal = mk_token("metal");

plastic = mk_token("plastic");

all_material = {glass,liquid,metal,plastic};

unpacking_inital = mk_Phase({},all_material,5);

sorting_inital = mk_Phase({},all_material,6);

assay_inital = mk_Phase({},all_material,5);

compaction_inital = mk_Phase({},{glass,metal,plastic},3);

storage_inital = mk_Phase({},{glass,metal,plastic},50);

coninfo_inital = {|->};

phases_inital = {mk_token("Unpacking") |-> unpacking_inital,
mk_token("Sorting") |-> sorting_inital,
mk_token("Assay") |-> assay_inital,
mk_token("Compaction")|-> compaction_inital,
mk_token("Storage") |-> storage_inital};

tracker_inital = mk_Tracker(coninfo_inital,phases_inital)



B.10 Solutions for Chapter 11 Exercises 275

functions

SetUp: () -> Tracker
SetUp() ==

tracker_inital

B.10 Solutions for Chapter 11 Exercises
11.1

operations

AddString(str: String) err: <Ok> | <AlreadyThere>
ext wr cat: Category
post if str in set cat

then cat = cat˜ and and err = <AlreadyThere>
else cat˜ union {str} = cat and err = <Ok>;

RomoveString(str: String)
ext wr cat: Category
post cat = cat˜ \ {str};

AddMessage(m: Message)
ext wr input : seq of Message
post input = input˜ ˆ [m]





Bibliography

[Ammann95] Paul Ammann. A Safety Kernel for Traffic Light Control. In
COMPASS’95: Proceedings of the Tenth Annual Conference on
Computer Assurance, pages 71–82, June 1995. Gaithersburg,
MD.

[Ammann96] Paul Ammann. A Safety Kernel for Traffic Light Control. IEEE
Aerospace and Electronic Systems Magazine, 11(2):13–19, Febru-
ary 1996.

[Andersen&92] Michael Andersen and René Elmstrøm and Poul Bøgh Lassen
and Peter Gorm Larsen. Making Specifications Executable – Us-
ing IPTES Meta-IV. Microprocessing and Microprogramming,
35(1-5):521–528, September 1992.

[Bicarregui&94] Juan Bicarregui and John Fitzgerald and Peter Lindsay and Richard
Moore and Brian Ritchie. Proof in VDM: A Practitioner’s Guide.
FACIT, Springer-Verlag, 1994. 245 pages.

[Boehm81] B. Boehm. Software Engineering Economics. Prentice-Hall In-
ternational, 1981. 767 pages.

[Booch&97] Grady Booch and Ivar Jacobson and Jim Rumbaugh. The Unified
Modelling Language, version 1.1. Technical Report, Rational
Software Corporation, September 1997.

[Brookes&96] Tom M. Brookes and John S. Fitzgerald and Peter Gorm Larsen.
Formal and Informal Specifications of a Secure System Compo-
nent: Final Results in a Comparative Study. In Marie-Claude
Gaudel and Jim Woodcock, editors, FME’96: Industrial Bene-
fit and Advances in Formal Methods, pages 214–227, Springer-
Verlag, March 1996.

277



278 Bibliography

[Clement&99] Tim Clement and Ian Cottam and Peter Froome and Claire Jones.
The Development of a Commercial “Shrink-Wrapped” Applica-
tion to Safety Integrity Level 2: the DUST-EXPERT Story. In
Safecomp’99, Springer-Verlag, September 1999. LNCS 1698,
ISBN 3-540-66488-2.

[Fitzgerald&05] John Fitzgerald and Peter Gorm Larsen and Paul Mukherjee and
Nico Plat and Marcel Verhoef. Validated Designs for Object-
oriented Systems. Springer, New York, 2005.

[Fitzgerald&07a] J. S. Fitzgerald and P. G. Larsen. Triumphs and Challenges for
the Industrial Application of Model-Oriented Formal Methods.
In T. Margaria and A. Philippou and B. Steffen, editors, Pro-
ceedings of the 2nd IEEE International Symposium on Lever-
aging Applications of Formal Methods, Verification and Valida-
tion (ISoLA 2007), 2007.

[Fitzgerald&07b] J. S. Fitzgerald and P. G. Larsen. Balancing Insight and Effort:
the Industrial Uptake of Formal Methods. In Cliff B. Jones and
Zhiming Liu and Jim Woodcock, editors, Formal Methods and
Hybrid Real-Time Systems, Essays in Honour of Dines Bjørner
and Chaochen Zhou on the Occasion of Their 70th Birthdays,
pages 237–254, Springer, Lecture Notes in Computer Science,
Volume 4700, September 2007. ISBN 978-3-540-75220-2.

[Fitzgerald&08] John Fitzgerald and Peter Gorm Larsen and Shin Sahara. VDM-
Tools: advances in support for formal modeling in VDM. Sigplan
Notices, 43(2):3–11, February 2008.

[Fitzgerald&95] John Fitzgerald and Peter Gorm Larsen and Tom Brookes and
Mike Green. Applications of Formal Methods, chapter 14. De-
veloping a Security-critical System using Formal and Conven-
tional Methods, pages 333–356. Prentice-Hall International Se-
ries in Computer Science, 1995.

[Fitzgerald&98] John S. Fitzgerald and Cliff B. Jones. Proof in the Validation of a
Formal Model of a Tracking System for a Nuclear Plant. In Juan
C. Bicarregui, editor, Proof in VDM: Case Studies, Springer-
Verlag, 1998.

[Fuchs92] Norbert E. Fuchs. Specifications are (Preferably) Executable.
Software Engineering Journal, 323–334, September 1992.



Bibliography 279

[Hall96] Antony Hall. Using Formal Methods to Develop an ATC Infor-
mation System. IEEE Software, 12(6):66–76, March 1996.

[Hayes&89] Ian J. Hayes and Cliff B. Jones. Specifications Are not (Nec-
essarily) Executable. Software Engineering Journal, 330–338,
November 1989.

[ISOVDM96] P. G. Larsen and B. S. Hansen and H. Brunn and N. Plat and
H. Toetenel and D. J. Andrews and J. Dawes and G. Parkin and
others. Information technology – Programming languages, their
environments and system software interfaces – Vienna Develop-
ment Method – Specification Language – Part 1: Base language.
December 1996.

[Jones99] Cliff B. Jones. Scientific Decisions which Characterize VDM. In
J.M. Wing and J.C.P. Woodcock and J. Davies, editors, FM’99 -
Formal Methods, pages 28–47, Springer-Verlag, 1999. Lecture
Notes in Computer Science 1708.

[Kurita&08] Taro Kurita and Miki Chiba and Yasumasa Nakatsugawa. Appli-
cation of a Formal Specification Language in the Development of
the “Mobile FeliCa” IC Chip Firmware for Embedding in Mobile
Phone. In J. Cuellar and T. Maibaum and K. Sere, editors, FM
2008: Formal Methods, pages 425–429, Springer-Verlag, May
2008.

[Larsen01] Peter Gorm Larsen. Ten Years of Historical Development: “Boot-
strapping” VDMTools. Journal of Universal Computer Science,
7(8):692–709, 2001.

[Larsen&08] Peter Gorm Larsen and John S. Fitzgerald and Steve Riddle. Prac-
tice-oriented courses in formal methods using VDM++. Formal
Aspects of Computing, DOI 10.1007/s00165-008-0068-5, Febru-
ary 2008.

[Larsen&96] Peter Gorm Larsen and John Fitzgerald and Tom Brookes. Ap-
plying Formal Specification in Industry. IEEE Software, 13(3):48–
56, May 1996.

[Mukherjee&93] Paul Mukherjee and Victoria Stavridou. The Formal Specifica-
tion of Safety Requirements for Storing Explosives. Formal As-
pects of Computing, 5(4):299–336, 1993.



280 Bibliography

[Naur&69] P. Naur and B. Randell (Editors). Software Engineering: Report
on a Conference sponsored by the NATO Science Committee.
231 pages. Garmisch, Germany, 7th to 11th October 1968, Brus-
sels, Scientific Affairs Division, NATO, January 1969.

[OMG&96] The Common Object Request Broker: Architecture and Specifi-
cation. OMG, July 1996.

[omniORB3] Sai-Lai Lo and David Riddoch and Duncan Grisby. The om-
niORB version 3.0 User’s Guide. AT&T Laboratories Cambridge,
May 2000.

[Puccetti&99] Armand Puccetti and Jean Yves Tixadou. Application of VDM-
SL to the Development of the SPOT4 Programming Messages
Generator. In John Fitzgerald and Peter Gorm Larsen, editors,
VDM in Practice: Proceedings of the First VDM Workshop 1999,
pages 127–137, September 1999.

Available at www.vdmportal.org

[Rushby86] John Rushby. Kernels for Safety? In Tom Anderson, editor, Safe
and Secure Computer Systems, pages 210–220, Blackwell Scien-
tific Publications, October 1996.

[Smith&99] Paul R. Smith and Peter Gorm Larsen. Applications of VDM
in Banknote Processing. In John S. Fitzgerald and Peter Gorm
Larsen, editors, VDM in Practice: Proceedings of the First VDM
Workshop 1999, September 1999.

Available at www.vdmportal.org

[UML20] OMG. Unified Modeling Language: Superstructure. August 2005.

Available at http://www.uml.org

[UserMan] The VDM Tool Group. VDM-SL Toolbox User Manual. Techni-
cal Report, CSK Systems, January 2008.

Available at http://www.vdmtools.jp/en/

[Vadera&01] Sunil Vadera and F. Meziane and M. Huang. Experience with
mural in Formalising Dust-Expert. Information and Software
Technology, 43:231–240, 2001.



Bibliography 281

[Verhoef&06] Marcel Verhoef and Peter Gorm Larsen and Jozef Hooman. Mod-
eling and Validating Distributed Embedded Real-Time Systems
with VDM++. In Jayadev Misra and Tobias Nipkow and Emil
Sekerinski, editors, FM 2006: Formal Methods, pages 147–162,
Springer-Verlag, 2006.

[Verhoef&07a] Marcel Verhoef and Peter Gorm Larsen. Interpreting Distributed
System Architectures Using VDM++ – A Case Study. In Brian
Sauser and Gerrit Muller, editors, 5th Annual Conference on Sys-
tems Engineering Research, March 2007.

Available at http://www.stevens.edu/engineering/cser/

[Verhoef&07b] Marcel Verhoef and Peter Visser and Jozef Hooman and Jan Broenink.
Co-simulation of Real-time Embedded Control Systems. In Jim
Davies and Jeremy Gibbons, editors, Integrated Formal Meth-
ods: Proceedings of the 6th International Conference, pages 639–
658, Springer-Verlag, July 2007.





Subject Index

abs, 238, 258
abstraction, 2, 3, 8, 11, 17–19, 26, 220
and, 61, 72, 74, 89, 95, 149, 237, 259
API, 188

biimplication, 63, 73, 237, 259
bool, 57, 59, 106, 149, 236
Boolean

data type, 57, 59, 106, 149, 236
break point, 46, 125

card, 25, 109, 143, 258
CASE tools, 218
cases expression, 94, 159, 160, 247, 258
char, 18, 21, 84, 236, 240
conc, 134, 242, 258
conjunction, 61, 72, 74, 89, 95, 149,

237, 259
continue, 47
cost-effectiveness, 217, 223
critical systems, 1, 71, 78, 97, 185, 224,

226

data type, see type
debug, 46, 125
dialog pane, 43
dinter, 118, 240, 241, 258
disjunction, 60, 72, 74, 237, 259
distributed operators, 115, 133, 155
div, 238, 258, 271
$$, 95, 115
dom, 20, 145, 243, 258
domain checking, 174
dunion, 117, 240, 241, 258
dynamic link, 182, 183, 188

elems, 133, 168, 242, 258
equality, 57, 97, 237, 238, 240, 242–

246, 259
ESA PSS-05, 224
execution, 43
exists, 66, 67, 111, 146, 248, 259
exists1, 70, 248, 259
ext, 192, 193, 198, 201, 250, 256
externals, 192, 193, 198, 201, 250, 256

false, 57, 60–64, 71–73
flat model, 203
forall, 67, 67, 87, 116, 147, 168,

175, 178, 179, 247, 259
frame problem, 198
function

definition, 7, 11, 59, 87, 255
explicit, 11, 25, 59, 87, 178, 249,

256
implicit, 8, 11, 25, 27, 110, 110,

179, 250, 256
parameter, 88, 250, 256
recursive, 124, 157, 161, 164, 196,

199
signature, 88, 249, 255

function trace, 125

hd, 125, 242, 258

IEC 61508, 224
if-expression, 110, 112, 125, 128, 129,

154, 247, 257
implication, 62, 72, 95, 175, 179, 237,

259
in set, 114, 240, 259
inds, 124, 130, 242, 258

283



284 Subject Index

inequality, 97, 237, 238, 240, 242–246,
259

information hiding, 216
init, 43
int, 82, 98, 101, 236
integers, 82, 101, 236
integrity checking, 49
integrity property, 49
inter, 107, 240, 259
interpreter, 43, 125
interpreter window, 43
invariant, 5, 10, 23, 28, 31, 85, 86, 87,

95, 106, 116, 127, 143–145, 177,
178, 221, 236, 255

is-expression, 84, 245, 260

len, 57, 127, 242, 258
let be expression, 161, 246, 257
let expression, 111, 113, 114, 151, 246,

257
logic, 55
looseness, 26, 28, 110, 161
LPF, 71

maintenance, 219, 222
map to, 6, 19, 139, 142, 237, 255
mapping

application, 146, 149, 243, 244
comprehension, 140, 243, 260
distributed merge, 155, 243, 244, 258
domain, 137, 145, 243, 258
domain restriction, 153, 243, 244, 259
domain subtraction, 153, 243, 244, 259
empty, 139, 243
enumeration, 139, 243, 260
maplet, 137, 139, 243, 260
override, 89–91, 93, 150, 243, 244,

259
range, 137, 145, 243, 258
range restriction, 153, 153, 243, 244,

259
range subtraction, 153, 243, 244, 259
type, 6, 19, 139, 142, 237, 255
union, 148, 149, 175, 243, 259

match value, 248, 262

merge, 155, 243, 244, 258
MIL-STD-882, 224
mod, 238, 259
module

export, 207, 210, 213, 216
import, 208, 209, 210, 213, 214, 216
interface, 205, 206
test, 219

module, 252
munion, 147, 149, 175, 243, 259

nat, 23, 82, 98, 105, 143, 236
nat1, 82, 98, 236
natural numbers, 23, 82, 105, 143, 236
negation, 59, 237, 258
nil, 77, 96, 110
not, 59, 237, 258
not in set, 8, 149, 153, 175, 210,

240, 259, 263, 266, 269

object-orientation, 214, 216
operation

definition, 189, 190, 192, 193, 200,
250, 256

parameter, 192, 193, 197, 250
operator

partial, 78, 175
total, 78

optional type, 77, 96, 96, 110, 237, 246,
255

options
dynamic type, 51
invariant, 51
pre-condition, 51

or, 60, 72, 74, 237, 259

pattern, 111, 161, 248, 248, 262
don’t care, 116, 248, 262
for records, 26, 86, 88, 92, 106, 116,

151, 249, 262
for sequences, 249, 262
for sets, 248, 262
for tuples, 249, 262
identifier, 111, 248, 262



Subject Index 285

post-condition, 8, 28, 31, 49, 110, 179,
180, 193, 197, 198, 221, 250, 251

pre-condition, 8, 11, 28, 29, 31, 49, 88,
89, 94, 110, 113, 149, 151, 175,
176, 178, 179, 193, 221, 250, 251

predicate, 57, 101
print, 45, 46
proof, 184

obligation, 29, 174, 187
rule, 186

proposition, 57

quantification
existential, 66, 67, 111, 146, 248, 259

unique, 248
expression, 24, 66, 67, 247, 259
unique existential, 70, 259
universal, 67, 67, 87, 116, 147, 175,

178, 179, 247, 259
quote, 17, 81, 98, 128, 237
quote type, 81, 254

rd, 193, 193, 194, 195, 197–199, 250
real, 82, 98, 143, 236
record

constructor, 84, 84, 88, 132, 244
field, 84, 84, 85, 86, 91, 92, 98, 255
pattern, 26, 86, 88, 92, 106, 116, 151,

249, 262
selector, 84, 86, 151, 245, 260
type, 18, 20, 78, 84, 105, 141, 143,

158, 162, 237
renaming, 214, 216
requirements

analysis, xi, 3, 15
specification, 9, 13

response pane, 43, 43
rigour, 2, 225
rng, 20, 145, 243, 258
run-time error, 51, 73, 103, 266

satisfiability, 179, 180, 188
SDE tools, 218
seq of, 18, 84, 122, 127, 237, 255
seq1 of, 122, 127, 168

sequence
comprehension, 123, 132, 241, 260
concatenation, 130, 242, 259

distributed, 134, 242, 258
elements, 133, 242, 258
empty, 123, 241
enumeration, 123, 241, 260
head, 125, 242, 258
index, 124, 242
indices, 124, 130, 242, 258
length, 57, 127, 242, 258
modification, 134, 242
subsequence, 123, 241, 260
tail, 125, 242, 258
type, 18, 84, 122, 127, 237, 255

set
binding, 67, 102, 123, 140, 240, 241,

249, 262
cardinality, 109, 143, 240, 258
comprehension, 26, 102, 108, 114, 117,

238, 259
difference, 113, 240, 259
empty, 100, 238
enumeration, 101, 238, 259
intersection, 107, 240, 259

distributed, 118, 240, 241, 258
membership, 114, 240, 259
range, 66, 101, 130, 240, 260
subset, 114, 146, 240, 259
type, 18, 100, 237, 255
union, 112, 128, 240, 259

distributed, 117, 240, 241, 258
set of, 18, 100, 143, 237, 255
signature, 22, 88, 107, 128
silence, 28
software

design, 218
state

definition, 9, 191, 199, 200, 251, 255
initialisation, 191, 199, 201, 251, 255
invariant, 191, 199, 251, 255

struct, 213
Structured Analysis, 225
subsequence, 123, 241, 260
subset, 114, 146, 240, 259



286 Subject Index

syntax
checking, 38

test
coverage, 184, 188

time to market, 220, 222
tl, 125, 242, 258
token, 18, 19, 21, 82, 83, 98, 116,

142, 237
tools menu, 51
trace, 47
true, 28, 57, 60–64, 71–73, 106, 111,

149
truth table, 59, 74
tuple

constructor, 244, 260
type, 244, 255

tuple type, 237
type

basic, 57, 81, 82, 82, 254
binding, 47, 67, 102, 103, 140, 240,

249, 262
definition, 5, 17, 81, 236, 254
invariant, 5, 10, 23, 28, 31, 85, 86,

87, 95, 106, 116, 127, 143–145,
177, 178, 221, 236, 255

judgement, 179, 261
membership, 97, 178

type checking, 38

UML, 214, 215, 225
undefinedness, 71, 73, 125, 149
union, 112, 128, 240, 259
union type, 17, 78, 81, 81, 158, 160,

162, 237, 245, 255
unit test, 219

validation, 4, 180, 183, 224
by proof, 172, 184, 185, 187
by testing, 172, 183, 187
conjecture, 184, 188

value definition, 43, 83, 91, 255
VDM, xi, 4
VDM++, 214, 216
VDM-SL, xi, 3, 4, 10

vdmlite, 36
VDMTools, xii, 4

Lite, 35
verification, xi, 184

what, not how, 4, 7, 27
wr, 193, 195, 197–199, 250



Definitions Index

AcyclicGraph, 165, 166
AircraftPosition, 6
Alarm, 18, 21
AllDesc, 166
AmberChange, 91
AnyHighClass, 133

Bottom, 120

Category, 128, 196
Censor, 134, 135
Chains, 168, 169
ChgLight, 91
ChgTime, 93
Classification, 127, 128, 196
Classify, 129
Conflict, 84, 85
Container, 143
ContainerId, 142
ContainerInfo, 142
ContOverLimit, 61

Delete, 152–154, 175
Descendants, 166

Expert, 18, 21, 23
ExpertId, 19, 21
ExpertIsOnDuty, 26
ExpertToPage, 27
Expr, 162

FallibleLight, 96
FilterBig, 124
Find, 154, 180
FlattenMessages, 133, 134

Gateway, 128, 129, 199

Gateway2, 132
GenTree, 160
Graph, 165

IfExpr, 162
InBounds, 106
Indices, 130
Introduce, 149, 175
Inventory, 117
InventoryItem, 117
IsLinear, 168

Kernel, 85, 86, 91

LabGraph, 167
Latitude, 5
Light, 81, 96
ListBigItems, 118

Material, 143
MaterialSafe, 147
max, 159
MaxTree, 159
Merge, 155
Message, 127, 196
MinimumGreen, 91
Move, 151, 177

NewAircraft, 8
Node, 158, 160, 165
NumberOfExperts, 25
NumObjects, 109, 194

Object, 105
Occurs, 129, 130
Over, 155

287



288 Definitions Index

Overlap, 108
OverLimit, 60, 66

Path, 83, 168
Paths, 169
PathsFromNode, 169
Period, 19, 21
Permission, 149, 176, 184
Phase, 143
PhaseId, 142
PhaseInfo, 142
PhasesDistinguished, 146
Place, 113, 195
Plant, 20, 21, 28
Point, 105
Points, 108
Ports, 128
ProcessMessage, 129, 130, 132, 197–

199

Qualification, 17, 21
QualificationOK, 28

RadarInfo, 6
RaiseAlarm, 64
RedClearance, 91
Remove, 114, 150, 151, 179, 196
Rising, 59
RoomAt, 111, 194

Safe, 63
SafeSpace, 119
Schedule, 19, 21, 24
SelectForLanding, 9
SeqSum, 125
Site, 116
SiteInventory, 118
Store, 105, 106, 116, 191
StoreInventory, 117
StoreName, 116
String, 83, 127, 196
SuggestPos, 110, 112, 194

TempRead, 57
TestTrees, 160

Time, 82, 87
ToAmber, 90, 93
ToColour, 94
ToGreen, 88, 89, 92
ToRed, 90, 92
Tracker, 141, 144, 145
Tree, 158
TreeToSeq, 160
TrustedGateway, 196

wf IfExpr, 163


