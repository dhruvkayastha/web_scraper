***- IEEE Software (September_October). Volume 19, Number 5 (2002)***




































T
wenty years ago, I left the security
(and frustration) of working for a
large corporation to begin a consult-
ing career in software measurement.
Since then, I’ve helped many firms
implement software measurement

programs. For some clients, the motivation
for measurement was process improve-

ment; for others, it was resolv-
ing an immediate crisis and get-
ting a product out the door. In
this column, I’ll share the eight
“secrets” of software measure-
ment that I’ve learned. I call
them secrets because they were
not obvious to me at the begin-
ning. Only in retrospect, as I’ve
tried to discern patterns of suc-
cess and failure, have these se-
crets become clear. 

It’s not about the metrics
Four-time Tour de France winner Lance

Armstrong titled his autobiography It’s
Not About the Bike: My Journey Back to
Life (Berkeley Publishing Group, New
York, 2001). Although he has spent count-
less hours on the bike, for him, it was only
a vehicle for his fight back from life-threat-
ening cancer.

By the same token, measurement is not an
end in itself; it’s a vehicle for highlighting ac-
tivities and products that you, your project
team, and your organization value so you
can reach your goals. But it’s only a tool. To
get anywhere, you must navigate the road—
you’ve got to make decisions and act.

To create an effective measurement pro-
gram, you first must understand exactly where
you want to go or what you want to accom-
plish; that is the “why” of measurement. 

Success comes from channeling an
organization’s pain into action 

No matter how much I dislike this secret,
I have found it to be so. It comes back to the
fact that it’s not about the metrics; it’s about
the strength of the motivation to know or
improve something and to follow through
with action. No matter how noble the inten-
tion, “Let’s do metrics” just doesn’t provide
sufficient motivation. 

The single biggest determinant of mea-
surement success lies in the answers to the
following questions: How badly do you
want to know the information, and how
will you use it? 

Establishing a measurement
program is easy; keeping it going is
hard

I am continually impressed by how easy it
is to think about potentially useful measures
and how hard it is to implement an effective
measurement program. Within a project or
organization, it’s often easy to get people en-
thused about measures—but all too often,
that enthusiasm does not translate into ac-
tion. Even when it does, it is unlikely to be
sustained. Getting the numbers is easy; do-
ing something with them is not.

What you need is no less than to change
your organization’s culture. Cultural change
is hard. 

manager

Eight Secrets of Software
Measurement
Betsy Clark

E d i t o r :  D o n a l d  J .  R e i f e r  � R e i f e r  C o n s u l t a n t s  � d . r e i f e r @ i e e e . o r g

1 2 I E E E  S O F T W A R E S e p t e m b e r / O c t o b e r  2 0 0 2 0 7 4 0 - 7 4 5 9 / 0 2 / $ 1 7 . 0 0  ©  2 0 0 2  I E E E



S e p t e m b e r / O c t o b e r  2 0 0 2 I E E E  S O F T W A R E 1 3

MANAGER

People skills matter
more than quantitative
skills

Every step of the measure-
ment process requires input
from the people within the pro-
ject or organization who will
provide and use the data. Emo-
tion plays a strong role, espe-
cially at the beginning, leading
to a variety of reactions from
the individuals involved. Fear
that the measures will be mis-
interpreted or misused can also
lead to resistance. (We’ll ad-
dress this in more detail below.)
Positive and negative reactions
accompany any organizational
change; anticipating and man-
aging these are necessary. 

In my experience, at least
one person always steps up
as an early adopter. This per-
son intuitively understands
the need for measurement
and its benefits. I make sure
to find that person and work
with him or her. By demonstrating
that providing the data isn’t so hard
and that it really is useful, such peo-
ple can bring credibility to the mea-
surement activities.

By the same token, I almost al-
ways encounter someone who feels
threatened by the measurement pro-
gram. This person—usually a long-
term middle manager—often derives
a sense of importance as the reposi-
tory of organizational knowledge.
Measurement sheds light on the 
organization’s basic workings; so
much of the knowledge previously
held in that person’s head now be-
comes an organizational asset acces-
sible by all. That’s good news for the
organization but can be threatening
to the particular individual who
might lose status as the company’s
resident sage.

Senior-level sponsorship and
leadership are critical 

Although this one might be so ob-
vious that it really shouldn’t qualify
as a secret, it’s absolutely key and of-
ten neglected. Remember that it’s
not about the metrics; it is about ar-

ticulating a vision and following
through with consistent and persis-
tent action. Without these, measure-
ment won’t help. The person at the
top must participate in the measure-
ment program, by

� Articulating organizational goals
� Behaving in ways that are consis-

tent with these goals
� Creating a culture that exposes,

rather than hides, problems
� Looking at the data and asking

questions
� Making decisions and following

through with action
� Expecting lower-level managers to

do the same

Effective measurement will ex-
pose an organization’s warts. To im-
prove a situation, you must first un-
derstand where you are. In some
ways, things might seem to get
worse before they get better. They
aren’t really worse, but you are now,
perhaps for the first time, bringing
problems to light. Dealing with this
challenge effectively takes courage
and fortitude. 

Measuring individuals
can be okay

This is probably the most
controversial secret. Every
source of guidance I’ve read
on measurement advises
against measuring individu-
als. In conference presenta-
tions and casual conversa-
tion, people often repeat this
observation. In my view,
there are counterproductive
ways of measuring individu-
als, but there are also times
when it is appropriate.

Let’s look first at some
counterproductive ways.
Punishing people for re-
porting honest results can
quickly destroy data in-
tegrity. Organizations with
effective measurement pro-
grams do punish people
who hide risks and prob-
lems; they don’t punish peo-
ple for exposing them, espe-
cially when they also offer

solutions. Rewarding one program-
mer for producing more lines of code
per labor hour or punishing someone
else for producing less is also inap-
propriate. That course ignores the
fact that code quality and inherent
task difficulty vary.

In looking at intelligent uses, I’ve
worked with clients who have imple-
mented detailed progress measures
that begin with the individual, mea-
suring actual progress against a plan.
The measures can be rolled up, lead-
ing to an overall progress assess-
ment, and they can be drilled down,
to the level of teams or individuals,
supporting a detailed assessment of
problem areas. Such an approach
lets managers hold individuals ac-
countable for completing assign-
ments as planned. There’s nothing
negative about this.

Don’t go overboard trying to
be perfect

Anyone who has gotten down and
dirty with data quickly realizes the
importance of understanding what
the data represent. Even seemingly
straightforward data can be ambigu-



MANAGER

ous. One of my early consulting en-
gagements in capturing milestone
dates brought this point home to me.
When I asked for the date of a design
review, I was asked, in turn, “Are
you asking for the date the review
was held or the date the customer
signed off on it nine months later?” It
is very important to understand what
the data represent.

By the same token, keep in mind
that “the good is the enemy of the
perfect.” You must continually bal-
ance clarity of definition with the
need to get started. In my view, it’s
best to get started and work to
improve the measurement process
over time. 

Understanding the reasons 
for variability in the data
provides a powerful decision
tool

One of the striking characteristics
of real data is its huge variation.
Look at any graph showing the rela-
tionship between size and effort or

between size and defects and you’ll
see a very large spread—so large that
these data are typically represented
in logarithmic scales. If you can un-
derstand what’s behind the variation,
you’ll understand a lot.

I once had a client who was em-
barking on a process improvement
initiative. They wanted to baseline
where they were at the beginning to
establish a comparison point for as-
sessing the impact of their improve-
ment activities over time. In typical
fashion, the relationship between size
and effort varied across projects by
an order of magnitude. They mea-
sured a number of characteristics
about each project, including the
project’s percentage of personnel
turnover. In this organization, turn-
over had a major impact on produc-
tivity. When turnover increased from
12 percent to 24 percent per year, the
associated effort increased by 36 per-
cent. In dollar terms, if a project with
low turnover costs US$250,000, then
one with high turnover would cost

US$340,000. Within this organiza-
tion, it makes monetary sense to min-
imize turnover.

I mplementing an effective measure-ment program is full of challenges.Overcoming these challenges is
worthwhile because measures pro-
vide insight supported by hard data.
Measurement provides a vehicle for
improving your ability to plan and
track progress and for addressing
risks and problems earlier. You’ll
know where you are and where you’re
going. You still have to set the direc-
tion and do the steering, but measure-
ment wil be an important tool in nav-
igating the road to success. 

Betsy Clark is President of Software Metrics, a Virginia-
based measurement consulting company she co-founded in
1983. She received her BA from Stanford University and PhD
from the University of California, Berkeley, both in cognitive
psychology. Contact her at Betsy@software-metrics.com.

The exploding popularity of mobile Internet access, third-generation wireless
communication, and wearable and handheld devices have made pervasive
computing a reality. New mobile computing architectures, algorithms,
environments, support services, hardware, and applications are coming online
faster than ever. To help you keep pace, the IEEE Computer Society and IEEE
Communications Society are proud to announce IEEE Pervasive Computing.

This new quarterly magazine aims to advance mobile and ubiquitous
computing by bringing together its various disciplines, including peer-reviewed
articles on

• Hardware technologies
• Software infrastructure
• Real-world sensing and interaction
• Human–computer interaction
• Security, scalability, and privacy

SUBSCRIBE NOW!

http://computer.org/pervasive

NEW FOR 2002

M. Satyanarayanan
Carnegie Mellon Univ. and Intel Research Pittsburgh

Associate EICs

the IEEE Computer & Communications Societies present  

IEEE PERVASIVE COMPUTING

Editor in Chief

Roy Want, Intel Research; Tim Kindberg, HP Labs; 
Deborah Estrin, UCLA; Gregory Abowd, GeorgiaTech.;

Nigel Davies, Lancaster University and Arizona University



0 7 4 0 - 7 4 5 9 / 0 2 / $ 1 7 . 0 0  ©  2 0 0 2  I E E E S e p t e m b e r / O c t o b e r  2 0 0 2 I E E E  S O F T W A R E 1 5

A
strong link between testing and re-
quirements engineering can benefit
both sides, but often this link is miss-
ing. Let’s examine the seven most
common myths or misconceptions be-
hind this missing link.

Myth 1: Requirements at
the beginning, testing 
at the end

“We don’t need to think about
testing yet. Let’s just concentrate
on requirements.” This attitude
guarantees that you will have a
rough time at the end of your
project. Of course, getting good
requirements is important, but
getting testers involved during

requirements analysis is one of the best ways
to ensure good requirements.

As Figure 1 shows, you should perform
test design activities as soon as there is
something to design tests against—usually
during the requirements analysis for system
and user acceptance tests.

A common problem, especially for testers,
is the impact of late changes on requirements.
Suppose you’re in the last weeks of system
testing, and user acceptance tests are sched-
uled to start running in two weeks. Suddenly,
your users say, “By the way, we’d like the sys-
tem to do this differently,” which is extremely
frustrating and happens more often than it
should. But, what are the users really doing?

They are designing their acceptance tests. The
act of test design highlights what they really
want the system to do. If they had designed
their tests early (left side of Figure 1), they
could have discovered these problems before
they were built into the system.

Getting users involved in both require-
ments and testing is crucial. Have you ever
bought a used car? Would you go to the
salesperson and say, “You know more about
cars than I do, so take the test drive for me”?
If you do, you deserve what you get. Simi-
larly, users often say to techies, “You know
more about computers than we do, so do the
acceptance testing for us.” Caveat emptor!

Myth 2: Testing isn’t possible until
the system exists

“We can’t do any testing because nothing
has been built yet. Testers just play with the
system and see what happens. Anyway, you
can’t test a piece of paper.” Three things are
wrong with this sentiment. 

First, testing is more than just seeing
what happens. It’s far more rigorous and
systematic than that. Second, it’s more than
just executing tests. As Figure 2 shows, exe-
cuting tests and checking results is part of
the fundamental test process, but other im-
portant activities exist as well. Third, you
can and should test written requirements
documents against business or project objec-
tives for completeness and correctness. If
you don’t test requirements on paper, you

requirements

Requirements and Testing:
Seven Missing-Link Myths
Dorothy Graham

E d i t o r :  S u z a n n e  R o b e r t s o n  � T h e  A t l a n t i c  S y s t e m s  G u i l d  � s u z a n n e @ s y s t e m s g u i l d . c o m

Testing expert Dorothy Graham asserts that we can save a great deal of time and money if testers
are involved in testing requirements. If the requirements have some consistent quality criteria,
testers can raise questions and find problems before we turn them into code. —Suzanne Robertson



will build errors into the system that you
could have easily removed much earlier.

Myth 3: Requirements are used in
testing, but not vice versa

“You don’t test requirements—you test
from them.” A tester’s mindset differs from
a developer’s. It’s fairly easy to write a re-
quirement that’s a bit vague and ambiguous
but appears to be OK. However, when good
testers look at a requirements specification,
they devise specific test cases to flush out
vague, ambiguous, or unclear requirements. 

When you try to explain an abstract con-
cept to someone, you say “for example” and
illustrate the idea with concrete and specific
cases to clarify the concept. Tests are the “for
examples” for requirements. Think of “what
if” use cases or business scenarios. If you con-
sider how a particular user will use the sys-
tem, the system functionality that seemed ab-
stract when first described becomes specific
for that particular user. Both testing and re-

quirements analysis benefit from having this
feedback loop in place. Good requirements
engineering produces better tests; good test
analysis produces better requirements.

Myth 4: If writing tests is difficult,
it’s solely a test problem

“The testers seem to have problems writing
tests from our requirements—maybe we should
get some better testers.” Not all requirements
are created equal from a tester’s perspective.
Specifying tests for some of them is easy;
for others, identifying exactly what the system
should do (and thus identifying tests to verify
that it can do these things) is a nightmare.

Specifying testable nonfunctional require-
ments such as usability or performance is
difficult.1 Phrases such as easy to use, user
friendly, very reliable, or acceptable perfor-
mance are not specifications: they are vague,
ethereal intentions. I subscribe to Tom Gilb’s
law: “Anything can be made measurable in
a way that is superior to not measuring it at
all.”2 Note that it is not made measurable in
a perfect way but a useful way. Suzanne and
James Robertson’s “fit criteria” show specif-
ically how to make requirements measurable
and therefore testable.3

Myth 5: Minor changes in
requirements won’t affect the
project (much)

“Just add a couple more spaces to this in-
put field. There’s plenty of room on the
screen. It’s a minor change; you won’t need
to test it because it’s so small.” A change
that appears to be minor from a require-
ments viewpoint could have a far-reaching
impact, especially in testing. Suppose that
adding two more characters to a field means
that the database where this field is defined
must be rearranged. What if this field corre-
sponds to similar information held else-
where in the system? What if the routines
that check this field also check other fields
that you have not increased in length? Do
you now need two checking routines?

You must test all such changes to confirm
that the system is now doing the right thing
in every situation affected by this change. In
addition, some unexpected side effects
could arise, so you should also do regres-
sion testing to ensure that the system has
not regressed in any other areas. How much
testing you do depends on the risks of a
change having both known and unknown
impacts on the system. Testing can also help

1 6 I E E E  S O F T W A R E S e p t e m b e r / O c t o b e r  2 0 0 2

DEPT TITLEREQUIREMENTS

Test des

Test des

Test des

Test des

Test des

Project
specification

System
specification

Design
specification

Code
Component

testing

Component
integration testing

System
testing

System integration
testing

Acceptance
testing

Run
tests

Design
tests

Business
requirements

Figure 2. What is
“testing”?

Process im
provem

ent

Check exit criteria, test report

Identify conditions

Design test cases

Build tests

Execute (run) tests

Check results

Test
process

Policy and strategies

Test planning
(at each level)

Figure 1. A V-model
for early test design.



mitigate the risk of change by giving confi-
dence that such impacts are low.

Myth 6: Testers don’t really need
requirements

“I know we don’t have good require-
ments for this system, but test it as best you
can—just see what the system does.” A
tester’s job is to adjudicate between what a
system does and what it should do. The sys-
tem should help the business accomplish a
goal, so what the system actually does
should be compared with those goals.

There is an oracle assumption in testing
(which has nothing to do with databases or the
companies that supply them—rather, it is
based on the oracle of Delphi, who could pre-
dict the future with unerring accuracy). The or-
acle assumption states that the tester routinely
knows what the correct answer is supposed to
be, which is fundamental to testing. A test
comprises the test inputs, preconditions, and
expected outcomes. How do you know what
the expected outcome should be? A require-
ment specification is this test basis, or oracle.
So, yes, testers do need requirements; other-
wise, you could argue that it’s not really a test.

Myth 7: Testers can’t test without
requirements

“Because requirements form the basis for
tests, obviously we can’t do any testing un-
til we have decent requirements.” This is
also a common tester’s misconception.
Sometimes changes are made to systems
where requirements are inadequate or
nonexistent. This makes the testing more
difficult, but you shouldn’t just throw your
hands up and say that you can’t do it.

Without requirements, testers still need
some kind of test oracle—maybe users who
are familiar with the way the system works,
the old system, user manuals, or the tester’s
own opinions. What happens if the test or-
acle is the tester? Instead of merely compar-
ing a system against a document, the testers
are judging the system against their per-
sonal view of what it should do. (Actually,
testers should always do some of this any-
way, but that’s another story.) 

Some would say that without a specifica-
tion, you are not testing but merely explor-
ing the system. This is formalized in the ap-
proach known as exploratory testing,
designed for situations with inadequate re-
quirements and severe time pressure.4

If you end up with a good set of testware,

test plans, test specifications, and so on, the
testware actually becomes the only require-
ment documentation in the project. So with
good enough tests, who needs requirements
at all? Do the testers become the require-
ments engineers? Is this a good idea?

If requirements are poor or nonexistent,
testers must do the best testing they can un-
der less than ideal circumstances. Testing is
far more rigorous if it is based on good re-
quirements, and tester involvement early on
can help produce them. 

I hope I’ve convinced you that testers havemuch to offer in producing better require-ments. Here’s how to achieve it in practice:
� Invite testers to participate in require-

ment reviews and inspections
� Begin planning testing in parallel with re-

quirements analysis
� Ask for sample test conditions and test

cases to use as examples in the require-
ments specification

� Include in the requirements document
any specific cases that you had in mind
when analyzing requirements

� Use business scenarios and use cases to
give specific examples of how the system
should work

� Set measurable criteria for both func-
tional and nonfunctional requirements

Testing is challenging in two ways: it’s a re-
warding intellectual activity, but it also chal-
lenges whatever the tests are based on. Make the
link between requirements and testing. If you ac-
cept and encourage the challenges that testers
make to your requirements, you will avoid these
misconceptions and will end up with signifi-
cantly better requirements and tests.

Acknowledgments
Thanks for comments on drafts of this article from Clive
Bates, Mark Fewster, Robin Goldsmith, and Dot Tudor.

References
1. B. Lawrence, K. Weigers, and C. Ebert, “The Top Ten

Risks of Requirements Engineering,” IEEE Software,
vol. 18, no. 6, Nov./Dec. 2001, pp. 62–63.

2. T. Gilb, Principles of Software Engineering Manage-
ment, Addison Wesley, Boston, 1988.

3. S. Robertson and J. Robertson, Mastering the Require-
ments Process, Addison Wesley, Boston, 1999.

4. C. Kaner, J. Bach, and B. Pettichord, Lessons Learned in
Software Testing, John Wiley & Sons, New York, 2002.

Dorothy Graham founded Grove Consultants in the UK, a company
that provides consultancy, training, and inspiration in all aspects of software
testing. Contact her at dorothy@grove.co.uk.

S e p t e m b e r / O c t o b e r  2 0 0 2 I E E E  S O F T W A R E 17

DEPT TITLE

Good
requirements
engineering

produces
better tests;

good test
analysis
produces

better
requirements.

REQUIREMENTS



1 8 I E E E  S O F T W A R E S e p t e m b e r / O c t o b e r  2 0 0 2 0 7 4 0 - 7 4 5 9 / 0 2 / $ 1 7 . 0 0  ©  2 0 0 2  I E E E

I
n its first release of the .NET Frame-
work, Microsoft has provided a de-
fined method for adding declarative in-
formation (metadata) to runtime enti-
ties in the platform. These entities in-
clude classes, methods, properties, and

instance or class variables. Using .NET, you
can also add declarative information to the
assembly, which is a unit of deployment that
is conceptually similar to a .dll or .exe file.
An assembly includes attributes that de-
scribe its identity (name, version, and cul-
ture), informational attributes that provide
additional product or company informa-
tion, manifest attributes that describe con-
figuration information, and strong name at-
tributes that describe whether the assembly
is signed using public key encryption. The
program can retrieve this metadata at run-
time to control how the program interacts
with services such as serialization and secu-
rity. Here, we compare design decisions
made using custom attributes in .NET with
the Java platform.

Marker interfaces
In the Java platform there is a common

design trick called marker interfaces. A
marker interface has no methods or fields
and serves only to identify to the Java Vir-
tual Machine (JVM) a particular class at-
tribute. Here is one example:

public interface Serializable {}

If the class that you are writing must be se-

rializable, then it must implement the inter-
face as follows:

public class MyClass implements

Serializable

Serialization might have certain behav-
iors associated with it that the class devel-
oper wants to control. However, Java doesn’t
explicitly associate such behavior with the
interface that represents the serialization
contract. At runtime, when the program
tells the JVM to serialize this class, it looks
to see if the class has implemented the inter-
face. It also looks to see if the class has de-
fined any special methods associated with
the serializable interface but not directly de-
clared in it, such as readResolve, read-
Object, or writeObject. 

The JVM relies on a naming convention
and method signatures to locate the methods
via reflection; if it finds them, it invokes
them. The interface itself does not specify
any methods, because implementors might
then unnecessarily implement methods in the
simplest case. Because the interface doesn’t
explicitly specify the methods used to control
the process and thus might incorrectly spec-
ify the method signature, this mechanism is
prone to failure. Unfortunately, no compile
time check will identify this as an error. 

.NET solves this problem by being ex-
plicit. In the simplest case, where the pro-
grammer wants to rely on the provided ca-
pability to serialize an object, there is a
class-level attribute called Serializable

design

How .NET’s Custom 
Attributes Affect Design
James Newkirk and Alexei A. Vorontsov

E d i t o r :  M a r t i n  F o w l e r  � T h o u g h t Wo r k s  � f o w l e r @ a c m . o r g



S e p t e m b e r / O c t o b e r  2 0 0 2 I E E E  S O F T W A R E 1 9

DESIGN

that marks a class as having that ca-
pability. For example,

[Serializable()] 

public class MyClass {}

Marking a class serializable implies
nothing else. If the programmer
wants to completely control the seri-
alization process, then he or she must
also implement an interface called
ISerializable, specifying the meth-
ods used to control serialization (see
Figure 1).  At runtime, when the pro-
gram tells the Common Language
Runtime to serialize a class, the CLR
looks to see if the class was marked
with SerializableAttribute.

The Java and .NET approaches
are similar in intent, but .NET’s use
of attributes is more explicit. Con-
trary to an interface’s basic purpose,
the marker interface reuses an exist-
ing language construct interface to
represent what the attribute repre-
sents. According to the Java Lan-
guage Specification (2nd ed., Addi-
son-Wesley, 2000), 

An interface declaration intro-
duces a new reference type whose
members are classes, interfaces,
constants and abstract methods.
This type has no implementation,
but otherwise unrelated classes can
implement it by providing imple-
mentations for its abstract methods.

Stylistic naming patterns
At the method level, it is common in

the Java platform to use naming con-
ventions to identify a special method. By
virtue of the name, the program finds
the method at runtime using reflection.
Once found, the executing program spe-
cially interprets this method. For exam-
ple, when a programmer defines 
a test method in JUnit—a popular unit-
testing framework for Java (www.
junit.org)—the first four letters of a test
method must be test (see Figure 2a).
The program that executes the tests first
verifies that the class inherits from
TestCase. Then, using reflection, it
looks for any methods that start with
Test. In the code in Figure 2a, the pro-

gram finds and calls
testSuccess. 

The code in Figure
2b demonstrates a
common design id-
iom used in JUnit
when the program-
mer wants to verify
that the code throws
an exception. Unfor-
tunately, the pro-
grammer will dupli-
cate such code in
every test case that
expects an exception,
and the idiom is not
as intuitive as you
might expect. 

Having the testing
framework support
such a common case
directly would be
nice. However, rely-
ing on the naming convention could
lead to some variation of the code in
Figure 2c. In this case, we use a nam-
ing convention to specify not only a
test method but also additional infor-
mation about how to interpret the
test result. We expect that this
method’s execution will throw MyEx-
ception. This example might seem
somewhat ridiculous, but it demon-
strates the limitations of naming con-
ventions, because of how much infor-
mation the name itself can convey. In
fact, JUnit doesn’t implement the
functionality to check boundry condi-
tions in this way. Other approaches
used in Java (such as JavaDoc tags)
can provide additional information.
However, they are not present at run-
time and usually require preprocess-
ing the code to identify and process
the tags.

In .NET, stylistic naming patterns
are not needed because, in addition
to attributes that the Framework
specifies, a programmer can create
custom attributes that are defined
and used in the same way. These at-
tributes are not just names but are 
instances of classes that might have
additional data. Figure 3a shows a
similar test class defined with Nunit
(www.nunit.org), a unit testing tool
for the .NET platform. Nunit, a de-

rivative of JUnit, supports all lan-
guages in the .NET framework and
uses attributes at the class and
method levels. The class attribute is
called TestFixture; it tells the pro-
gram that runs the tests to look for
test methods in this class. A Test at-
tribute then identifies test methods.
This overall solution makes for a
more consistent approach. 

In addition, this solution is more
extensible because more than one at-
tribute can be associated with a
method, and attributes can have ad-
ditional data. For example, Nunit
has another attribute defined for a
method that expects an exception.
This leaves the name not only unen-
cumbered by the context in which it
is run but also more relevant to what
is being tested (see Figure 3b). 

A ttributes in .NET provide an ele-gant, consistent approach toadding declarative information to
runtime entities. Because the runtime
entities interact with the supporting
services via declarative information,
the set of services and supporting at-
tributes does not have to be closed.
By providing a standard mechanism
to extend built-in metadata with cus-

Figure 1. Implementing the IISSeerriiaalliizzaabbllee
interface, which specifies the methods for 
controlling serialization.

[Serializable()] 

public class MyClass : ISerializable  

{ 

public MyClass( 

SerializationInfo info, 

StreamingContext context) 

{  

// ...  

} 

public void GetObjectData( 

SerializationInfo info, 

StreamingContext context) 

{  

// ...  

} 

}



2 0 I E E E  S O F T W A R E S e p t e m b e r / O c t o b e r  2 0 0 2

DESIGN

tom attributes, .NET lets program-
mers develop applications that can
interact with services not yet defined
or supported by CLR. In fact, Nunit
version 2.0 was written with custom
attributes and provides much of the
flexibility we’ve demonstrated here. 

In contrast, the most common ad
hoc mechanisms in Java to add de-
clarative information include marker
interfaces, stylistic naming patterns,
and JavaDoc tags. These inconsis-
tently solve the problem of adding
declarative information to runtime
entities. They are also error prone
and too simplistic for today’s appli-
cations. The Java community recog-
nizes this limitation and has started
working on JSR-175 (see www.jcp.
org/jsr/detail/175.jsp), which speci-
fies a similar facility for Java that is
already in .NET. 

James Newkirk is a software project manager for
Thoughtworks. He has been working with the .NET Framework
since its introduction in the summer of 2000. Contact him at
jim@nunit.org.

Alexei A. Vorontsov is a software technical lead for 
Thoughtworks. He has worked on an enterprise transforming 
application for the past three years. Contact him at alexei@
nunit.org.

Figure 3. A test class (a) defined with Nunit and (b) with another 
attribute defined for a method that expects an exception.

[TestFixture] 
public class MyClass 
{ 

[Test] 
public void Success() 
{ /* ... */ } 

}
(a)

[TestFixture] 
public class MyClass

{ 
[Test] 
[ExpectedException(typeof(MyException))] 
public void Success() 
{ /* would throw my exception */ } 

}
(b)

Figure 2. (a) A test method in JUnit (the method’s first four letters
must be tteesstt); (b) a test for the boundary conditions that verify that
an exception is thrown when expected; (c) a naming convention to
specify not only a test method but also some additional information
about how to interpret the test result.

public class MyClass extends TestCase 
{ 

public void testSuccess() 
{ /* ... */ } 

}
(a)

public class MyClass extends TestCase 
{ 

public void testMyException() 
{ 

try { 
/* code that throws exception */ 
fail(“Code should have thrown MyException”); 

} 
catch(MyException e) 
{ /* expected exception — success */ } 

} 
}

(b)

public class MyClass extends TestCase 
{ 

public void testSuccess_ExpectException_MyException() 
{ /* ... */ } 

}
(c)

FUTURE TOPICS:

The Business of
Software Engineering

Software Inspections

Usability

Internationalization

FUTURE TOPICS:

The Business of
Software Engineering

Software Inspections

Usability

Internationalization

IEEE

http://computer.org/software

Visit us
on the
web

Visit us
on the
web



0 7 4 0 - 7 4 5 9 / 0 2 / $ 1 7 . 0 0  ©  2 0 0 2  I E E E S e p t e m b e r / O c t o b e r  2 0 0 2 I E E E  S O F T W A R E 2 1

memorial
S e n i o r  L e a d  E d i t o r :  D a l e  S t r o k  � s o f t w a r e @ c o m p u t e r . o r g

D
id you know that Edsger
Dijkstra just passed away?”
When I first heard the news, I
was shocked. “How could
this happen?!” I asked my-
self. Last year (but it seemed

just yesterday) when Edsger and I sat
together on a small bus leaving 
the Software Pioneers Conference in
downtown Bonn, Germany, to return
to our hilltop hotel, he looked
healthy. On that bus ride, we dis-
cussed the interesting difficulties he
had faced early on in his career. Al-
though he had run into obstacles, he
could now laugh about them since he
had discovered ways to overcome
them and change history. Today as I
recall his face and soft voice, I see the
smile of a man who revolutionized
software development.

A short biography
Edsger W. Dijkstra was born in

the Netherlands in 1930 and died 6
August 2002. After receiving his PhD
in computing science from the Uni-
versity of Amsterdam, he worked as
a programmer at the Mathematical
Centre in Amsterdam, a math profes-
sor at Eindhoven University of Tech-
nology, a research fellow at the Bur-
roughs Corp., and the Schlumberger
Centennial Professor of Computer
Science at the University of Texas at
Austin. He received the ACM Turing
Award in 1972.

I am a “programmer!”
The first time I saw Dijkstra was

when he delivered his Turing Award
acceptance speech. I was one of the
many people who stood for an hour
to listen to that speech because all the
seats were filled. It was worth it: he
told us a story I will never forget. 

When he applied for a wedding li-
cense in 1957, Dutch law required him
to declare his profession. Filling in the
form, Dijkstra stated he was a “pro-
grammer.” The Amsterdam authorities
claimed there was no such profession
and rejected his initial application. As a
result, his marriage certificate stated his
profession as “theoretical physicist.”
What struck me 30 years ago and still
resonates in my mind today is how
Dijkstra was proud to be a program-
mer instead of a theoretical physicist.
This is the kind of person software de-
velopment needs; being proud of one’s
profession is one of the most crucial
psychological steps toward better-
quality work.

Major contributions 
Dijkstra’s most famous paper is

probably “Goto Statement Considered
Harmful” (Comm. ACM, Mar. 1968,
pp. 147–148), which brought consid-
erable attention to the problem of
software developers’ careless usage of
the Goto statement. As a result, pro-
grammers today use it more carefully
or not at all.

In 1972, Dijkstra published “Notes
on Structured Programming” (Struc-
tured Programming, O.J. Dahl, E.W.
Dijkstra, and C.A. Hoare, eds., Acad-
emic Press, 1972). This triggered the
Structured Programming movement,
which helped many of us improve our
practices. 

A survey of more than 1,000 col-
lege professors identified the 38 most
influential papers in computer science
(Great Papers in Computer Science, P.
Laplante, ed., West Publishing Co., 1996;
www.csc.lsu.edu/~chen/greatpapers.
htm), and Dijkstra authored five of
them. In June 2001, at the Software
Pioneers Conference, about 1,200
software professionals saw Dijkstra
speak for the last time. Fortunately,
that speech is preserved in streaming
video   (www.sdm.de/conf2001/index_
e.htm) and book/DVD (Software Pio-
neers: Contributions to Software Engi-
neering, M. Broy and E. Denert, eds.,
Springer-Verlag, 2002) format.

E dsger Dijkstra is one of the most in-fluential figures in computer sci-ence. His teachings (www.cs.utexas.
edu/users/EWD) will resonate through
the work of software developers for
many years to come.

Peter P. Chen is the Foster Distinguished Professor at
Louisiana State University and the inventor of the Entity-
Relationship model. Contact him at pchen@lsu.edu.

From Goto-less to Structured Programming:

The Legacy of 
Edsger W. Dijkstra 
Peter P. Chen



focus
The Impending Changes 
in Software Education

Thomas B. Hilburn, Embry Riddle Aeronautical University

Watts S. Humphrey, The Software Engineering Institute, Carnegie Mellon University

special issue sheds light on some of the is-
sues both academic and industry-based edu-
cators must resolve to better address soci-
ety’s need for qualified and capable software
professionals.

Software’s critical nature 
Software is increasingly used in business-

critical and even life-critical situations. We
are moving from a benign environment with
typically friendly and honest users to an en-
vironment in which criminals, malcontents,
and even terrorists use our systems. Safety
and security are growing concerns. 

However, although the public’s health,
safety, and welfare increasingly depend on
software, approximately 75 percent of all
software projects are either late or can-
celled.1 A staggering 78 percent of IT or-
ganizations have been involved in disputes

guest editors’ introduction

2 2 I E E E  S O F T W A R E S e p t e m b e r / O c t o b e r  2 0 0 2 0 7 4 0 - 7 4 5 9 / 0 2 / $ 1 7 . 0 0  ©  2 0 0 2  I E E E

B
ecause of the growing impact of software and its historically
poor performance in meeting society’s needs, the practice of soft-
ware engineering is in need of substantial changes. One challenge
concerns preparing software professionals for their careers; the

field must drastically change its approach to software engineering education
if it hopes to consistently provide safe, secure, and reliable systems. This



ending in litigation, and 67 percent of those
cases involved late delivery or total project
failure.2 In nearly half the cases, the soft-
ware was so defective it was unusable. Just
in the US manufacturing and transportation
industries alone, inadequate software infra-
structures cost $5.85 billion annually.3

Political action
Society’s typical reaction to industrial

problems affecting the public is instructive.
The government typically regulates indus-
tries concerning public health, safety, and
security—for example, nuclear power, med-
ical devices, food, drugs, and aviation all re-
quire regulation. When the public feels an
industry isn’t sufficiently protecting its in-
terests, problems cease to be technical and
become political.

When faced with a public outcry, politi-
cians often enact laws and set up regulatory
bodies so organizations cannot release prod-
ucts or provide services without governmen-
tal approval. These fears might seem unreal-
istic and overstated, but consider the history
of political action when faced with repeated
industrial failure. If the software industry
can’t solve its own problems, the govern-
ment might establish an oversight group to
protect the public. All it would take is a
highly visible disaster to galvanize public
opinion and motivate political action. 

Although the pace of political action is
typically glacial, the political process has
already started. States are now considering
the licensing of software professionals;
Texas has already enacted such legislation,
and two state legislatures have enacted the
controversial Uniform Computer Informa-
tion Transactions Act (UCITA) proposal to
limit industrial liability for software fail-
ures. (The National Conference of Com-
missioners on Uniform State Laws devel-
oped the UCITA proposal to update the
Universal Commercial Code for the infor-
mation age. It provides a legal framework
for interpreting contracts involving soft-
ware and other intellectual property. Indus-
try groups are now trying to get all 50 US
states to enact UCITA legislation.) The soft-
ware problem is now a political concern,
and we can only hope we find sound tech-
nical solutions before the public demands
governmental protection from our inade-
quate performance.

Can we solve our own problems?
Can the software industry solve its own

problems in time to prevent a serious public
disaster, or must the government solve our
problems for us? The fact that a govern-
mental body doesn’t know how to solve
these problems any better than we do will
not deter politicians. If the problems are se-
rious enough, and the public concerned
enough, there will be action—whether it’s
effective or not.

Because today’s software professionals
can’t consistently and predictably produce
quality software, we must change how we
develop and support software and how we
educate, train, and manage software profes-
sionals. Because a few leading organizations
can consistently produce quality software,
this must be at least partly an education
problem.

A fundamental question concerns the mix
of theory and practice in software engineer-
ing education. In this issue’s Point/Counter-
point department, Barry Boehm compares
software to a contact sport, claiming soft-
ware professionals must be prepared for the
industry’s rough-and-tumble life. He argues
for an increased focus on economics, change
management, and practical experience. Con-
versely, Allen Tucker argues that software
professionals need a stronger grounding in
theory and disciplined practice to consis-
tently produce quality software. 

The theory-versus-practice debate raises
the issue of how completely the academic
community can and should prepare gradu-
ates for an industrial software career. For
example, is software like mechanical and
electrical engineering, where new graduates
must know the basics to get their first job,
and then they can start their lifelong career
of learning how to become professional en-
gineers? Or should software education more
closely mirror the medical profession, with
its intense specializations, teaching hospi-
tals, internships, and licensing? Two of the
articles in this issue, one by Richard Conn
and the other by Jorge Diaz-Herrera, Mike
Murphy, and Dawn Ramsey, discuss indus-
try needs, focusing on the quality and com-
mitment problems industry faces and how
better preparation could help address these
problems. Dale Callahan and Bob Pedigo
address the IT community’s needs, including
graduate programs for IT managers.

S e p t e m b e r / O c t o b e r  2 0 0 2 I E E E  S O F T W A R E 2 3



Four articles discuss the tradeoffs in-
volved in designing software curricula. Hos-
sein Saiedian, Donald Bagert, and Nancy
Mead address the academic considerations
involved in developing software engineering
programs. Jürgen Börstler, David Carring-
ton, Gregory Hislop, Susan Lisack, Keith
Olson, and Laurie Williams describe the
curriculum issues involved in introducing
disciplined software engineering methods
and in structuring and teaching a Personal
Software Process course. Ken Surendran,
Helen Hays, and Andrew Macfarlane de-
scribe how apprenticeship programs pro-
vide practical exposure to industrial prob-
lems and issues, and Grant Cheston and
Jean-Paul Tremblay discuss introducing
software engineering courses at the begin-
ning of an academic program. 

The final three articles deal with team
project courses, discussing the skills in-
volved and disciplines required to work on
software teams. The trade-offs concern the
rigor required to produce quality work and
students’ willingness to enroll in rigorous
academic programs. The steady decline in
computer science and engineering enroll-
ments suggests that these more rigorous
methods must be justified or student enroll-
ments will continue to drop. In our article,

we discuss why we need team courses and
present various ways to structure them.
David Umphress, Dean Hendrix, and James
Cross describe their long search for a suit-
able framework for teaching software proj-
ect courses, and Lisa Burnell, John Priest,
and John Durrett describe a unique and in-
novative approach to teaching in a simu-
lated industrial environment. 

W e hope this special issue serves asa catalyst for continued discus-sion of society’s needs for safe,
secure, and reliable software products and
the importance of software education in ad-
dressing these needs.

References
1. Chaos, A Recipe for Success, The Standish Group Int’l,

West Yarmouth, Mass., 1999.
2. Cutter Consortium, “78% of IT Organizations Have

Litigated,” The Cutter Edge, 9 Apr. 2002,
www.cutter.com/research/2002/edge020409.html.

3. “The Economic Impacts of Inadequate Infrastructure
for Software Testing,” Planning Report 02-3, NIST,
Gaithersburg, Md, 2002; http://nist.gov/director/
prog-ofc/report02-3.pdf.

2 4 I E E E  S O F T W A R E S e p t e m b e r / O c t o b e r  2 0 0 2

About the Authors

Watts Humphrey is a Fellow of the Soft-
ware Engineering Institute at Carnegie Mellon Uni-
versity. His principal areas of interest are in soft-
ware process, process improvement, teamworking
methods, and transitioning improved methods into
general practice. He holds graduate degrees in
physics and business administration and an hon-
orary PhD in software engineering. He led the ini-
tial development and introduction of the Software

Capability Maturity Model and developed the Personal Software Process as well
as the initial versions of the Team Software Process. He is a member of the
ACM, an IEEE Fellow, and a past member of the Malcolm Baldrige National
Quality Award Board of Examiners. Contact him at the Software Eng. Inst.,
Carnegie Mellon Univ., Pittsburgh, PA 15213; watts@sei.cmu.edu.

Thomas B. Hilburn is a professor of com-
puter science at Embry-Riddle Aeronautical Univer-
sity and a visiting scientist at the Software Engi-
neering Institute, Carnegie Mellon University. His
research interests include software processes, for-
mal specification techniques, and curriculum devel-
opment. He is a member of the ACM and IEEE
Computer Society, serves as the academic editor for
the Forum for Advancing Software Engineering Ed-
ucation, is the software engineering editor for Computing Reviews, and is an ed-
itor for the ACM/IEEE-CS Computing Curriculum–Software Engineering project.
Contact him at the Dept. of Computing, Embry-Riddle Aeronautical Univ., Day-
tona Beach, FL 32114; hilburn@erau.edu.

D. Bagert et. al., Guidelines for Software Engineering Education, Ver-
sion 1.0, tech. report CMU/SEI-99-TR-032, Software  Engineering Insti-
tute, Carnegie Mellon Univ., 1999.

N. Coulter and N. Gibbs, eds., Annals of Software Engineering, vol. 6,
Apr. 1999. 

P.J. Denning, “Educating a New Engineer,” Comm. ACM, vol. 35, no.
12, Dec. 1992, pp. 83–97.

G. Ford and N. Gibbs, A Mature Profession of Software Engineering,
tech. report, CMU/SEI-96-TR-004, Software Engineering Institute,
Carnegie Mellon Univ., 1996, www.sei.cmu.edu/publications/
documents/96.reports/96.tr.004.html, 1996.

W.S. Humphrey, Introduction to the Personal Software Process, Addi-
son-Wesley, Boston, 1997.

W.S. Humphrey, The Discipline of Software Engineering, Addison-
Wesley, Boston, 1995.

W.S. Humphrey, Introduction to the Team Software Process, Addison-
Wesley, Boston, 2000.

W.S. Humphrey, Winning With Software: An Executive Strategy, Addi-
son-Wesley, Boston, 2002.

T. Lethbridge, “What Knowledge is Important to a Software Profes-
sional,” Computer, vol. 33, no. 5, May 2000, pp. 44–50. 

Joint IEEE-CS/ACM Task Force on Computing Curriculum, Computing
Curriculum 2001, Volume II, Dec. 2001; www.computer.org/education/
cc2001/final/index.htm.

Suggested Reading



focuseducating software professionals

0 7 4 0 - 7 4 5 9 / 0 2 / $ 1 7 . 0 0  ©  2 0 0 2  I E E E S e p t e m b e r / O c t o b e r  2 0 0 2 I E E E  S O F T W A R E 2 5

Sun workstations and PCs networked to
Web servers, a configuration management
server, an aircraft simulator implemented in
software, and laboratories are composed of
the aircraft’s hardware mounted in equip-
ment racks for easy access. A Web-based
digital nervous system2 supports software
engineering activities including data collec-
tion and metrics generation for software
product and process evaluation. 

This IPT has educational needs as di-
verse as the roles of the C-130J aircraft.
IPT activities cover many software devel-
opment domains that address corporate,
Federal Aviation Administration, and na-
tional and international military and civil-
ian requirements. Many new hires, 
however, lack preparation for this envir-
onment. This article discusses the IPT’s di-
verse education and training needs, focus-
ing on how to address shortfalls in
conventional computer science and engi-
neering education that result in mis-
matched expectations between the new
hire and the company.

The C-130J Airlifter and its Software
Factory

To appreciate this article’s perspective,
it’s essential to understand the product we
create. Lockheed Martin rolled out the first
production C-130 aircraft on 10 March
1955. Since then, Lockheed Martin has
built more than 2,100 C-130s, and over 60
nations worldwide fly them in dozens of
variations. C-130 aircraft 

� Carry troops, vehicles, and armaments
into battle

� Drop paratroopers and supplies from
the sky

� Serve as airborne and ground refuelers
� Serve as flying hospitals and hurricane

hunters
� Provide emergency evacuation and hu-

manitarian relief
� Perform airborne early warning and

maritime surveillance
� Operate in extreme conditions, from the

Sahara deserts to the ice of Antarctica
� Have helped recover space capsules

Developing Software
Engineers at the C-130J
Software Factory

Richard Conn, Lockheed Martin and Kennesaw and Southern Polytechnic State Universities

The experience of
new hires at
Lockheed Martin’s
C-130J Software
Factory serves as 
a focal point in
discussing how
industry and
academia must
coordinate efforts 
to produce effective
software engineers.

L
ockheed Martin’s C-130J Avionics/Software Integrated Product
Team (hereafter referred to as the IPT) creates software that runs a
wide variety of systems on the C-130J aircraft. This team develops
embedded safety-critical real-time air vehicle software and a

ground-based data analysis system for aircraft analysis. The IPT operates
within the infrastructure of the C-130J Software Factory,1 which consists of



In May 1992, Lockheed Martin deliv-
ered the 2,000th C-130, a C-130H. In
September 1992, formal development of
the C-130J began. Unlike its predecessors,
the C-130J is a software-intensive system,
employing modern avionics that have sig-
nificantly improved its performance. By
March 2001, the C-130J was flying with
a full complement of embedded safety-
critical, real-time air vehicle software and
had set 50 world records in the National
Aeronautics Association’s C-1-N (aircraft
weighing between 132,276 and 176,368
pounds) and short take-off and landing
(STOL) categories for speed, altitude,
time-to-climb, and other aspects of the
aircraft operation (see www.lmasc.com
and www.lockheedmartin.com).

The C-130J Airlifter incorporates dis-
tinct products, such as display panels,
radars, and engines, from over 20 suppli-
ers. Two mission computers backed up
by two bus interface units integrate these
products into a cohesive whole and con-
trol all aircraft functions. During opera-
tion, the C-130J Airlifter is supported by
a ground-based data system that offloads
data contained in the digital flight data
recorders for analysis, including future
failure prediction. 

The IPT develops the mission com-
puter and bus interface unit software
and the ground-based data system soft-
ware, and integrates the supplier’s prod-
ucts. The IPT is supported by a Web-
based digital nervous system that tracks
problem reports, documents and tracks
software changes, conducts software
product evaluations, reports costs, and
records and analyzes various process
and product data.

Problem spaces
All new IPT hires have at least a bache-

lor’s degree in computer science or one of
the engineering disciplines, such as electrical
or mechanical engineering. They have writ-
ten relatively small programs during their
educational career, and, in virtually all
cases, these programs had a well-defined
problem space or domain. 

One of the first adjustments new hires
face is realizing that they do not understand
the entire problem space. Among some of
the surprises:

� No one person completely understands all
of the aircraft’s software. Teams in over 20
companies write the software, which the
IPT then integrates into a cohesive whole.
The various teams specialize in domains
such as propulsion, radar, communica-
tions, air traffic control, and collision
avoidance. Depending on the customer,
even more specialized domains can exist,
such as hurricane monitoring and atmos-
pheric test equipment.

� Even within the domain of integrating the
various aircraft systems, the software en-
gineer does not know enough to just sit
down and write the code. Software engi-
neers work with systems engineers, cus-
tomer representatives, flight test special-
ists, and others to draw up the
requirements for the code they will later
have to write. Software quality assurance
specialists, auditors, and other team
members check their work. To most new
hires’ surprise, requirements specification
is the single greatest source of injected de-
fects in our code.

� The code is large, well beyond most new
hires’ previous experience. The IPT con-
structs the C-130J airborne software
baseline from which the IPT then de-
rives customer-specific variants, and this
adds up to over five million lines of
code. The new hire’s experience with
relatively small programs that cap off at
10,000 lines of code in a well-under-
stood domain offers scant preparation
for the more constrained discipline
needed to build a larger, safety-critical
software system like that on the aircraft.

College graduates as raw material
This new environment comes as quite a

cultural shock to most new hires, who,
proud of their accomplishments at school,
find that their education to date is really just
a springboard for another step. Many com-
panies view people straight out of school as
raw material to be shaped to the corporate
culture. In such a setting, new hires face
some common frustrations.

Process. A mature software development or-
ganization follows a defined process that,
while mutable, does not change easily or
quickly. Many ideas the new hire carries from

2 6 I E E E  S O F T W A R E S e p t e m b e r / O c t o b e r  2 0 0 2

As used here, new hire
refers to people who re-
cently joined the IPT fresh
out of school. It does not
refer to those who join the
IPT with previous software
engineering experience.

Avionics/Software Inte-
grated Product Team (IPT)
refers to the team of peo-
ple who develop the avion-
ics and software for the
aircraft and integrate the
various aircraft systems
into a cohesive whole. This
team works in the Software
Factory, an environment of
networked computers, lab-
oratories, and software
and hardware simulators.

Mature software engi-
neering organization refers
to maturity as defined by
the Software Engineering
Institute’s Software Capabil-
ity Maturity Model. CMM
Levels 4 and 5 designate
mature software engineer-
ing organizations. Data
primitives refer to raw data
such as defect counts and
cost measurements. Mea-
surements refer to informa-
tion items derived from the
data primitives, such as the
number of defects per lines
of code.

Problem space refers to
a body of knowledge that
an IPT or individual must
possess to accomplish a mis-
sion. It can cover many
knowledge domains.

Terminology



academia might not fit into the process and
thus simply fall by the wayside. New hires
may feel like they are taking a step backward,
and in some cases they are—but for a good
reason. The mature software development or-
ganization’s objective is to get a defined prod-
uct out the door on schedule and within
budget with no major defects and few minor
defects. Unwisely introducing new technology
and ideas can disrupt these deliveries. CMM
Level 5 recognizes as key the transfer of new
technology into the organization, but only
when disruption will be minimal.

The place of coding. Coding is often a very
small part of a software engineer’s life, while
in academia coding was probably the end-all
and be-all of the new hire’s view. In a mature
software development organization, much
of a software engineer’s life is spent in meet-
ings, discussing requirements, planning,
evaluating software products (requirements
specifications, designs, code, test scripts, de-
liverable documents, and more), document-
ing and reporting, and testing. The IPT’s
software development process incorporates
over 110 distinct subprocesses, only a hand-
ful of which involve writing code.

Early team roles. Many new hires expect to
jump into the “fun” coding work right away,
but this is seldom the case. Before they move
into the development groups that actually
write the code, new hires are usually assigned
to test code and participate in software prod-
uct evaluations on code, requirements specifi-
cations, designs, test scripts, and other deliv-
erables and nondeliverables. This is often
more challenging and frustrating than coding.

These early roles, however, serve an im-
portant purpose: catching defects before
product delivery. These roles also serve an
important secondary purpose in that new
hires learn about the corporate culture and
the people they will work with later as re-
quirements engineers, designers, coders, and
testers. Role-specific training for all IPT
members is controlled by the Software Fac-
tory’s Web-based Learning Navigator tool
and augmented by mentoring.

Metrics. Providing various data primitives and
metrics to management, rather than just con-
centrating on the work at hand, forms a sig-
nificant part of the corporate culture. Few new

hires have experience using metrics for project
management or see the value in doing so.

More mature software engineering organ-
izations, by contrast, use data primitives
gathered throughout their processes’ execu-
tion. They also use metrics computed from
those data primitives to measure the quality
of the products produced and processes exe-
cuted by their teams. They establish “metrics
yardsticks” by which to measure process
and product quality and then use these to es-
tablish new goals. Metrics help senior man-
agement gain visibility into programs and
projects for which they are responsible with-
out having to take part in the day-to-day ac-
tivities. Metrics help first- and second-line
management gain insight into where defects
are being injected into their processes and
products, making it easier to improve the
quality. Metrics are a way of life in mature
software engineering organizations.

Soft skills: A missing ingredient
A common and significant omission in

most new hires’ education is the development
of “soft skills”—communication, sales and
marketing, and teamwork in particular. One
of the greatest shocks to a new hire is the
amount of communicating a software engi-
neer must do. Some of the communication
software engineers perform routinely includes
documenting designs, preparing and giving
presentations, discussing and evaluating prob-
lems and challenges, understanding and evalu-
ating software products, tracking action items,
and documenting changes to software prod-
ucts. They also must write requirements, test
plans and cases, defect reports on software
products, and activity reports. Few new hires
did much or any of this in school.

Many new hires are surprised by the need
for sales and marketing skills. Teams sel-
dom accept new ideas readily from any
team member, particularly a new hire. Team
members must communicate their ideas ef-
fectively to sell both software engineers and
management (which might have little or no
background in software engineering) on
them, and they must package and market
them with increasing skill as they go further
up the engineering and management chain.
To new hires, the frequent rebuff of their
ideas can be a constant source of frustra-
tion. Even experienced software engineers
find this frustrating, but the better ones

S e p t e m b e r / O c t o b e r  2 0 0 2 I E E E  S O F T W A R E 2 7

Coding is often a
very small part
of a software

engineer’s 
life, while 

in academia 
coding was

probably the
end-all and 
be-all of the

new hire’s view.



have the advantage of a track record that
gives them an edge new hires do not enjoy.
New hires’ education-oriented track records
seldom count in these situations.

Adjusting to working on a mature software
development team poses several additional
problems. Most new hires’ rewards through-
out their educational career have come from
their individual efforts, and they typically have
little exposure to the team-oriented processes
found in mature software development organ-
izations. They might be used to meeting dead-
lines through individual heroic effort, often at
the last minute, which contradicts a con-
trolled, process-driven software development
approach where deadlines are met through
consistent team effort over time—sometimes
months or years. Heroic efforts might prove
necessary from time to time, but as both the
software and systems engineering activities
mature, such efforts become less frequent. 

New hires also might find software product
evaluations discouraging. When a team criti-
cally examines the new hire’s software (such as
a test plan or a requirements specification), the
new hire might view such critiques as attacks
on his or her work. Educational experience
rarely prepares the new hire for a world in
which software cannot be produced without
teamwork and evaluation. This cultural mis-
match creates vastly different expectations for
new hires and the mature software develop-
ment organization employing them. 

Retention and investments lost
This mismatch of expectations can lead

to problems in retaining new hires. The first
job might become just a training ground for
the next as the new hire becomes increas-
ingly frustrated with the discipline of ma-
ture software engineering. When a company
loses a new hire, it loses its investment in
that person. Organizations must plan for
such a loss, being ready to fill the gap until
they can find a replacement. The safeguards
in place in mature software engineering or-
ganizations ensure that the work the new
hire has done is not lost, but nothing can re-
place the initial investment.

IPT Solutions
Overcoming one culture and instilling a

different one in a group of people can be
difficult and time-consuming. As happens at
most companies, new IPT hires attend a

new employee orientation, a sort of prelim-
inary indoctrination to the culture. This in-
doctrination covers a lot of material, and
time constraints prevent in-depth explana-
tions of why things are the way they are.

New hires then go to their specific as-
signments, where they receive job-specific
material to study and are assigned mentors
to guide them in their daily work. They also
receive role-based training, which offers the
opportunity to explore the rationale behind
company processes and procedures. How-
ever, most new hires don’t ask such ques-
tions, simply accepting the training at face
value. We therefore try to work into the
training information on the rationale.

What universities can do
Being educational rather than training in-

stitutions, universities and colleges produce
graduates whose educational foundation
lets them technically adapt to challenges
both foreseen and unforeseen. Corporations
like Lockheed Martin then take the new
hires as raw material, training them to deal
with organizational issues such as

� Software process and its execution—how
to produce requirements specifications,
create designs, develop code, evaluate
software products, test software prod-
ucts against the requirements, and so on

� Appropriate use—how to use the orga-
nization’s software tools and program-
ming languages within the bounds of the
processes and methodologies adopted

� Organization member information—
such as chain of command, problem re-
porting, and daily operation details

The IPT interacts with local universities,
particularly Southern Polytechnic State Uni-
versity and Kennesaw State University, and
such institutions as the Software Productiv-
ity Consortium (SPC; www.software.org)
and the Software Engineering Institute (SEI;
www.sei.cmu.edu), to help address its em-
ployees’ educational needs. The resulting
cultural change we see in new hires from
these universities—from a focus on coding
to involvement in other software engineer-
ing activities such as requirements defini-
tion—eases their entry into the corporate
culture. We would see more of this across
the industry if universities would interact

Unless our
educational

system 
can produce
graduates

familiar with
and ready to
adopt more

mature
software

development
practices,
software
failures 

will persist.

2 8 I E E E  S O F T W A R E S e p t e m b e r / O c t o b e r  2 0 0 2



more with local firms, collaborate with or-
ganizations like the SPC and SEI, and be-
come involved with groups such as the Fo-
rum for Advancing Software Engineering
Education (www.cs.ttu.edu/fase) to help
faculty better understand the issues facing
industry.

At the IPT, organization members pro-
vide some training; other training comes
from Southern Polytechnic State Univer-
sity’s Software Engineering Retraining Pro-
gram (http://cs.spsu.edu) and the Software
Productivity Consortium’s courseware col-
lection, among others. Such training, how-
ever, is not appropriate as part of a regular
degree program at a local university or col-
lege—an institution would compromise
graduates’ educational foundation if it per-
mitted such corporate influence in its de-
gree programs. More fitting are courses like
CSIS 1020 at Kennesaw State University
(http://science.kennesaw.edu/csis/), which
introduces Visual Basic programming with
a software engineering flavor to first-year
students, and degree programs like South-
ern Polytechnic State University’s master’s
in software engineering (http://cs.spsu.edu),
which covers general concepts such as ca-
pability maturity and software engineering
principles.

Rather than making training specific to
the current needs of local industry part of
their degree programs, universities and col-
leges should foster fundamental cultural
change by adding software engineering and
soft-skill knowledge units. Such knowledge
units might include

� Dealing with problems larger than a
single student can grasp and that require
a team of domain specialists to solve

� Working with a team of people under
the control of a process

� Developing products that a team of
peers will critically evaluate

� Testing and evaluating products effec-
tively, to detect as many defects in the
products as possible, and learning how
to deal with the critical evaluation of
one’s own products

� Communicating concepts effectively and
selling and marketing ideas to others

� Measuring product and process quality
analytically, establishing criteria to as-
sess product or process improvements

Such cultural changes can better position
our graduates to produce the higher-quality
products we need now and in the future.
Work was already underway to place soft-
ware engineering knowledge units into
Computing Curriculum 2001 of the Associ-
ation for Computing Machinery’s Special In-
terest Group in Computer Science Education
(www.acm.org/sigcse/cc2001/), and software
engineering degree accreditation under the
auspices of the Accreditation Board for En-
gineering and Technology (www.abet.org)
will begin in Fall 2002, but it must go fur-
ther than just covering software engineering
topics to effect the desired cultural change.

A s society relies increasingly on soft-ware for critical operations, softwarefailures become intolerable. In air-
craft, they can cost lives; in our communica-
tions systems, they can cost billions of dol-
lars. In a microwave oven, a software failure
can result in a very costly recall of thousands
of units. Failure of a commercial software
product can take its manufacturer out of
business, and if a Web site used to transact
sales fails, a company could lose millions of
dollars an hour until the Web site is repaired.

Unless our educational system can pro-
duce graduates familiar with and ready to
adopt more mature software development
practices, however, software failures will
persist. The education community must
evolve at the cultural level to produce grad-
uates who already embrace mature software
engineering practices. While students ac-
quire knowledge relatively easily, the wis-
dom to apply that knowledge well comes
much more slowly. The cultural changes
proposed here, therefore, go beyond devel-
opment of technical knowledge to culturing
the experience and mindset needed to create
and apply high-quality software. 

References
1. R. Conn, S. Traub, and S. Chung, “Avionics Modern-

ization and the C-130J Software Factory,” Crosstalk—
J. Defense Software Engineering, vol. 14, no. 9, Sept.
2001, pp. 19–23.

2. B. Gates, Business @ the Speed of Thought, Warner
Books, New York, 1999; www.speed-of-thought.com.

For more information on this or any other computing topic, please visit our
Digital Library at http://computer.org/publications/dlib.

S e p t e m b e r / O c t o b e r  2 0 0 2 I E E E  S O F T W A R E 2 9

About the Author

Richard
L. Conn is
a software
process engi-
neer for the C-
130J Airlifter
at Lockheed
Martin Aero-
nautics Com-

pany. His research interests include software
process engineering, component-based soft-
ware engineering, software reuse, and soft-
ware engineering education. He holds a BS
from Rose-Hulman Institute of Technology
and an MS from the University of Illinois,
both in computer science. He has served on
the Federal Advisory Board for Ada (receiv-
ing ACM/SIGAda’s award for Outstanding
Contributions to the Ada Community), the
DoD Software Reuse Initiative, ACM and
IEEE software engineering education work-
shops, and IEEE standards efforts. Contact
him at Lockheed Martin Aeronautical Sys-
tems, 86 South Cobb Dr., Dept. 70-D6, Mail
Zone 0674, Marietta, GA 30063-0674;
richard.l.conn@lmco.com, http://unicoi.
kennesaw.edu/~rconn, http://cs.spsu.
edu/rconn.



3 0 I E E E  S O F T W A R E S e p t e m b e r / O c t o b e r  2 0 0 2 0 7 4 0 - 7 4 5 9 / 0 2 / $ 1 7 . 0 0  ©  2 0 0 2  I E E E

Planning
In early 1999, LM Aero-Marietta asked

SPSU to investigate these concerns:

� High turnover in software engineering
positions due to competition for such
professionals

� Significant downsizing that included
personnel with valuable domain skills in
traditional engineering and avionics

� Continued viability depending, in part,
on filling critical software engineering
positions

The resulting investigation was two-fold: to
establish the specific needs associated with
these concerns and to determine the feasibility
of tailoring a program to address these needs.

The preliminary investigation took place
in the spring and summer of 1999. Initial
conversations between LM Aero-Marietta
managers and members of SPSU’s Com-
puter Science Department (now the School

of Computing and Software Engineering)
dealt with the company’s overall software
engineering environment and SPSU’s capa-
bilities to respond effectively to the results
of a full investigation. The Computer Sci-
ence Department had long offered strong
undergraduate and graduate programs in
computer science and had a major interest
in software engineering since the late 1980s.
It added a professional master of science in
software engineering (MSSWE) degree in
1997. In August 1999, we agreed to pro-
ceed with a formal needs assessment.

The assessment included focused inter-
views with key software managers at LM
Aero-Marietta, followed by written re-
sponses to a survey that addressed numer-
ous software engineering issues. The survey
was based on IEEE standards related to
software engineering (http://standards.ieee.
org/software). The resulting report proposed
an undergraduate credit-based certificate,
the Software Systems Development Certifi-

focus
A Collaborative Program
to Retrain Lockheed 
Martin Aero Engineers

Jorge Díaz-Herrera, Mike Murphy, and Dawn Ramsey, 
Southern Polytechnic State University

This innovative
program turns
engineers from
traditional areas into
software engineers
through university
coursework and a
company practicum.
Others considering
such partnerships
will benefit from
reading about the
program’s planning
and implementation,
results thus far, and
the organizers’
recommendations.

L
ockheed Martin Aeronautics Company in Marietta, Georgia,
wanted to transform a surplus of engineers from traditional areas
into software engineers, whom it found hard to attract and keep as
employees. LM Aero-Marietta approached Southern Polytechnic

State University to plan and offer a software engineering retraining program.

educating software professionals



cate, to be delivered at SPSU to LM Aero-
Marietta personnel. In addition to the 32-
credit coursework to be delivered on an ac-
celerated schedule, the SSDC required a
12-week, 240-hour internship at the com-
pany. Another possible component, provid-
ing professional growth and development
for existing LM Aero-Marietta software en-
gineers, was the Graduate Certificate in
Software Engineering, an existing credit-
based certificate program that provides one
half of the coursework required for the
MSSWE. We decided to use the new under-
graduate certificate as the primary response.

Funding
The state of Georgia offers partial fund-

ing for economic development initiatives.
One program, the Intellectual Capital Part-
nership Program (www.icapp.org), is de-
signed to build partnerships among the state,
business and industry, and public higher ed-
ucation. ICAPP’s purpose is to help compa-
nies meet specific workforce needs in Geor-
gia for educated workers in high-demand,
high-technology fields. Georgia provides fo-
cused funding, SPSU provides expertise, and
LM Aero-Marietta agrees to hire the pro-
gram’s graduates for a minimum of two years.
In addition, participants are eligible for Geor-
gia’s Hope Grant (as opposed to the Hope
Scholarship for high-achieving traditional
students) to cover tuition, fees (except park-
ing), and books. Our ICAPP proposal was
submitted in June 2000, funded in August
2000, and the first group of students started
in November 2000. LM Aero-Marietta pays
the students their regular salaries during the
32 weeks, which represents a major commit-
ment by the company. Georgia (through
ICAPP) pays for a computer classroom, fac-
ulty stipends, and administrative support
costs, and SPSU provides the program space
and instruction. We wanted to immerse the
students in a campus environment (SPSU is
approximately a mile from the company);
the courses are credit-bearing, and distrac-
tions would be fewer.

The initial version of the SSDC required 10
credit-based courses that would lead to a
meaningful student transcript representing ca-
reer-focused education rather than just skills
acquisition. Other factors that we addressed
included a workable format that would pro-
duce results over a relatively tight timetable,

selection of participants, and program fund-
ing. The proposed format was full days, 8 am
to noon and 1 pm to 5 pm, for 30 weeks (the
extra two weeks mentioned earlier include
minor breaks and official holidays). In gen-
eral, the morning is devoted to instruction
and the afternoon to lab work and study. Af-
ter 18 weeks, the afternoon lab ends and stu-
dents begin a 12-week internship. This makes
their days quite full, as the assignments and
projects for the courses don’t diminish during
the internship.

Curriculum
The SSDC curriculum has evolved over

time, and has stabilized to include a two-
course sequence on programming funda-
mentals, including the basics of the Personal
Software Process,1 and introductory two-
credit courses on software engineering,
databases, and operating systems. These are
followed by more advanced courses, includ-
ing client-server programming, Ada soft-
ware development, real-time systems, soft-
ware testing and quality assurance, and a
software engineering project. The project
course covers advanced Ada topics in a
team project setting and is supported by the
Team Software Process.2 It requires students
to make extensive use of graphics libraries
as well as tasking and distributed client-
server processing, all within Ada. The last
course is software project management,
which serves to tie up loose ends and gives
a broad perspective of the development
process. One of the challenges in building
and adjusting the curriculum was to be sure
that students have sufficient background for
a meaningful internship while still taking
courses in the program.

As soon as the proposal was approved,
faculty were sought, and they began adapt-
ing regular courses to the compressed for-
mat. Faculty members received stipends for
developing new courses, revising existing
courses into this format, and teaching them.
The stipend was used as an incentive and to
minimize the disruption to our regular of-
ferings. We hired an administrative support
person, identified space for the computer
classroom, ordered equipment, and began
searching for a half-time lab support techni-
cian. While this was happening, we started
soliciting and reviewing applications of po-
tential participants.

S e p t e m b e r / O c t o b e r  2 0 0 2 I E E E  S O F T W A R E 3 1

Georgia
provides
focused
funding, 

SPSU provides
expertise, 

and Lockheed
Martin 

Aeronautics
agrees to hire
the program’s
graduates for 
a minimum of

two years.



Implementation
Coordination of the SPSU academic pro-

gram centered on a faculty advisory com-
mittee composed of four professors and the
CS Department industry liaison. Committee
members visited the company to present the
program’s curriculum to potential partici-
pants and answer questions. Others from
SPSU and LM Aero-Marietta were also
present at these information sessions to ex-
plain admission to SPSU as well as the se-
lection and processing of applicants.

The committee developed an evaluation
form to assess the academic indicators of
program success (for example, math matu-
rity, previous GPA and degree type, and
motivation as indicated in a statement of
purpose in applying). Applicants were
screened into one of three categories: highly
recommended, acceptable, and not recom-
mended. The files of those in the top two
categories then went to LM Aero-Marietta,
where managers of software-intensive units
reviewed them. The managers interviewed
the candidates who met the company’s de-
sired profile (for example, work history,
domain knowledge, and references) and
chose the top applicants. The plan was to
have four staggered groups of 20 each.

Results to date
The first three groups have graduated.

The students refer to themselves as “SER-
Pents,” showing they can maintain a sense
of humor and camaraderie while being im-
mersed in an intense retraining program.

There are some interesting observations
that we can make at this point. The stu-
dents tend to have some difficulty adjusting
to the rapid pace and academic nature of
the program. They are used to having
rather well defined requirements and deliv-
erables for their work as engineers. Thus,
they are rather intense and anxious about
grades and course requirements. They
sometimes have surprisingly high expecta-
tions for the instruction they receive, and
there is the adjustment from one instructor
to the next. The first group objected to the
term “internship” as somewhat demeaning
for those who have already been practicing
engineers, so we changed it to “practicum,”
which has been well received thus far. Also,
some managers had unrealistic expec-
tations regarding the students’ software 

engineering maturity at the point of the
practicum.

We have done some tuning of the
courses based on feedback from students
and managers. In particular, we increased
the coverage of software development in
Ada. We also lengthened the delivery time
of the two-credit courses by running them
in parallel at half the contact time each for
twice the number of days, because the
original format caused that material to be
frustrating in terms of time to absorb and
apply concepts. We also found that per-
formance is best overall for those who
come in with some software development
experience but not too much. Too little or
none tends to cause anxiety at the pace of
instruction, and too much brings up issues
of unlearning bad practices and resisting
new or more formal approaches because
“that isn’t the way it gets done in real
life.” From the other side, managers also
have concerns about taking on a senior en-
gineer (from a traditional field) as a
trainee in software engineering.

Figure 1 shows how the third delivery of
the program was organized; the top part of
the figure describes lectures and the bottom
part lab and practicum time. Originally, the
software engineering project course was
placed toward the end of the program, be-
cause students would be doing their
practicum at the same time (in the after-
noons) and could address problems with
real systems. This, however, caused severe
problems, as we explain later, so we decided
to place the project course before the
practicum. This worked much better, be-
cause the project course

� Immediately followed the Ada program-
ming course, allowing smooth continua-
tion of this material

� Exposed students to structured team-
work, which turned out to be very use-
ful for application during the practicum

� Gave students a higher-level view of
real-time programming and distributed
computing before they were exposed to
the lower-level details of these topics

We planned the project course around
the Introductory TSP framework, which is
designed for a semester of 15 to 17 weeks.
However, the course had to be taught in

Performance 
is best overall
for those who
come in with

some software
development

experience but
not too much.

3 2 I E E E  S O F T W A R E S e p t e m b e r / O c t o b e r  2 0 0 2



four weeks, so drastic changes were in or-
der. TSPi calls for a cyclical development ap-
proach, each of the three cycles preceded by
a launch (or relaunch) and followed by a
postmortem. The first time we taught the
course, we condensed two cycles, and this
did not work well. The amount of record
keeping necessary to collect all TSPi data
and the learning curve of the process scripts,
forms, and such was overwhelming for the
amount of time available—compounded by
the fact that the students did not have the
afternoon lab time anymore because they
were engaged in the practicum. The second
and subsequent offerings of the course fo-
cused on one cycle and a modified imple-
mentation phase organized in builds or
minicycles. We had only one project launch
and one postmortem. The instructor and the
students were very satisfied with the results.

The curriculum was not the only thing
that changed. The company’s commitment
diminished due to evolving needs, changes
in the general economy, and winning or los-
ing specific government contracts. The third
group included only 10 LM Aero-Marietta
employees plus two people from elsewhere.
The program will end when the fourth
group graduates in December.

A lthough others have developed soft-ware engineering retraining pro-grams,3–5 the program presented
here reflects a collaborative effort of higher

education, government, and industry re-
sponding to a critical need in a specific do-
main, aerospace. The lessons learned are
similar to those from software development
in general: the field is young and immature;
requirements change almost as fast as they
can be written down; process improvement
is at the heart of effective and efficient deliv-
ery; and what works on one project doesn’t
assure that it can be replicated. Anyone in-
terested in keeping up with software engi-
neering education, training, and retraining
should consider attending the annual Con-
ference on Software Engineering Education
and Training (CSEE&T).

Based on our experience to date, the fol-
lowing key principles have emerged:

� Leverage support for economic develop-
ment from seemingly diverse sources.

� Nurture the relationship with those
committed to the program’s vision and
success.

� Establish and maintain high levels of
communication with all parties.

� Be flexible in building such programs
but do not abandon core values.

These “platitudes” are critical to success in
linking higher education to the needs and
support of business and industry. The re-
training program at SPSU is making a differ-
ence. Lockheed Martin has publicized the
program widely and is proud of participating
and adding value to their workforce.6

S e p t e m b e r / O c t o b e r  2 0 0 2 I E E E  S O F T W A R E 3 3

Programming
Fundamentals

I and II

Laboratory
(afternoon)

Practicum
(afternoon)

150 hours 150 hours 90 hours60 hours 60 hours 75 hours

PSP
(light)

C++

Intro to
Software

Engineering

Intro to
Operating
Systems

Application
Program-

ming

Real-Time
Systems

Quality
Assurance

Intro to
Databases

Client-
Server

Project
Manage-

ment

Software
Engineering

Project

Ada Ada
(advanced)

TSPi

Figure 1. Program organization for the third and fourth groups.



References
1. W. Humphrey, Introduction to the Personal Software

Process, Addison-Wesley, Reading, Mass., 1997.
2. W. Humphrey, Introduction to the Team Software

Process, Addison-Wesley, Reading, Mass., 2000.
3. A. Ben-David et al., “An Industrial Software Engineer-

ing Retraining Course: Development Considerations
and Lessons Learned,” IEEE Trans. Software Eng., vol.
10, no. 6, June 1984, pp. 748–755.

4. J.Z. Loeb (Lavi), M.I. Ben-Porat, and A. Ben-David,
“IAI Corporate Software Engineering Training and Ed-
ucation Program,” IEEE Trans. Software Eng., vol. 13,
no. 11, Nov. 1987, pp. 1207–1216.

5. “Carleton Computer Science Certificate (Software),”
Carleton Univ. School of Computer Science,
www.scs.carleton.ca/~dehne/proj/certificate.

6. “Programmed for Success,” Lockheed Martin Today,
vol. 7, no. 8, Aug. 2001, p. 4.

For more information on this or any other computing topic, please visit our
Digital Library at http://computer.org/publications/dlib.

3 4 I E E E  S O F T W A R E S e p t e m b e r / O c t o b e r  2 0 0 2

About the Authors

Jorge Díaz-Herrera is dean and a professor in the Golisano College of Computing and
Information Sciences at the Rochester Institute of Technology. Formerly, he was a professor of
computing and software engineering at Southern Polytechnic State University, where he partici-
pated in the work for this article. He has also worked at Carnegie Mellon University’s Software
Engineering Institute. Some of his current activities relate to software engineering education
and the software engineering of embedded systems. Contact him at the Golisano College of
Computing and Information Sciences, Rochester Inst. of Tech., 20 Lomb Memorial Dr.,
Rochester, NY 14623-5603; jdiaz@gccis.rit.edu.

Mike Murphy is founding dean and professor in the School of Computing and Software
Engineering at Southern Polytechnic State University. He is interested in software engineering
education, courses, and curricula. Contact him at Southern Polytechnic State Univ., School of
Computing and Software Eng., 1100 S. Marietta Pkwy., Marietta, GA 30060-2896; mmuphy@
spsu.edu.

Dawn Ramsey is dean of the Extended University at Southern Polytechnic State Univer-
sity and industry liaison for the School of Computing and Software Engineering at SPSU. Her
areas of interest are industry–academia collaboration and retraining programs. Contact her at
the Extended Univ., Southern Polytechnic State Univ., 1100 S. Marietta Pkwy., Marietta, GA
30060-2896; dramsey@spsu.edu.

PURPOSE The IEEE Computer Society is the world’s
largest association of computing professionals, and is the

leading provider of technical information in the field.

MEMBERSHIP Members receive the monthly
magazine COMPUTER, discounts, and opportunities

to serve (all activities are led by volunteer mem-

bers). Membership is open to all IEEE members,

affiliate society members, and others interested in

the computer field.

B O A R D  O F  G O V E R N O R S
Term Expiring 2002: Mark Grant, Gene F. Hoff-
nagle, Karl Reed, Kathleen M. Swigger, Ronald
Waxman, Michael R. Williams, Akihiko Yamada 

Term Expiring 2003: Fiorenza C. Albert-
Howard, Manfred Broy, Alan Clements, Richard
A. Kemmerer, Susan A. Mengel, James W. Moore,
Christina M. Schober

Term Expiring 2004: Jean M. Bacon, Ricardo
Baeza-Yates, Deborah M. Cooper, George V. Cy-
benko, Wolfgang K. Giloi, Haruhisha Ichikawa, 
Thomas W. Williams
Next Board Meeting: 8 Nov 02, Boston, MA.

I E E E  O F F I C E R S
President: RAYMOND D. FINDLAY

President-Elect: MICHAEL S. ADLER

Past President: JOEL B. SYNDER

Executive Director: DANIEL J. SENESE

Secretary: HUGO M. FERNANDEZ VERSTAGEN

Treasurer: DALE C. CASTON

VP, Educational Activities: LYLE D. FEISEL

VP, Publications Activities: JAMES M. TIEN

VP, Regional Activities: W. CLEON ANDERSON

VP, Standards Association: BEN C. JOHNSON

VP, Technical Activities: MICHAEL R. LIGHTNER

President, IEEE-USA: LeEARL A. BRYANT

EXECUTIVE COMMITTEE
President: WILLIS K. KING*
University of Houston
Dept. of Comp. Science
501 PGH
Houston, TX 77204-3010
Phone: +1 713 743 3349 Fax: +1 713 743 3335
w.king@computer.org

President-Elect: STEPHEN L. DIAMOND*
Past President: BENJAMIN W. WAH*
VP, Educational Activities: CARL K. CHANG *
VP, Conferences and Tutorials: GERALD L. ENGEL*
VP, Chapters Activities: JAMES H. CROSS†

VP, Publications: RANGACHAR KASTURI†

VP, Standards Activities: LOWELL G. JOHNSON
(2ND VP)*

VP, Technical Activities: DEBORAH K. SCHER-
RER(1ST VP)*

Secretary: DEBORAH M. COOPER*
Treasurer: WOLFGANG K. GILOI*
2001–2002 IEEE Division VIII Director:
THOMAS W. WILLIAMS

2002–2003 IEEE Division V Director:
GUYLAINE M. POLLOCK†

Executive Director: DAVID W. HENNAGE†

*voting member of the Board of Governors

COMPUTER SOCIETY WEB SITE
The IEEE Computer Society’s Web site, at 
http://computer.org, offers information and samples
from the society’s publications and conferences, as
well as a broad range of information about technical
committees, standards, student activities, and more.

COMPUTER SOCIETY O F F I C E S
Headquarters Office

1730 Massachusetts Ave. NW 
Washington, DC 20036-1992
Phone: +1 202 371 0101 • Fax: +1 202 728 9614
E-mail: hq.ofc@computer.org

Publications Office
10662 Los Vaqueros Cir., PO Box 3014
Los Alamitos, CA 90720-1314
Phone:+1 714 821 8380
E-mail: help@computer.org
Membership and Publication Orders:
Phone: +1 800 272 6657 Fax: +1 714 821 4641
E-mail: help@computer.org

European Office
13, Ave. de L’Aquilon
B-1200 Brussels, Belgium
Phone: +32 2 770 21 98 • Fax: +32 2 770 85 05
E-mail: euro.ofc@computer.org

Asia/Pacific Office
Watanabe Building
1-4-2 Minami-Aoyama, Minato-ku,
Tokyo 107-0062, Japan
Phone: +81 3 3408 3118 • Fax: +81 3 3408 3553
E-mail: tokyo.ofc@computer.org

E X E C U T I V E  S T A F F
Executive Director: DAVID W. HENNAGE
Publisher: ANGELA BURGESS
Assistant Publisher: DICK PRICE
Associate Executive Director: ANNE MARIE KELLY
Chief Financial Officer: VIOLET S. DOAN
Director, Information Technology & Services:
ROBERT CARE
Manager, Research & Planning: JOHN C. KEATON

12-JULY-2002



focuseducating software professionals

0 7 4 0 - 7 4 5 9 / 0 2 / $ 1 7 . 0 0  ©  2 0 0 2  I E E E S e p t e m b e r / O c t o b e r  2 0 0 2 I E E E  S O F T W A R E 3 5

In recent years, software researchers and
developers have explored numerous princi-
ples for improving software practices, some
of which have proven effective in practical
projects. These include software develop-
ment methodologies and environments,
structured and object-oriented program-
ming, software process improvement mod-
els (such as the CMM), Computer-Aided
Software Engineering (CASE) tools, and
fourth-generation languages. Nevertheless,
we have not completely resolved our soft-
ware problems, and many organizations
continue to suffer from bad practices.

One way to improve practice is to focus
on properly educating the next generation
of SE professionals. However, the debate
about the most effective approach to edu-
cating this next generation continues un-
abated. Some argue for an SE track under
existing computer science (or computer en-

gineering) programs. Others promote spe-
cialized and independent SE degrees at the
graduate as well as undergraduate levels.
Some universities have established such spe-
cialized programs, hoping that they will ad-
dress all industrial SE problems. Unfortu-
nately, universities often don’t know what
new programs should offer or when or at
what level they are most appropriate. Fur-
thermore, traditional computer scientists
have criticized these programs as merely
providing an opportunity to offer industrial
training in programming. In many ways, the
current situation mirrors that of the com-
puter science field in the 1960s and 70s:
electrical engineering and mathematics fac-
ulty initially resisted the growth of com-
puter science degree programs just as cur-
rent computer faculty are treating SE today. 

Contributing to the hype about and harsh
criticism of SE programs are some widely held

Software Engineering
Programs: Dispelling the
Myths and Misconceptions

Hossein Saiedian, University of Kansas

Donald J. Bagert, Rose-Hulman Institute of Technology

Nancy R. Mead, Software Engineering Institute

Some people think
new software
engineering degree
programs address
industrial software
development
problems; others
argue that they 
are merely an
opportunity to
provide industrial
training in
programming. The
authors address
these and similar
issues, discussing
commonly held
myths about such
programs. 

I
n a now classic 1994 Scientific American article, W. Wayt Gibbs de-
scribed software crises in both the private and government sectors.1 The
problems he discussed ranged from overrunning budgets and schedules
to terminating projects despite multimillion-dollar investments. Similar

concerns were reported as recently as March 2001 in the Communications of
the ACM, where several authors made grim predictions about the future of
software engineering (SE) if the industry continues with “business as usual.”2



myths. This article examines these myths, dis-
pelling the misconceptions to defuse unneces-
sary concerns, conflicts, and distractions and
help provide an appropriate context and di-
rection for new SE degree programs.

Myth 1

A new software engineering degree 
program is an academic necessity.

There seems to be a rush to develop new SE
degree programs (especially at the graduate
level) simply because many SE faculty mem-
bers believe that adding such programs will
improve the reputation of their departments
and institutions. Adding a new degree pro-
gram will lead to a better image, but we must
calculate the associated costs to determine
whether the program will be cost effective in
the long run. In certain market areas, such pro-
grams are absolutely necessary and a welcome
addition; in other areas, they won’t have such
an impact and thus might become a burden.

Institutions should not develop new pro-
grams based on image-enhancing effects,
popular trends, or peer pressure. Rather,
they should introduce a program only if it is
necessary and has a valid and viable market.
Those interested in introducing a degree
program must objectively assess existing in-
dustrial needs, the potential pool of stu-
dents, expertise among the existing faculty,
and administrative support. Furthermore,
developing a new SE program is not always
the only means of addressing the needs of
local industrial organizations or student re-
quests. Many times, adding core SE courses
in a computer science program or adding an
SE focus area (or specialization) will address
both real and perceived demands.

Myth 2

Software engineering programs will unneces-
sarily expend computer science resources.

The general consensus in both industry
and academia is that computer science degree
programs are worthwhile and should con-
tinue for the foreseeable future. Therefore, to
meet the demand for computer scientists as
well as the emerging need for those educated
in SE, there must be sufficient resources (es-
pecially faculty) for both programs.

There is a severe shortage of faculty in
all computing fields, including SE. Master’s

programs in SE often overcome this obsta-
cle by using part-time adjunct faculty, but
this is a less viable option for many under-
graduate programs. With a small pool of
potential new faculty available, some insti-
tutions must retrain computer science fac-
ulty to teach SE. However, finding people
willing to undergo such retraining is more
difficult than in industry, due to the rights
that tenured faculty exercise at many aca-
demic institutions.

The discussion here assumes that a com-
puter science department will house the SE
program, perhaps becoming the Department
of Computer Science and Software Engineer-
ing (CSSE). Because the disciplines are closely
related, housing them in the same academic
unit is the best option, letting the two faculties
work together for their mutual good. How-
ever, at many institutions, there are difficult
political issues involved in forming a CSSE de-
partment, especially if the Computer Science
Department is not in a College of Engineering.
Furthermore, people believe that an SE pro-
gram in such a CSSE department would con-
siderably drain computer science resources—
but this is not necessarily the case. 

Consider the following scenario: The cur-
riculum for a computer science department
in a College of Engineering has nearly half of
its credit hours in the computer science de-
partment. In addition, there is a 90/10 per-
cent split between the computer science and
SE hours, which is consistent with the core
material recommended for a computer sci-
ence degree under Computing Curricula
2001 (CC2001).3 Thus, 90 percent of the
computer science faculty must teach com-
puter science courses, and the other 10 per-
cent must teach software engineering classes.

Now suppose the department adds an SE
degree program. The total number of credit
hours computer science and SE majors take
through the newly named CSSE Depart-
ment are the same, but the split in hours is
now 50/50 between the two disciplines.
(This is consistent with the recommenda-
tions made in the Guidelines for Software
Engineering Education,4 which provides
the SE undergraduate curriculum model
most cited in recent literature.) Subse-
quently, one-third of the department’s ma-
jors are in SE and the other two-thirds are
in computer science. How does this affect
the allocation of resources?

Adding a new
degree program

will lead to a
better image,
but we must
calculate the

associated costs
to determine
whether the

program will be
cost effective 

in the long run.

3 6 I E E E  S O F T W A R E S e p t e m b e r / O c t o b e r  2 0 0 2



When academic programs discuss re-
sources, they’re generally referring to fac-
ulty. Suppose the Computer Science De-
partment has 30 faculty members. Before
the SE degree existed, the department
would need 27 computer science instruc-
tors and three SE instructors, due to the
90/10 percent split in hours. Under this
scenario, implementing the SE program
would require a shift of four faculty mem-
bers. The computer science majors (two-
thirds of the total) would require 18 com-
puter science and two SE instructors; the SE
majors would need five computer science
and five SE instructors, meaning that the
computer science and SE split of the faculty
would now be 23/7.

So, only 13 percent of the faculty (four out
of 30) would need to shift to SE to implement
the change. Considering the number of elec-
trical engineering and mathematics faculty
that changed to computer science as it was
emerging, this seems reasonable, despite the
retraining issues involved. Furthermore, it is
likely that students who would have origi-
nally been computer engineering majors in
an Electrical and Computer Engineering
(ECE) Department will now be SE majors.
Those students will take about the same
number of computer science hours as in com-
puter engineering, so there will be no addi-
tional drain on computer science faculty; any
additional faculty needed would be in SE. So,
this means that the department would gain
more majors (at the expense of ECE) and (if
available) more faculty to teach them.

We can vary the scenario, but it still indi-
cates that creating an SE program in an CSSE
Department will have minimal negative im-
pact on the faculty. The positive benefits—
more majors, faculty, and choices available
to the student—far outweigh the disadvan-
tages, and we would get better-educated soft-
ware professionals without depleting the sup-
ply of computer science graduates.

Myth 3

Software engineering undergraduate 
programs do not have enough depth.

Many companies believe that a master’s
degree program in SE provides a sufficient
overall background for future software pro-
fessionals. Such programs typically require
the student to have a minimal background

of a set of undergraduate computer science
courses such as data structures, discrete
structures, design and analysis of algo-
rithms, and operating systems, for a total of
24 to 30 hours. The question is, can an un-
dergraduate SE program provide the com-
puter science background needed while pro-
viding the additional SE topics necessary to
educate a software professional?

Several sources indicate the type of core
computer science background that should be
required. Tim Lethbridge surveyed software
professionals and reported that the 25 most
important topics required of such individuals
include computer science areas such as spe-
cific programming languages, data structures,
object-oriented concepts, design of algo-
rithms, operating systems, systems program-
ming, databases, file management, and net-
works.5 Providing undergraduate education
in these topics would once again require 24 to
30 semester hours. This range of hours would
also be sufficient for CC2001’s core require-
ments and many of the requirements for com-
puter science courses (outside of SE) specified
in the criteria of the Computing Accreditation
Commission of the Accreditation Board for
Engineering and Technology.6 (ABET is the
accreditation body for engineering degree
programs in the US.) Therefore, it is reason-
able to assume that those same 24 to 30 com-
puter science hours would be sufficient in an
undergraduate SE curriculum.

As far as determining how many SE credit
hours are required, a typical master’s degree
requires at least 24 semester hours of gradu-
ate course work in the major (SE, in this
case). The question is, how does this trans-
late to undergraduate hours? One option is
to use a 3:2 ratio between undergraduate
and graduate hours, which is commonly
done in comparable courses in computer sci-
ence and other disciplines. So 24 graduate
hours would then translate to 36 undergrad-
uate hours. It is possible (although difficult)
to squeeze 24 to 30 hours of computer sci-
ence and 36 hours of SE into an undergrad-
uate SE curriculum. However, such compar-
isons are usually made using graduate
courses that build on undergraduate classes
in the same discipline, whereas a master’s de-
gree in SE requires little or no SE back-
ground when entering the program. There-
fore, 36 undergraduate SE hours might be
too many.

S e p t e m b e r / O c t o b e r  2 0 0 2 I E E E  S O F T W A R E 3 7

Many times,
adding core SE
courses in a

computer
science

program or
adding an SE

focus area will
address both

real and
perceived
demands.



The Guidelines for Software Engineering
Education suggests that an undergraduate
SE curriculum have 21 required hours of
computer science, 24 required hours of SE,
and nine hours of electives in either com-
puter science or SE. That model was in-
tended to satisfy CC2001 core computer sci-
ence requirements and ABET criteria for SE
undergraduate degree programs in the US. It
also aims to cover the same material typi-
cally found in an SE degree program, all in a
120-semester-hour, four-year curriculum,
which is generally the minimum requirement
for a baccalaureate program in the US. (It is
also interesting to note that virtually all of
the 25 most important topics for a software
professional cited in the Lethbridge survey—
including those in computer science and
SE—are also covered in the model from the
Guidelines report, even though the latter
was published first.) Such an SE curriculum
would provide minimally sufficient depth
for an SE major; allowing more than 120
hours (which is often the case for US engi-
neering programs) would provide even more
depth in computer science or SE.

Myth 4

A new SE degree will address industrial
software development crises.

A new SE degree program will not be a
panacea or a silver bullet. It will be one of the
first steps, albeit the most important step, to-
ward addressing industrial software develop-
ment crises, but we also must consider com-
plementary factors. For example, we need to
clearly define the “engineering education”
(the curricula and the style of presentation).
A starting point is understanding the objec-
tive of an engineering education as David
Parnas defines it.7 He argues that to provide
the most effective SE education, a new SE
program must follow the traditional engi-
neering approach to professional education
while maintaining the scientific basis of SE
(computer science). He emphasizes that an
engineering education should teach engineers 

� What is true and useful in their chosen
specialty

� How to apply the body of knowledge
� How to apply a broader area of knowl-

edge to build complete products that
must function in a real environment

(In a related article, Mary Shaw compares the
evolution of chemical engineering and civil en-
gineering with today’s SE. She uses her evolu-
tion model of engineering disciplines to iden-
tify the steps for enhancing the SE discipline.8)

Another important issue is that of defin-
ing an acceptable body of knowledge for
software engineers. The Software Engineer-
ing Body of Knowledge (SWEBOK) has
been an excellent starting point, but it has
certain deficiencies. One is its perceived
North American bias; such a guide must ob-
tain international acceptance. Yet another
criticism surrounds its certification and li-
censing implications. We must clearly ad-
dress such issues and invite other computing
associations to join SWEBOK’s development.

Furthermore, software engineers must be
able to apply the methods in different con-
texts and tune their knowledge to more effec-
tively use the new technologies. As Michael
McCracken has observed,9 academia cannot
predict the next popular language or method-
ology industry will use, so the education pro-
vided to software engineers must focus on the
fundamentals to prepare the new graduates to
assimilate and apply new technology quickly
and efficiently. A long-term aspiration would
be to identify distinct roles in SE and provide
appropriate education and specialized train-
ing for each.10

SE students (and education) must include
an element of training, not only during their
academic careers (for example, through in-
ternships) but once they enter the workforce
and before important design and implemen-
tation responsibilities are delegated to them.
This is not only true in other engineering 
disciplines but also in nonengineering disci-
plines. (For example, in the medical field,
new graduates go through at least two years
of training as part of their residency program
before they are allowed to engage in real
practice.) Steve McConnell and Leonard
Tripp suggest at least four years of appren-
ticeship for software engineers.11

In addition, there must be a paradigm
shift in attitude at the workplace. Existing
software development professionals and
managers must value and respect SE (and
computer science) education, acquaint them-
selves with the fundamentals and the body
of knowledge, and update their personnel
skills to avoid “cultural clashes” with new-
comers. Otherwise, new SE graduates will be

There must be a
paradigm shift
in attitude at 

the workplace.
Existing

software
development
professionals
and managers

must value 
and respect 

SE education.

3 8 I E E E  S O F T W A R E S e p t e m b e r / O c t o b e r  2 0 0 2



unsuccessful in transitioning their new body
of knowledge and will end up following un-
proven skills and the “code and fix” culture
that dominates the workplace.11

Certification and licensing are equally im-
portant. Although formal education is crucial,
a software engineer should also regularly (for
example, every five years) prepare for and
pass certification exams. This would assure
that he or she has maintained a minimum un-
derstanding of the SE body of knowledge.
Certification exams can then evolve into a
kind of licensing exam, similar to licensing in
other fields, to facilitate and assure profes-
sional competency and responsibility.

Myth 5

Computer science is to software engineering
what chemistry is to chemical engineering.

Another widely held misconception per-
tains to the relationship between computer
science and SE (which has been compared
with that of chemistry to chemical engineer-
ing or physics to mechanical engineering).
This is essential in understanding how edu-
cating software professionals differs from
educating computer scientists. 

This myth is tempting for SE faculty be-
cause it supports their contention that, over
time, computer science will become more
theoretical. In the long term, it will thus be
difficult to find (more) room for SE in com-
puter science curricula. The alternative then
is to also develop SE curricula, which can
focus more on the practical aspects of soft-
ware development while also including top-
ics such as software management, process,
and project organization throughout the
curriculum. 

It is true that computer science—itself a
relatively young field—has gradually ex-
panded both its theoretical and scientific
bases, and that this has caused an increase
in theory content in many computer science
curricula. However, physics and chemistry
are examples of physical sciences, whereas
software is a nonphysical entity. As such,
software (on a small scale, which is useful in
an educational setting) can be easily created
and duplicated. So, the development and
manipulation of software should continue
to be a central theme in computer science
curricula as well as in practice by computer
professionals. 

Myth 6
Software engineering graduates will not
need further training to perform like ex-
perienced software engineers.

Typical new SE graduates find themselves
working on teams where they are expected
to perform (with little or no additional
training) alongside experienced software en-
gineers. Organizations often assume that
new hires can internalize corporate culture
and standards on their own and acquire do-
main expertise on the job.

The new hires often find themselves on a
software project’s critical path. One reason
for this is that most corporate managers
think their new hires know the latest and
greatest methods and can handle more chal-
lenging assignments than some of the folks
who have been around for a while. Another
reason is that the new hire is often expected
to put in many extra hours and not to have
outside family obligations. A third reason is
that many software projects start out with
difficult schedules, and it is just not feasible
to give new staff members the time to gradu-
ally ramp up the learning curve. In Death
March, Ed Yourdon says, “To many grizzled
veterans... every project is a death march
project.”12 Tom DeMarco, in his book Slack,
says: “…a dangerous corporate delusion: the
idea that organizations are effective only to
the extent that all their workers are totally
and eternally busy.”13

Consider the following example: A new
hire joins a project in progress, replacing an-
other employee who has been transferred to
a different project. After a brief orientation,
he or she inherits the other employee’s work
and is expected to perform to the existing
schedule. After all, if the schedule for this
particular software isn’t met, the whole proj-
ect will fall behind. Furthermore, the other
team members are busy with their own work.
Although they will answer an occasional
question, they are quick to refer the new hire
to documentation or Web resources.

New employees on new projects don’t
fare much better. Faced with a death-march-
type plan, the new employee is given the
same workload as experienced employees.
Furthermore, new-hire salaries are suffi-
ciently high that experienced employees are
not that sympathetic to the new hire’s plight,
thinking to themselves, “When I started out,

S e p t e m b e r / O c t o b e r  2 0 0 2 I E E E  S O F T W A R E 3 9

Although formal
education 
is crucial, 
a software
engineer

should also
regularly 

(for example,
every five

years) prepare
for and pass
certification

exams.



I got a fifth of what these new hires are get-
ting, so they should pull their own weight.”

Whatever the reason, new graduates are
expected to perform on the same level as
their experienced counterparts. Everyone up
the line is under schedule pressure, and the
idea of an apprenticeship period is a foreign
concept in software development. The best
that the new employee can hope for is a
sympathetic, experienced mentor who will
coach him or her along.

Prospective employees must look for
those enlightened companies that can pro-
vide appropriate education and mentoring
for their staff, and companies must recog-
nize the need for apprenticeship and contin-
uing education. The fact that books such as
Death March and Slack exist and have a
large audience suggests that this will not be
an easy task.

Myth 7

Software engineering programs will corre-
spond to specific corporate requirements.

All you have to do is to look at current job
postings to see a list of specific languages and
tools, such as C, C++, Ada, UML, Visual Stu-
dio, XML, and ASP, along with the disclaimer
that no experience is required. To quote from
some recent newspaper classified ads: “Must
know C/C++,” “Must be familiar with Accel-
erated SAP,” and “Must have experience with
object-oriented programming in Java or
C++.” Searching the job site www.monster.
com, we found only one job description that
talked about developing software require-
ments, designing, coding, and testing, along
with using best engineering practices. We seem
to be stuck in a time warp that emphasizes
form over substance. There is no point in re-
quiring experience in specific languages and
tools—a software engineer can learn new lan-
guages and tools fairly readily, most of which
will change in five years anyway. On the other
hand, the education received on best engineer-
ing practices and techniques to support vari-
ous software life-cycle activities will benefit a
job candidate for a lifetime.

It would seem that many employers are still
looking for programmers who can produce
code in specific languages using specific tools
in the short term. They’re not looking for soft-
ware engineers who can develop software us-
ing best engineering practices with a long-term

view. This is because people in industry typi-
cally are looking for someone to start devel-
opment work immediately—they do not have
the time or interest to train their employees.
Furthermore, companies expect their employ-
ees to leave in a year or two, so they assume
they won’t benefit from the longer term SE
knowledge that the employee might have. The
events of recent years have supported this atti-
tude; SE staff expect to change jobs regularly,
in some cases for a healthy salary increase. So,
we have a vicious cycle: Software staff change
jobs regularly because companies make little
investment in employee retention, and compa-
nies make little investment in employee reten-
tion because software staff change their jobs
regularly. In fact, the company that invests in
employee training might find that the em-
ployee adds the newly acquired skill to his or
her resume to find a job. Another contributing
factor is that industry managers typically
started as programmers, with no SE back-
ground, so that is their frame of reference.
They want someone like themselves when they
were starting out. 

Companies also expect universities to use
particular programming languages and
tools in their curriculum, regardless of
whether these languages and tools are the
best vehicle to support the universities’ edu-
cation goals. If you query a software execu-
tive on his or her needs and how universities
can help to meet them, that executive’s first
reaction is to list languages and tools. Only
after some discussion does he or she move
beyond this low-level litany to focus on the
real education software engineers need.

H ow should we, as SE practitionersand educators, respond to thesemyths? First, remember that the
field is still young, so we can expect to see
diverse opinions on various issues. More-
over, education is not a panacea. We are not
going to cause SE to become a mature field
overnight by fielding relatively small num-
bers of SE degree programs.

We must foster stronger communication
between diverse groups, such as various fac-
ulty groups, and between universities and in-
dustry. Myths tend to develop when there is
little communication or when the communi-
cation that exists reflects our preconceived
notions rather than objective assessment.

The education
received on 

best engineering
practices and
techniques to

support various
software life-
cycle activities

will benefit a job
candidate for 

a lifetime.

4 0 I E E E  S O F T W A R E S e p t e m b e r / O c t o b e r  2 0 0 2



Universities and degree programs that have
industry advisory boards report valuable ex-
changes of information through this mecha-
nism. Faculty groups in different depart-
ments can also benefit from both informal
and formal communications opportunities.

We tend to lose sight of the fact that there
might not be a right or wrong approach to SE
education. There is ample opportunity to ex-
periment. We do not need to pigeonhole SE
education into one model or another just yet.
If we experiment and track our results, we will
learn what works over time. It is actually good
to have many different kinds of degree pro-
grams because they will allow the proper en-
vironment for experimentation and discovery.

So, maybe we just need to lighten up a
little when we consider SE education degree
programs, have fun developing and deliver-
ing these programs, and try to identify good
educational models that work. At the same
time, we need to figure out how to elicit in-
dustry feedback and incorporate it into de-
gree programs in appropriate ways. Only
then will SE reach the professional status it
so richly deserves. 

References
1. W. Gibbs, “Software’s Chronic Crisis,” Scientific Am.,

vol. 271, no. 3, Sept. 1994, pp. 86–95.
2. H. Lieberman and C. Fry, “Will Software Ever Work?”

Comm. ACM, vol. 44, no. 3, Mar 2001, pp. 122–124.
3. Computing Curricula 2001, ACM Special Interest

Group on Computer Science Education, 2001,
www.acm.org/sigs/sigcse/cc2001.

4. D. Bagert et al., Guidelines for Software Engineering
Education, Version 1.0., tech. report CMU/SEI-99-TR-
032, Software Eng. Inst., Carnegie Mellon Univ., Pitts-
burgh, Pa., 1999. 

5. T. Lethbridge, “What Knowledge Is Important to a
Software Professional?” Computer, vol. 33, no. 5, May
2000, pp. 44–50.

6. ABET, ABET Criteria for Accrediting Computing Pro-
grams, 2002, www.abet.org/criteria.html.

7. D. Parnas, “Software Engineering Programs Are Not
Computer Science Programs,” IEEE Software, vol. 16,
no. 6, Nov./Dec. 1999, pp. 19–30.

8. M. Shaw, “Prospect for an Engineering Discipline of
Software,” IEEE Software, vol. 7, no. 1, Jan./Feb.
1990, pp. 15–24.

9. M. McCracken, “Software Engineering Education:
What Academia Can Do,” IEEE Software, vol. 14, no.
6, Nov./Dec. 1997, pp. 26–29.

10. M. Shaw, “Software Engineering Education: A Roadmap,”
The Future of Software Engineering, A. Finkelstein, ed.,
ACM Press, New York, 2000, pp. 371–380.

11. S. McConnell and L. Tripp, “Professional Software En-
gineering: Fact or Fiction?” IEEE Software, vol. 16, no.
6, Nov./Dec. 1999, pp. 13–17.

12. E. Yourdon, Death March, Prentice Hall, Upper Saddle
River, N.J., 1997, p. 218.

13. T. DeMarco, Slack, Broadway Books, New York, 2001,
p. 226.

For more information on this or any other computing topic, please visit our
Digital Library at http://computer.org/publications/dlib.

S e p t e m b e r / O c t o b e r  2 0 0 2 I E E E  S O F T W A R E 4 1

About the Authors

Hossein Saiedian is a professor of software engineering and an associate chair in the De-
partment of Electrical Engineering and Computer Science at the University of Kansas. His primary
research area is software engineering—in particular, models for quality software development.
He is also interested in SE education and training and cochaired the ICSE’s Software Engineering
Education track for 2000 and 2001 (and will cochair it again for 2003). He received his PhD in
computer science from Kansas State University. He is a senior member of the IEEE and a member
of the IEEE Computer Society and ACM. He is chair of the IEEE-CS TCSE’s Committee on Software
Engineering Education. Contact him at the Dept. of EECS, Univ. of Kansas, Lawrence, KS, 66045;
saiedian@eecs.ku.edu.

Donald J. Bagert is a professor of computer science and software engineering at the Rose-
Hulman Institute of Technology, where he is also the director of software engineering. His re-
search interests include software process improvement, software tools for student advising, and
software methodologies. He received a PhD in computer science from Texas A&M University. He is
the steering committee chair for the IEEE Computer Society Conference on Software Engineering
Education and Training, and the Professional Issues Editor for FASE, an electronic newsletter de-
voted to software engineering education, training, and professional issues. He is also a member of
both the Educational Activities Board and the Professional Practices Committee for the IEEE Com-
puter Society, and is a senior member of the IEEE. Contact him at the Dept. of Computer Science
and Software Engineering, Campus Mail Box 97, Rose-Hulman Inst. Of Technology, 5500 Wabash Ave., Terre Haute, IN 47803;
don.bagert@rose-hulman.edu. 

Nancy R. Mead is the team leader for the Survivable Systems Engineering team as well as a
senior member of the technical staff in the Networked Systems Survivability Program at the Soft-
ware Engineering Institute. She is also a faculty member in the Master of Software Engineering and
Master of Information Systems Management programs at Carnegie Mellon University. She received
her PhD in mathematics from the Polytechnic Institute of New York, and a BA and an MS in mathe-
matics from New York University. She is a senior member of the IEEE and IEEE Computer Society and
is a member of the ACM. Contact her at the Software Engineering Inst., Carnegie Mellon Univ., Pitts-
burgh, PA 15213; nrm@sei.cmu.edu. 

Master software
with these future
topics:

IEEE

The Business of
Software Engineering

Model-Driven
Development

Managing Outsourced
Projects

Software Geriatrics

Visit us on the web at

http: / /computer.org/sof tware



4 2 I E E E  S O F T W A R E S e p t e m b e r / O c t o b e r  2 0 0 2 0 7 4 0 - 7 4 5 9 / 0 2 / $ 1 7 . 0 0  ©  2 0 0 2  I E E E

to define, measure, and analyze your own
processes.”1 The PSP adapts a continuous
improvement model to the specific needs of
an individual software developer who wants
to be more productive and produce higher
quality software. In particular, the PSP tar-
gets the process used to individually design
and develop software and incorporates ways
to measure and change the process to achieve
higher quality and increased efficiency.

Humphrey designed the complete PSP
process as a semester-long university course
for graduate students.1 A student or profes-
sional learning to integrate the PSP into his or
her process begins at Level 0 and progresses
in process maturity to Level 3 (see Figure 1).
During the course, each student accumulates
personal historical data to create estimates
and measure improvement. Each level incor-
porates new skills and techniques to improve
software quality into the student’s process

and has detailed scripts, checklists, and tem-
plates to guide the student through the re-
quired steps. The measurement-based feed-
back in the PSP helps each student improve
his or her own personal software process.
Thus, Humphrey encourages customization
of these scripts and templates as the students
use this feedback to understand their own
strengths and weaknesses. Students generally
observe significant quality improvements as
they progress through the four levels.2

Why teach the PSP?
The concepts that a graduating software

engineer should know are well defined in the
Stoneman version of the Guide to the Soft-
ware Engineering Body of Knowledge. 3 Of
the 10 areas defined in SWEBOK, the PSP
covers five: design, construction, testing,
process, and quality. During a PSP course,
students receive concrete experience in soft-

focus
Teaching PSP: Challenges
and Lessons Learned

Jürgen Börstler, Umeå University, Sweden

David Carrington, University of Queensland, Australia

Gregory W. Hislop, Drexel University

Susan Lisack, Purdue University

Keith Olson, Utah Valley State College

Laurie Williams, North Carolina State University

Software
engineering
educators must
provide educational
environments where
their students can
learn about the size
and complexity of
modern software
systems and the
techniques available
for managing the
difficulties
associated with
them.

W
atts Humphrey from the Software Engineering Institute at
Carnegie Mellon University developed the Personal Software
Process and first taught it as a graduate course at CMU in
1994. He says its goal is “to help you be a better software en-

gineer ... As you study and use [PSP’s techniques], you will soon know how 

educating software professionals



ware metrics, life cycles, quality, and process
improvement. The PSP lets students cover
these topics both in theory and in practice.

With the increasing complexity of soft-
ware projects, a growing emphasis exists on
process maturity as a means of providing a
quality product when time and budget con-
straints arise. The PSP provides a frame-
work for high maturity processes scaled for
an individual software engineer. Hence, it
provides a meaningful way to instill process
awareness in software engineers. Even if
students don’t use the PSP again, improving
and making them aware of their program-
ming habits will help them in their future
academic and professional careers.

With the recent rise in popularity of agile
software development methodologies4 (such
as Extreme Programming), some educators
might question the need to teach the PSP. Ag-
ile methods are highly incremental ap-
proaches that de-emphasize front-end analy-
sis, design, and documentation in favor of
communication and tacit knowledge transfer
through human communication. However,
Barry Boehm believes that both plan-driven
methodologies (such as the PSP) and agile
methodologies are important. “Both agile and
plan-driven methods have a home ground of
project characteristics in which each clearly
works best and where the other will have dif-
ficulties. Hybrid approaches that combine
both methods are feasible and necessary for
projects that combine a mix of agile and plan-
driven home ground characteristics.”5

Teaching options 
Depending on the environment, many

ways to teach the PSP exist. The PSP mate-
rial is quite extensive, so instructors might
need to tailor and customize it to meet the
needs of their class. We have identified three
primary factors that influence the teaching
of the PSP: course environment, coverage
level, and support tools.

A PSP course’s environment depends on
the target audience, course level, and subject
content. For professional software develop-
ers, teachers generally present the PSP in a
distinct course using Humphrey’s A Disci-
pline for Software Engineering.1 For stu-
dents in computing programs, educators
have tried integrating the PSP into almost
every type of course from first to fourth
year—as well as at the graduate level. Pub-

lished case studies show
that teaching the PSP can
be successful in any envi-
ronment, but they also
mention the difficult inte-
gration with first (CS1)
and second semester
(CS2) computing courses.
Those who do integrate
the PSP into CS1 often
use Humphrey’s An In-
troduction to the Per-
sonal Software Process.6

This shorter, easy-to-read
book is specifically intended for teaching
first-year students the basic principles of us-
ing disciplined software processes to pro-
duce high-quality software. In this article,
we refer to this text as PSP-lite.

Another factor to consider when teaching
the PSP is coverage of the material. In dedi-
cated PSP courses, teachers introduce its four
levels using 10 exercises that A Discipline for
Software Engineering describes.1 However,
when integrating the PSP with other course
topics, such a complete introduction is not
feasible. Humphrey recognizes this problem
and gives some suggestions for variations.1

However, all the proposed variations are still
staged introductions involving at least seven
assignments. Instead, some teachers intro-
duce just one specific (often slightly modi-
fied) PSP level and use it throughout the
course, making it possible to reduce the num-
ber of exercises. The PSP can also be inte-
grated into CS1 or CS2 using PSP-lite.

Having the proper tools to support the
tasks involved in PSP related activities is
also important. Manual data collection of-
ten leads to incomplete, inconsistent, or er-
roneous data sets. Many PSP studies men-
tion this observation and identify tool
support as an important issue. The instruc-
tor’s guide accompanying A Discipline for
Software Engineering provides spreadsheets
to calculate statistics.1 However, Philip
Johnson and Anne Disney identify the main
problem as student data collection, not
teacher data collection and manipulation.7

University experiences
Using the three factors, environment,

coverage, and tool support, Table 1 summa-
rizes our experiences teaching some PSP
variations at five universities.

S e p t e m b e r / O c t o b e r  2 0 0 2 I E E E  S O F T W A R E 4 3

Figure 1. The levels
of the Personal 
Software Process.

PSP3
Apply PSP2 iteratively

PSP2
Manage product quality

PSP1
Estimate using historical data

PSP0
Gather data on current process



Umeå University
Umeå University used the PSP to exem-

plify disciplined software development. To
minimize changes to the curriculum, we in-
tegrated certain basic PSP topics into two
existing courses: a second-year C++ course
and a second- or third-year software engi-
neering course.

For the C++ course, we developed an ex-
tra-lite version of the PSP to deliver an essen-
tial PSP lesson—namely, “plan, track, and re-
view what you did.” We introduced this
adaptation of PSP in two extra 45-minute lec-
tures and used it throughout all the exercises.
We felt three medium-size exercises, with one
or two weeks to complete each, were suffi-
cient to collect historical data for trend analy-
sis. We also provided a tool to support data
collection and minimize data errors. PSP use
was optional—only six of the 78 students
used it throughout the course. None of these
six students reported any perceived process
improvements during the course. For the re-
maining students, the main reason for aban-
doning the PSP was the feeling that it would
impose an excessively strict process on them
and that the extra work would not pay off.8

Similar experiences occurred in other courses
where PSP usage was optional. As a result, we
do not advise optional PSP use.

In the software engineering course, we
tried a different approach to familiarize stu-
dents with the PSP. This course combines a
group project and a theory track with lec-
tures and assignments. During the theory
track, we introduced the PSP as a bottom-up

approach to control software development,
using published case studies extensively to
show students that it was successful. During
the group project, students developed tools
to support data collection and trend analysis
for the PSP. This forced students to actively
acquire information about the PSP and its
usage. Examination results showed that this
teaching method helped the students under-
stand the problems that PSP can solve.

University of Utah
For many years, teachers at the Univer-

sity of Utah used PSP-lite to teach the PSP to
freshmen, integrating the material into both
CS1 and CS2 and giving approximately five
half-hour lectures on the material in each
class. CS1 covers PSP-lite’s second half,
which deals with defects (recording, reduc-
tion, prevention, and design–code reviews).
Students estimate, track, and analyze the de-
fects they remove from their programs. The
book’s first half, which focuses on resource
estimation and tracking, is taught in CS2,
where the students estimate, track, and ana-
lyze the time they spend on their programs
while continuing defect tracking and analy-
sis. Teachers provide students with reports
on class statistics and ask them detailed
questions about their own PSP data on ex-
ams. Neither the teaching staff nor the stu-
dents found integrating this material across
the two classes to be difficult. Students re-
ported that the knowledge gained on soft-
ware engineering principles greatly aided
them in obtaining summer internships.

4 4 I E E E  S O F T W A R E S e p t e m b e r / O c t o b e r  2 0 0 2

Table 1 
PSP results at five different universities

University Environment Coverage Tool support Comments

Umeå University 2nd-year C++ course Locally developed tool Optional usage was ineffective
2nd/3rd-year SE Modified PSP1 only Team project (developing a PSP tool); good learning

experience
University of Utah CS1/CS2 PSP-lite across Well received without much burden on students or

two courses Locally developed tool teaching staff
Senior SE Full PSP Students in pairs outperformed students working

individually
Purdue University CS1 only, PSP-lite Students felt the data collection for the PSP was too 

CS1/CS2, Used provided spreadsheets much for an introductory programming course
sophomores

Montana Tech CS1 PSP-lite Taught as an add-on to CS1, exercises not correlated; 
Marginal success

Junior CS/SE Full PSP Used provided spreadsheets Students resisted data collection at first, but were very
positive about the results at end of term 

Drexel University Graduate SE Full PSP through Standard forms Very good learning experience although somewhat
process course PSP2 labor intensive for instructor and students



Teachers taught the full PSP as well as a
customized form of it that included pair
programming during the last offering of a
senior software engineering class in 2000.
The university moved the software engi-
neering class to the sophomore year and
now relies on the PSP-lite taught in the
freshman year. The class was a formal ex-
periment to analyze the professed benefits
of pair programming; students experienced
even greater success when practicing pair
programming while following PSP’s prac-
tices.9 These students passed 15 percent
more black-box test cases and spent ap-
proximately half the elapsed time when
compared with students who worked alone
following the PSP. Additionally, the pairs
enjoyed themselves more, had higher confi-
dence in their work, and encouraged each
other to follow PSP practices.

Purdue University
Purdue University’s Department of Com-

puter Technology incorporated PSP materials
into its introductory programming courses on
two different occasions: once in the first
course only and once across the two-semester
sequence of introductory programming
courses. Students in these courses were pri-
marily sophomore computer information sys-
tem majors who had already taken several
courses to develop their computer literacy.

Faculty integrated the PSP-lite book and
activities into the existing programming
courses by covering half the book in each
course. Students collected the PSP data as
part of each weekly programming assign-
ment. Because other topics needed to be cov-
ered, teachers devoted a limited amount of
lecture time to discussing the PSP materials.

A course instructor checked the PSP data
occasionally to make sure students were
completing the activities correctly, and stu-
dents completed a brief questionnaire at the
course’s end to rate their attitude toward the
PSP. In general, the students viewed PSP ac-
tivities as extra work added to the regular
programming assignments and did not ap-
preciate the potential benefits of a disci-
plined process. Susan Lisack reported that
students made numerous errors on the PSP
forms, and expressed negative attitudes to-
ward the PSP on the course exit survey.10 In
short, students felt they were already busy
enough learning new language syntax and

the program development environment.
However, the students offered several

suggestions to improve future course offer-
ings. More automated tools would make it
easier to record the required data, especially
when more than one form needed the same
data. The instructor should review student
data early and provide immediate feedback
about recording errors so that the collected
data is meaningful. The instructor should
also present actual data from the class to il-
lustrate the PSP’s benefits. Most impor-
tantly, students strongly recommended plac-
ing the PSP topics in a later programming
course. Faculty responded by placing PSP
topics into a graduate-level course on soft-
ware processes and possibly including them
in an upper-level undergraduate software
methodologies course.

Montana Tech of the University of Montana
We also taught the PSP-lite and PSP in

courses at Montana Tech. Our best success
was with the full PSP, taught at the junior
level. All students had completed two courses
in data structures and algorithms and had a
high level of competency in programming.
The course met three days per week, and
used the A series of exercises in Humphrey’s
text.1 Student reaction was initially resistive,
but in the end, the course received excellent
student evaluations. The most common reac-
tion was the students feeling more aware of
their programming practices and shortcom-
ings after the course. Faculty did not attempt
to measure the students’ performance in sub-
sequent courses, but in senior exit interviews,
the students all stated that the course made
them more effective programmers.

Drexel University
The PSP continues to provide the focus for

a graduate course in process improvement of-
fered at Drexel University once or twice each
year since 1996. The students in the course
are masters students in both information sys-
tems and software engineering. The course
addresses the PSP as presented in A Discipline
for Software Engineering.1 Recently, the
course has also included some coverage of ag-
ile methodologies as a point of contrast.4

The course includes only seven PSP exer-
cises because Drexel operates on a quarter
term with 10 weeks of classes. This is suffi-
cient for students to try the PSP through Level

S e p t e m b e r / O c t o b e r  2 0 0 2 I E E E  S O F T W A R E 4 5

The most
common

reaction was
the students
feeling more

aware of their
programming
practices and
shortcomings.



2. Drexel faculty has used both the A and B
series of exercises, and has found that the B
series works much better for the information
systems students.1 Teachers use the standard
PSP forms and provide students with some
example spreadsheets to demonstrate various
PSP calculations such as regressions. Both in-
structors and students find the course work
labor-intensive, but manageable.

Students in this course have a wide range
of experience and programming ability.
They include people with only minimal
classroom programming experience, soft-
ware developers with extensive experience,
and managers who have not programmed in
many years. These varying perspectives help
enrich the discussion but also require the in-
structor to deal with each group’s different
problems approaching the PSP.

Overall results in teaching the PSP have
been excellent. The faculty members teach-
ing the course find it effective as a teaching
vehicle. Some students are initially resistant
to the PSP’s requirements, and instructors
have to be prepared to deal with these ob-
jections. However, by the course’s end, stu-
dents generally report that they found the
experience valuable, and several of them re-
port taking at least some PSP parts back to
their work environments.

Challenges for students
The PSP is less about mechanics and

more about instilling good habits and pro-
fessional attitudes. As such, learners
should apply PSP practices as a regular
part of their studies, not just in a single
course. Although widespread support is
preferred, few universities are able to pro-
vide reinforcement throughout the cur-
riculum because broad faculty support is
required.

While understanding the PSP’s mechan-
ics is relatively easy, developing an appre-
ciation for its goals and potential is much
harder. For students without industrial ex-
perience, understanding the problems of
large-scale, team-based software develop-
ment is difficult. Student programs tend to
be small and short-lived. Students experi-
ence neither the problems of post-release
defects nor the value of high-quality soft-
ware in production operation.

Students with industrial experience can
have different problems. They usually

have first-hand experience with the key
problems the PSP addresses. They under-
stand why solving these problems would
be good, but often they do not see the PSP
as a workable solution. Many experienced
students have ingrained programming
habits and imagine that the PSP adds ad-
ministrative overhead. Until they see the
benefit for themselves, they can be resist-
ant to it. In addition, these students might
believe that a different way of working is
impossible because managers will not sup-
port PSP practices.

Experienced or inexperienced students
could also miss the PSP’s value if they are
unwilling to make a serious effort to try it.
Students who simply do the minimum
amount of work to get through the course
are unlikely to gain any appreciation of the
potential value that the PSP has for them
personally as working software engineers.

Many universities teach software engi-
neering practices that industry does not
widely practice. This presents a particular
problem for students when they move
into the workplace. The typical situation
is that a student joins a software develop-
ment organization that neither knows
about nor accepts and applies practices
such as the PSP. Most students in this sit-
uation are likely to mold themselves to
the local culture rather than using prac-
tices that their peers and managers might
not respect. 

Challenges and suggestions for
teachers

With the rapid advances in computing
technology, fitting the PSP into an already
crowded curriculum is a continual prob-
lem for teachers. Universities are under
increasing pressure to produce students
with in-depth knowledge of the latest
technologies for an industry with a
chronic shortage of technical people. The
mechanics of the introductory PSP are
well within the reach of most students, al-
though there is a need to devote teaching
time to the PSP. The requirement for ap-
plication of basic regression and correla-
tion makes the full PSP difficult for first
year undergraduates. However, it is rea-
sonable to teach basic PSP processes in
the early years, and then address topics
requiring statistics in the later years.

While
understanding

the PSP’s
mechanics is

relatively easy,
developing an
appreciation
for its goals 

and potential is
much harder.

4 6 I E E E  S O F T W A R E S e p t e m b e r / O c t o b e r  2 0 0 2



Based on our experiences, we offer some
guidance and advice to teachers interested
in introducing the PSP. 

Student motivation
Motivating students about the PSP’s bene-

fits is essential. Students enter a university with
a predisposition toward coding without de-
signing, and they do not see the data collection
required for the PSP as enjoyable or useful.
Teachers must overcome students’ limited
knowledge of commercial-scale software de-
velopment and the work environment, and
provide them with an appreciation for PSP’s
data collection, analysis, and measurement-
based feedback. Introducing the PSP early
may help students form good software habits,
but teaching programming and the PSP simul-
taneously might cause cognitive overload for
students.

The first half of PSP-lite deals with time
recording, effort estimation, and commit-
ment making, while the second half deals
with defect reduction, prevention, and
recording. Through the eyes of a beginning
software engineering student, the material on
defects in the book’s second half seems more
relevant. Even after just one program, many
students have experienced the frustration of
losing several hours to a small syntax or se-
mantic error. They are motivated to reduce
the frustration of defect elimination and are
receptive to learning how to control their de-
fects and minimize the amount of time spent
debugging. We suggest that educators teach
the material on defects prior to the material
involving time recording.

Students are also more motivated to learn
the PSP’s lessons if the instructor can share
stories of how previous students fared much
better in job interviews because of their PSP
background. Employers are impressed with
students who can intelligently discuss the PSP
and the principles it emphasizes. 

Integration and adaptation
We have seen greater long-term success

instilling the lessons of high-quality soft-
ware development when teachers integrate
the material across the curriculum.11 Inte-
gration generally requires a commitment
from multiple faculty members. It is not es-
sential that these other faculty members in-
spect the students’ time and defect logs, but
these instructors can support the PSP’s les-

sons by asking students to estimate, track,
and report their PSP data.

A teacher’s ability to adapt the PSP to the
needs of their students is also important. Al-
though it makes sense for experienced soft-
ware engineers to develop the early PSP exer-
cises in a waterfall-style process, this is
normally not true for undergraduates who
lack the programming experience to design
and code even a small program in one itera-
tion. Early on, teachers should show such
students how to plan and perform multiple
iterations. However, students should be dis-
couraged from the practice of design-code-
compile-test cycles at the single statement
level. Apart from the practical problems of
recording process data for such fine-grained
iterations, such practices do not scale up to
industrial-scale software development.

Dealing with data
The PSP lets students collect their own

data to show how they’ve improved as they
use better software engineering practices.
When teachers reduce the number of exer-
cises, students cannot see this progress as
clearly because of a lack of data. Using pub-
lished PSP data from other PSP users to talk
about the PSP is possible, but it rarely has
the same impact. The power of the PSP is
when students realize that it works for them
by seeing their own work improve.

Teachers must be able to process and
present class data in a meaningful way. Stu-
dents appreciate seeing aggregate class re-
sults on time estimation versus actual time
spent (minimum, maximum, and average).
They also like to see class quality trends (de-
fects per KLOC) as they learn and apply
new programming and quality techniques.
To satisfy this desire for feedback, teachers
need mechanisms for reliably and efficiently
collecting PSP data from students and con-
verting it into presentations. Ideally, these
mechanisms would also let teachers provide
individual feedback where appropriate and
check the authenticity and validity of stu-
dent data. Several tools are now available to
support student data collection and analy-
sis—for example, LEAP (http://csdl.ics.
hawaii.edu/Tools/LEAP/LEAP.html) and the
Process Dashboard (http://processdash.
sourceforge.net). The challenge is to have
tools that are convenient to use and don’t
distract from the work itself.

S e p t e m b e r / O c t o b e r  2 0 0 2 I E E E  S O F T W A R E 4 7



Teachers must also be conscious of the po-
tential for misuse of PSP data. If students ever
believe that this data is being used for grading
purposes, they are likely to manipulate the val-
ues in an attempt to gain better grades. Stu-
dents starting to use PSP often feel that there
are ideal or target values that they should aim
for. Teachers need to make it clear that the ac-
tivities of collecting and analyzing the data are
important, not the particular values.

We hope our experiences and exper-iments teaching the PSP provideguidance and advice for others in-
terested in introducing the PSP into their
software engineering courses. We continue
to use elements of the PSP in our teaching
because we believe that it is one of the few
coherent and explicit approaches for teach-
ing students about effective software engi-
neering practices for developing high quality
software. As with the PSP itself, the quanti-
tative feedback available from teaching the
PSP allows teachers to base their improve-
ments on data, not just perceptions. 

Acknowledgments
This article is an outcome of the presentations and

discussions presented at a workshop on teaching the
PSP in universities held 20 February 2001 at the Con-
ference on Software Engineering Education and Train-
ing (CSEE&T) in Charlotte, North Carolina (see
www.spsu.edu/oce/cseet2001/registration.htm).

References
1. W.S. Humphrey, A Discipline for Software Engineering,

Addison-Wesley, Boston, 1995.
2. A. Wesslén, “A Replicated Empirical Study of the Im-

pact of the Methods in the PSP on Individual Engi-
neers,” Empirical Software Eng., vol. 5, no. 2, June
2000, pp. 93–123.

3 A. Abran et al., Guide to the Software Engineering
Body of Knowledge: Trial Version, IEEE CS Press, Los
Alamitos, Calif., 2001.

4. A. Cockburn, Agile Software Development, Addison-
Wesley, Boston, 2002.

5. B. Boehm, “Get Ready for Agile Methods, with Care,”
Computer, vol. 35, no. 1, Jan. 2002, pp. 64–69.

6. W.S. Humphrey, An Introduction to the Personal Soft-
ware Process, Addison-Wesley, Boston, 1997.

7. P. Johnson and A. Disney, “A Critical Analysis of PSP
Data Quality: Results from a Case Study,” Empirical
Software Eng., vol. 4, no. 4, Dec. 1999, pp. 317–349.

8. S. Olofsson, Evaluation of the PSP in the Undergradu-
ate Education, tech. report UMNAD 272.99, Dept. of
Computing Science, Umeå Univ., Sweden, 1999.

9. L. Williams and R. Kessler, “Experimenting with Indus-
try’s Pair Programming Model in the Computer Science
Classroom,” Computer Science Education, vol. 11, no.

1, Mar. 2001, pp. 7–20.
10. S. Lisack, “The Personal Software Process in the Class-

room: Student Reactions,” Proc. 13th Conf. Software
Eng., Education, and Training, IEEE CS Press, Los
Alamitos, Calif., 2000, pp. 169–175.

11. M. Towhidnejad and T. Hilburn, “Integrating the Per-
sonal Software Process (PSP) across the Undergraduate
Curriculum,” Proc. 27th Frontiers in Education Conf.,
IEEE Press, Piscataway, N.J., 1997, pp. 162–168.

For more information on this or any other computing topic, please visit our
Digital Library at http://computer.org/publications/dlib.

Jürgen Börstler is an associate professor of computer science at Umeå University, where
he leads the software engineering and computer science education groups. Contact him at De-
partment of Computing Science, Umeå University, SE-901 87 Umeå, Sweden; jubo@
cs.umu.se.

4 8 I E E E  S O F T W A R E S e p t e m b e r / O c t o b e r  2 0 0 2

About the Authors

David Carrington is a reader in the School of Information Technology and Electrical
Engineering at the University of Queensland, Australia, where he is the program director for
the software engineering program. His research interests include software engineering
processes, methods and tools, and software engineering education. Carrington is also a visiting
scientist with the Software Engineering Institute at Carnegie Mellon University. Contact him at
davec@itee.uq.edu.au.

Gregory W. Hislop is an associate dean and faculty member of the College of Informa-
tion Science and Technology at Drexel University, where he coordinates the college’s software
engineering and information systems programs. He has nearly 20 years industrial experience
in software engineering and enterprise systems management. Contact him at 
hislop@drexel.edu.

Susan Lisack is an assistant professor in the Computer Technology Department at Pur-
due University, with interests in the areas of programming and databases. She holds certifica-
tion as an Oracle8i Certified Database Administrator and also coordinates the departmental 
cooperative education program. Contact her at sklisack@tech.purdue.edu.

Keith Olson teaches at Utah Valley State College in Orem, Utah, where he coordinates
the software engineering program for the Department of Computing and Networking Sciences.
His principal research interests are in software processes and estimation. Contact him at 
olsonke@uvsc.edu. 

Laurie Williams is an assistant professor of computer science at North Carolina State
University.  She received her undergraduate degree in industrial engineering from Lehigh Uni-
versity. She also received an MBA from Duke University and a PhD in computer science from
the University of Utah. Her research interests include software development process, software
testing and reliability, software security, and Ecommerce. Contact her at
williams@csc.ncsu.edu.



focuseducating software professionals

0 7 4 0 - 7 4 5 9 / 0 2 / $ 1 7 . 0 0  ©  2 0 0 2  I E E E S e p t e m b e r / O c t o b e r  2 0 0 2 I E E E  S O F T W A R E 4 9

CS and applied CS curricula with opportu-
nities to practice SE concepts and principles,
we support an SE apprenticeship, simulated
through system development projects.

In this article, we examine the prevailing
SE body of knowledge and perspectives on
SE education to construct a model comprised
of knowledge areas for SE professional de-
velopment. We use this model and Benjamin
Bloom’s taxonomy1 to delineate knowledge
areas that an apprenticeship could best han-
dle. We then establish a framework for SE
apprenticeship, which we use to examine
practices for apprenticeship simulations in
three academic institutions that offer CS, ap-
plied CS, or computing systems curricula.

Body of knowledge
What knowledge does a software engineer

require for professional development? We
addressed this question by constructing an

SE professional development model, which
classifies knowledge areas into four cate-
gories: core, support, foundation, and con-
text (see Figure 1). This type of multitiered
architecture can help model the distribution
of SE professional development responsibili-
ties between academia and industry.

Knowledge areas
We used several KA sources in our devel-

opment model. The Software Engineering
Body of Knowledge, prototyped in the tech-
nical report by Thomas Hilburn and his col-
leagues2 and detailed in the Guide to the
Software Engineering Body of Knowledge
(SWEBOK),3 contains 10 software KAs: re-
quirements, design, construction, testing,
maintenance, configuration management,
management, process, tools and methods,
and quality. Each of these have numerous
topics and subtopics. 

Simulating a Software
Engineering
Apprenticeship

Ken Surendran and Helen Hays, Southeast Missouri State University

Andrew Macfarlane, QCOM

A framework 
for a software
engineering
apprenticeship and
an enriched model
for SE professional
development will
help establish 
steps for attaining
software
engineering
professional status.
The current practice
of industry-
sponsored projects
in coursework 
and internships is
insufficient.

A
lthough some professions require a period of internship, resi-
dency, or apprenticeship before marking an individual as a qual-
ified member, software engineering does not. Universities have
started offering curricula in SE, and many continue to offer SE as

a set of courses in their computer science curricula. Because the global de-
mand for software engineers far exceeds the supply of SE graduates, CS and
applied CS graduates frequently fill this gap. So, to enrich SE courses in the



A difficult thing
to achieve in a
curriculum is
realism—real

products
signifying
tangible,
relevant

achievements
and real people

signifying
collaborative

effort. 

Hilburn and SWEBOK also list KAs from
related disciplines: CS, mathematics, project
management, computer engineering, sys-
tems engineering, management and man-
agement science, and cognitive sciences and
human factors. 

Bertrand Meyer lists goals for a software
curriculum:4

� Principles—recurring concepts such as
recursion and debugging

� Practices—practical techniques such as
user interfaces and metrics

� Applications—traditional software do-
mains such as operating systems and
compilers

� Tools—such as industrial strength pro-
gramming languages

� Mathematics

Barry Boehm and his colleagues list,
aside from CS, three other underlying sci-
ences for SE: domain science, behavioral
sciences, and economics.5

Development model
In Figure 1, the core category comprises

the first five traditional waterfall model
KAs from SWEBOK. The support category
includes SWEBOK’s configuration, quality,
and methods and tools KAs and two topics
from its software engineering management
KA: project management and metrics. We
consider formal methods part of the meth-
ods and tools KA. The foundation category
contains underlying KAs from CS, mathe-
matics, and traditional generic software
domains.4

The context category includes four com-
ponents drawn primarily from Boehm and
his colleagues:5

� SE process deals with organizational,
team, and individual development (in-
cluding SWEBOK’s process KA).

� Practice deals with producing and oper-
ating software products under society’s
prevailing legal and ethical norms.

� Economics concerns the software prod-
ucts’ value realization in a business con-
text.

� Scope comprises the application domain
context from which the inspiration for
new and refined software products
emerges.

Two types of application domains exist:
generic software (such as database, artificial
intelligence, compiler, and operating sys-
tems) and field-specific software (such as
business information, bioinformatics, and
entertainment), which can heavily depend
on generic software. We include the generic
software application domains in the foun-
dation category and the field-specific ones
in the context category.

Knowledge elements
The idea of a software engineering appren-

ticeship (SEA) is not new. For instance, James
Bach and W. Michael McCracken discuss ap-
prenticeship and what an academic education
can and should offer future SE practitioners.6

However, considerable diversity exists among
opportunities for practical experience at uni-
versities, and not many universities have a
formal SEA component built into their curric-
ula. As we propose a standard SEA frame-
work, we examine the model in Figure 1 to
identify appropriate knowledge and the mas-
tery levels that we expect students to achieve.
We then define the mastery levels in terms of
Bloom’s taxonomy, which helps classify cog-
nitive educational goals. We list the progres-
sive mastery levels of Bloom’s taxonomy and
expected behaviors:

� Knowledge requires recognizing or re-
calling ideas

� Comprehension requires rearranging,
interpreting, and extrapolating ideas

� Application requires restructuring a
problem and selecting and using appro-
priate ideas to solve the problem

� Analysis requires breaking down mate-
rial and classifying its elements, identi-
fying relationships between elements,
and recognizing the whole’s organiza-
tional structure

� Synthesis requires combining elements
into a new structure

� Evaluation requires making criteria-
based judgments about the works’ inter-
nal quality and usefulness for achieving
desired ends

The KA experts who contributed to SWE-
BOK provided mappings from eight of the
KAs and associated topics to the six levels of
Bloom’s taxonomy, indicating for each topic
the mastery level expected of a graduate with

5 0 I E E E  S O F T W A R E S e p t e m b e r / O c t o b e r  2 0 0 2



four years’ SE experience.
(Ratings are omitted for the
construction and mainte-
nance KAs.) The SWEBOK
mappings generally classify
processes and concepts
(such as the requirements
engineering process, general
design, and SE process) at
the knowledge and compre-
hension levels. This is con-
sistent with the progressive
nature of Bloom’s taxon-
omy, in which the higher
levels build on and incorpo-
rate lower levels. SWEBOK
generally places activities
performed by analysts, pro-
grammers, and low-level
managers (such as software
design notations, test levels,
and personnel manage-
ment) at the application or analysis level. Ac-
tivities performed by quality assurance spe-
cialists and higher-level managers (such as
common planning activities and measurement
applied to quality assurance) are generally
placed at the synthesis or evaluation level. 

To develop a framework for the SEA, we
must determine what mastery levels stu-
dents can attain through coursework in the
CS-SE curriculum, in the SEA, or during the
first four years of work experience after
graduation.

Generally, students will achieve knowl-
edge and comprehension levels through
coursework. This includes the foundation
category in Figure 1 and underlying methods
and concepts for the remaining categories. 

The SEA will concentrate mainly on analy-
sis and application levels for the core and sup-
port categories in Figure 1. The apprenticeship
will also require comprehension of a particu-
lar application domain (“SE scope” within the
context category). To some extent, we can ap-
ply concepts from other components of the
context category in the SEA: process (the Per-
sonal Software Process), economics (feasibility
studies), and practice (ethics).

The SE professional will acquire higher
mastery levels through work experience
with large-scale, real-world problems after
graduation. As Bach and McCracken point
out, prior to graduation, students are inten-
tionally exposed to a broad set of topics in

an academic program, but depth is acquired
from experience. 

Framework
An apprenticeship program extends the

academic curriculum. A difficult thing 
to achieve in a curriculum is realism6—
real products signifying tangible, relevant
achievements and real people signifying
collaborative effort. So, an apprenticeship
program tries to provide opportunities to
start practicing the profession under super-
vision and guidance in an industrial setting. 

In the ideal SEA, a mentor in the industry
plays a critical role in guiding the appren-
tice’s professional development by assigning
different area supervisors, each charged with
giving the apprentice specific tasks and
closely monitoring progress in that area. The
SEA should emphasize honing skills to
achieve application and analysis mastery lev-
els in the core and support category KAs
(Figure 1). The apprenticeship should also let
the individual explore various possible roles
to help plan a professional specialization.
Furthermore, mechanisms must be built into
the program to measure accomplishments.
These elements lead to a three-dimensional
framework for an SEA (see Figure 2) with
practice, role, and evaluation as its axes. 

Practice
The practice axis addresses mastery of

S e p t e m b e r / O c t o b e r  2 0 0 2 I E E E  S O F T W A R E 5 1

SE process
(Professional development context)

SE practice
(Society context)

SE economics 
(Business context)

SE scope
 (Application domain context)

 

SE project management
SE methods and tools

Software configuration management
Software quality management

SE metrics

Support
category

Foundation
category

Context category

Mathematical foundations,
algorithms and data structures,

computer architecture,
programming language, generic software

Software
requirements

Software 
design

Software
construction

Software
testing

Software
maintenance

Core category

Figure 1. A software
engineering (SE) 
professional 
development model.



the core and support categories in Figure 1.
We apply a chronological order often used
for new employees, in which they are first
exposed to best practices in legacy systems
by working on maintenance projects and
gradually progress through those areas that
require analysis mastery. (We suggest this
order for the apprenticeship, not for the ini-
tial introduction of concepts in course-
work.) One of the authors, while serving in
a company as a mentor for summer interns,
tried the suggested development order and
found it effective for training purposes, with
the following advantages: Starting with
maintenance tasks (involving coding) in a
system with well-written documentation
and high-quality implementation will make
the task easier. Additionally, this order
stresses the efficacy of good SE practice and
sets the tone for the quality of work ex-
pected when the apprentice moves on to de-
veloping a new system. Because undetected
errors in the earlier stages of the software
development life cycle are more costly to
correct than those discovered later, the re-
verse-order exposure should minimize risks
when using novices. So, acquiring imple-
mentation skills takes precedence over de-
sign, and design over analysis. 

The apprentice program has modest in-
tentions and does not aim to develop the ap-
prentice into a systems architect by the pro-

gram’s end. However, the apprentice should
get opportunities to examine system archi-
tectures that are already in place (to under-
stand the rationale behind the choices
made) and to apply the concept of reuse (to
use frameworks). The program should ex-
pose the apprentice to at least one field-spe-
cific application domain during analysis.
Testing requires experience in all core skills
to carry out the integration and system-level
tests. Testing here should include preparing
specifications and test cases, as well as using
those prepared by others. Getting involved
in the various review activities in product
development is important. Because review is
an evaluative process, the program ad-
dresses it at the end.

Role
Items on the role axis parallel the practice

axis and indicate the roles the apprentice
will fill when performing the various prac-
tice items. Whereas practice helps hone the
hard skills needed in the core and support
categories, the roles (which involve profes-
sional relationships) provide opportunities
to develop soft skills (also called value
skills7). We use common names for roles and
order them to match with the practice ele-
ments. Soft skills requirements also increase
as the apprentice progresses from program-
mer to analyst. When you discover an ap-

5 2 I E E E  S O F T W A R E S e p t e m b e r / O c t o b e r  2 0 0 2

Maintain

Implement

Design

Analysis

Test

Review

Programmer

Designer

Analyst

Project Assistant

Activity log

Performance analysis by supervisor

System artifacts

Progress reports

Internal customer feedback

Overall performance evaluation by mentor

Organizational

Journal writing

Individual Planning process

Quality management

Role Practice 

Evaluation
Figure 2. The 
framework for a 
software engineering
apprenticeship.



prentice with higher potential, you could
give additional higher-level responsibilities
(such as active participation in review
processes) to develop integrative and evalua-
tive skills. The apprentice should work on
different projects (or at least different sub-
systems of a project) under different roles.
As a project assistant, the apprentice can get
an integrated view of product development
activities (especially supportive ones) and
can start appreciating the importance of del-
egation, value of metrics, and rationale for
business-driven decision making.

Evaluation
On the evaluation axis, we suggest two

types of mechanisms: individual and organi-
zational. On the left side of the axis (see Fig-
ure 2), individual evaluation components in-
clude PSP (Personal Software Process)8

mechanisms for professional development.
We consider two of these—planning and
quality—essential because they help develop
estimation and reviewing skills. Keeping a
personal journal helps the apprentice note
lessons learned and important observations
pertaining to ethics, quality, standards, and
metrics. On the right side of the axis, the or-
ganizational mechanisms are for formal
evaluation of the apprentice’s performance.
Although the overall performance evalua-
tion lies with the mentor, a portfolio of evi-
dence is built over the apprenticeship. This
evidence consists of various supervisors’ ob-
servations and assessments, which are, in
turn, based on feedback from team members
and internal customers and on the system ar-
tifacts the apprentice produced. The pro-
gram logs all activities to assess productivity
determination, quality awareness, and stan-
dards adherence. The weekly progress report
lists accomplishments, lapses, and plans of
remedial actions in a formal document. The
apprentice consolidates these progress re-
ports into a final report containing a list of
achievements, improvement in work quality,
familiarity with metrics, observations per-
taining to ethical and legal issues, and iden-
tified areas for further improvement. 

SEA criteria
An ideal apprenticeship program would

require an additional year of practicum fol-
lowing the usual CS-SE four-year program.
This would help instill best practices in the

application of KAs in the core and support
categories for realistic product develop-
ment, in the application of instruments for
evaluating and managing professional de-
velopment, and in the delivery of value-rich,
quality products. You could use the SEA cri-
teria in Figure 3 to measure the value of an
apprenticeship program.

Simulation
Using the assessment criteria in Figure 3,

we examine three academic programs that of-
fer project-based SE courses. Additionally, we
suggest a coordinated internship program.

Three programs
The first program (Prog-1), at a Midwest-

ern US state university, has a two-semester
sequence of SE courses. The first course em-
phasizes systems analysis and design, and
students work in teams on a project pro-
vided by the instructor. Both CS and MIS
students attend this course, and teams con-
tain a mix of students from the two pro-
grams. The second course emphasizes the
Rational Unified Process and project man-
agement, and student teams (of five to six
members) apply RUP to develop a client-
sponsored project. Some clients are internal
to the university; for example, one team,
working for a professor of communication
disorders, developed an expert system for di-
agnosing and recommending treatment for
speech articulation disorders. Other clients
are from business and industry. For example,
one team developed and installed a purchase
order management system for a small local
industry that manufactures radiators.

The second program (Prog-2), at an insti-
tution of technology in New Zealand, has a
two-semester sequence of systems analysis
and design courses and a project manage-
ment course, followed by a double-credit,
one-semester capstone project course. In the
capstone course, students work in teams of
two to find (with the assistance of faculty or
an advisory board), propose, and develop a
client-sponsored project, including all stan-
dard system artifacts. For example, one
team worked closely with a software house
to produce a Web-based change manage-
ment system.

The third program (Prog-3),9 at a Mid-
western US institution of technology, has a
two-quarter SE course followed by a two-

S e p t e m b e r / O c t o b e r  2 0 0 2 I E E E  S O F T W A R E 5 3

An ideal
apprenticeship
program would

require an
additional year
of practicum
following the
usual CS-SE
four-year
program. 



quarter capstone system development proj-
ect. In the SE courses, students work on
client-sponsored projects and generally pro-
duce prototype systems. For example, the
State Supreme Court sponsored a project for
administering continuing education for reg-
istered lawyers. For the capstone project,
students work in teams of four to five mem-
bers on a project that an external client must
sponsor. For example, one team, working
for a pharmaceutical company, developed a
scheduling system for manufacturing antibi-
otics and integrated it into the company’s
spreadsheet system. Another team, working
for a printer manufacturer, produced a pro-
totype 3D workbench program for designing
an optical system of lenses and mirrors.

Simulation evaluation
Table 1 evaluates the three programs us-

ing the SEA criteria in Figure 3. 
The first two programs provide a safer

approach in that the client-sponsored proj-
ect is assigned for the capstone course after
the students gain experience with an in-
course project. However, the third program
(Prog-3) offers the greatest potential for
simulating the SEA because it uses client-
sponsored projects both for in-course and
capstone purposes. Also, due to the univer-
sity’s location and nature, a wider variety of
projects from large companies is available.

Although such client-sponsored projects
can simulate quite a few SEA criteria, they
lack the depth required in dealing with real-
world, large-scale projects. For example, they
do not provide opportunities to work on
legacy systems (Criterion 1.1), and individu-
als can assume only a few critical roles re-
quired in the core category. Although a few

curricula10 are built around the PSP and seem
to address individuals’ quality improvement
(Criterion 2.3), simple client-sponsored proj-
ects do not simulate them. Moreover, these
projects totally fail to simulate some of the
criteria pertaining to the context category
KAs (particularly, the process and practice)
and partially fail to simulate a few in the
support category (metrics and quality). Stu-
dents will get only limited experience in qual-
ity assurance (Criterion 1.4) because only a
few of them will perform the integration and
system testing. In the project courses, most of
the feedback is for the whole group, so the
individual doesn’t get a detailed appraisal,
and Criterion 2.4 is not met.

Coordinated internships and co-ops
Project-based courses are a necessary com-

ponent of the SE curriculum, but they do not
provide the full apprenticeship experience
needed to prepare highly qualified SE profes-
sionals. An additional experience that you
can provide during a student’s undergraduate
education is an internship or co-op. The cur-
rent practice is for industry to hire students
as interns (for example, for a summer) or co-
ops (for example, for a period of six months).
You can enhance these experiences by coop-
eration between industry and academia.

Internships and co-ops do not always ad-
dress students’ specific professional training
requirements. However, programs coordi-
nated by academic advisors might address
some of the weaknesses identified in the SEA
simulation (Criteria 1.1, 1.4, 2.3, and 2.4)
and so enhance the students’ practical expe-
rience. For selected outstanding students,
faculty advisors could plan and facilitate ap-
propriate work experience. A preliminary

5 4 I E E E  S O F T W A R E S e p t e m b e r / O c t o b e r  2 0 0 2

1. Assures application and analysis mastery of core and support knowledge areas (KAs):
1.1 Exposes the apprentice to the best products (all system artifacts)
1.2 Requires the apprentice to use best practices in product development
1.3 Involves the apprentice in dealing with internal and external customers (information gathering, 

documentation, and presentations)
1.4 Assigns quality assurance tasks to the apprentice (test specification, test case preparation, and test log)
1.5 Involves the apprentice in formal review processes in product development
1.6 Exposes the apprentice to scaling up from smaller- to larger-sized projects

2. Assures application mastery of context KAs:
2.1 Coaches the apprentice in the development of interpersonal skills
2.2 Involves the apprentice in value judgment exercises (economic feasibility)
2.3 Exposes the apprentice to processes and tools (such as the CMM and ISO) used for continuous 

quality improvement
2.4 Measures apprentice performance periodically (strengths, weaknesses, and plans for improvement)

Figure 3. The 
criteria for an ideal 
software engineering 
apprenticeship.



discussion with a company that maintains
CMM Level 5 indicated that it’s possible to
maintain a dialog between an industry men-
tor and a student’s advisor (in the academic
institution) to plan the broad learning objec-
tives the student should achieve in the in-
ternship and co-op programs. The discus-
sion also indicated that most of the aspects
listed as measures for the SEA are possible
and that the apprentice could achieve many
of them over a one-year period.

A lthough the client-sponsored proj-ects we describe in this article meetmany of the SE professional’s devel-
opment needs, we also note their limitations.
However, such projects’ benefits outweigh
the costs, both for the student and the client
organization. The student benefits from
client-sponsored projects by gaining real-
world experience. The only cost to the client
organization in sponsoring a project is the
time the project sponsor spends in commu-
nicating requirements, reviewing specifica-
tions, and evaluating the final product. (At
times, the cost might also include equipment

and software licenses.) The client organiza-
tion benefits by acquiring a working system
or a prototype. A possible mutual benefit oc-
curs when the student gains employment in
the organization after graduation. 

Additionally, the coordinated internship
and co-op programs address some of the lim-
itations of using client-sponsored projects in
the capstone course. Greater levels of acade-
mia-industry partnerships help ease the stu-
dent’s transition to professional. In the co-ops
and internships, the faculty advisor can act as
a mentor. When options exist, the advisor
guides the student in choosing an option with
greater scope for skills enhancement. The cost
to industry includes the student’s stipend,
training overhead, and any additional time
for interaction with the academic advisor. The
usual benefits are in having a potential pool
of skilled future employees to choose from
and reduction in orientation time. Addition-
ally, if the student’s internship or co-op is co-
ordinated with the academic advisor, the fu-
ture employees should have the advantage of
a more complete, broad-based experience.

The client-sponsored projects and man-
aged internships together can serve as an al-

S e p t e m b e r / O c t o b e r  2 0 0 2 I E E E  S O F T W A R E 5 5

Table 1 
Simulation evaluation of three academic programs

SEA 
criteria Prog-1 Prog-2 Prog-3

1.1 No legacy system exposure No legacy system exposure No legacy system exposure
1.2 Rational Unified Process deliverables  Standard artifacts produced  Standard artifacts produced both in two SE 

produced to extent possible within time frame to extent possible within time frame courses and a two-quarter capstone course
(in a single software engineering course) (double-credit capstone course)

1.3 Internal clients for some teams’ External clients, mainly small- and Clients in both SE and capstone courses, with 
external clients are generally small, local medium-sized industries, located only external clients in capstone; these include 
business clients by the students large government and industrial clients.

1.4 One or two students conduct integration  Both students conduct testing, In capstone, one student performs integration 
and system tests, with artifacts with artifacts and system tests, with artifacts

1.5 Informal reviews by client; team   Often worked at client’s site: formal Requirements and user interfaces reviewed by 
presentations and peer evaluations; final reviews with client, and final products client; team formally reviews all artifacts; team 
products evaluated by clients, faculty, and evaluated by clients, faculty, and presentations and peer evaluations; final products
advisory board advisory board demonstrated at trade show to local community 

1.6 No, projects are small- to medium-sized No, projects are small- to medium-sized Some exposure to scaling up in SE courses
2.1 Not all team members deal extensively with The two team members interact Team members take different roles during SE

client; good experience dealing with several extensively with client but miss courses, giving all members interaction 
other team members in different roles interaction with larger team experience (a variation: two teams work on same 

project and swap artifacts at each phase end) 
2.2 Feasibility analysis in first course Feasibility analysis in the system analysis In capstone project, students research alternative

and design courses solutions with cost considerations
2.3 No exposure to continuous No exposure to continuous No exposure to continuous quality improvement

quality improvement quality improvement
2.4 Instructor acts as facilitator to team as More individual feedback due to Instructor acts as facilitator to team as a whole

a whole small team size



ternative to an SEA. However, in the long
run, undergoing a proper apprenticeship
program could become a requirement for SE
professional practice. By investing in future
employees through apprenticeship pro-
grams, industry stands to gain more broadly
trained SE practitioners, which should
translate into greater productivity and
higher-quality products. 

To realize a full industry-sponsored ap-
prenticeship program, we must consider
other administrative considerations in addi-
tion to the framework. Any comprehensive
SEA program will necessarily include ad-
ministrative components specific to an or-
ganization. These components include envi-
ronment (capability of personnel to train
apprentices, supply and demand for quali-
fied employees), implementation (availabil-
ity of suitable projects, support personnel
for administering apprenticeship programs),
and motivation (potential benefits to the or-
ganization and to the apprentice). For in-
stance, given the SEA criteria in Figure 3, an
organization offering such SEA programs
would ideally have a proven track record
(for example, CMM Level 3) and also the
necessary infrastructure to provide mentors
and administrators to support the program.
For the SEA framework component, SWE-
BOK provided the underlying concepts and
Bloom’s taxonomy was the chosen instru-
ment for analysis. Similarly, an SEA must
identify and apply relevant underlying con-
cepts and suitable analysis instruments per-
taining to the administrative components,

to flesh out the program details. These re-
quire extensive fieldwork and are beyond
this article’s scope, but we intend to address
them in due course.

In evaluating SE’s maturity level, Gilda
Pour and her colleagues observed that exist-
ing skill development mechanisms for pro-
fessionals entering the practice are ad hoc
and not identified with the SE profession.11

This reinforces the need for proper SEA pro-
grams, but their development will be an evo-
lutionary process. The programs could start
with a limited number of outstanding stu-
dents and committed industries that would
be willing to take on such an innovative ini-
tiative. Requiring an apprenticeship as a pre-
requisite for professional practice, as other
professions have done, might be a first step
toward solidifying the SE profession. 

References
1. L.W. Anderson and L.A. Sosniak, eds., Bloom’s Taxon-

omy: A Forty-Year Retrospective, Nat’l Survey on Stu-
dent Engagement, Univ. of Chicago Press, Chicago,
1994.

2. T. Hilburn et al., A Software Engineering Body of
Knowledge, Version 1.0, tech. report CMU/SEI-99-TR-
004, Software Eng. Inst., Carnegie Mellon Univ., Pitts-
burgh, 1999.

3. P. Bourque and R. Dupuis, eds., Guide to the Software
Engineering Body of Knowledge, IEEE CS Press, Los
Alamitos, Calif., 2001.

4. B. Meyer, “Software Engineering in the Academy,”
Computer, vol. 34, no. 5, May 2001, pp. 28–35.

5. B. Boehm and V.R. Basili, “Gaining Intellectual Control
of Software Development,” Computer, vol. 33, no. 5,
May 2000, pp. 27–33.

6. J. Bach and W.M. McCracken, “SE Education: What
Academia Can Do,” IEEE Software, vol. 14, no. 6,
Nov./Dec. 1997, pp. 26–29.

7. P.J. Denning and R. Dunham, “The Core of the Third-
Wave Professional,” Comm. ACM, vol. 44, no. 11,
Nov. 2001, pp. 21–25.

8. W.S. Humphrey, A Discipline for Software Engineering,
Addison-Wesley, Boston, 1995.

9. K. Surendran and F.H. Young, “Teaching Software En-
gineering in a Practical Way,” Proc. 13th Ann. Conf.
Nat’l Advisory Committee on Computing Qualifica-
tions (NACCQ), Hamilton, New Zealand, 2000, pp.
345–350.

10. R. Cannon, J. Diaz-Herrera, and T.B. Hilburn, “Teach-
ing a Software Project Course Using the Team Software
Process,” Proc. 33rd Technical Symp. Computer Science
Education (SIGCSE 2002), ACM Press, New York,
2002, pp, 369–375.

11. G. Pour, M.L. Griss, and M. Lutz, “The Push to Make
Software Engineering Respectable,” Computer, vol. 33,
no. 5, May 2000, pp. 35–43.

For more information on this or any other computing topic, please visit our
Digital Library at http://computer.org/publications/dlib.

5 6 I E E E  S O F T W A R E S e p t e m b e r / O c t o b e r  2 0 0 2

About the Authors

Ken Surendran is an associate professor in the Department of Computer Science at
Southeast Missouri State University. His research interests include software engineering, secu-
rity management education, and object technology. He has a BE in electrical engineering from
the University of Madras, India, an M.Tech in electrical engineering from the Indian Institute of
Technology, and a PhD in applied analysis from the State University of New York at Stony
Brook. He is a senior member of the IEEE and a member of the ACM. Contact him at Computer
Science Dept., MS 5950, Southeast Missouri State Univ., One Univ. Plaza, Cape Girardeau, MO
63701; ksurendran@semo.edu.

Andrew Macfarlane is a software test manager in QCOM Australia. His research inter-
ests include quality assurance and IT education. He has an MA in mathematics from Auckland
University and an MSc in mathematics from the University of New South Wales. He is the author
of Embracing the System: The Systemisation of Business and Life (1stBooks Library, 2001). He
is a member of the New Zealand Mathematical Society and American Mathematical Society. 
Contact him at QCOM Australia, 52 Douglas St., Milton, Brisbane, Australia 4064; andrew.
macfarlane@au.unisys.com. 

Helen Hays is an associate professor in the Department of Computer Science at South-
east Missouri State University. Her research interests include computer science and software
engineering education. She has a BA and MA in mathematics from the University of Missouri,
Columbia, and a PhD in higher education (with an emphasis in computer science education)
from Southern Illinois University, Carbondale. She is a member of the ACM. Contact her at
Computer Science Dept., MS 5950, Southeast Missouri State Univ., One Univ. Plaza, Cape 
Girardeau, MO 63701; hhays@semo.edu.



focuseducating software professionals

0 7 4 0 - 7 4 5 9 / 0 2 / $ 1 7 . 0 0  ©  2 0 0 2  I E E E S e p t e m b e r / O c t o b e r  2 0 0 2 I E E E  S O F T W A R E 5 7

tight timelines, robust feature sets with low
cost, and diverse user needs with architec-
tures’ functional limitations. Who teaches
IT professionals what to do in this dynamic,
diverse environment? Should universities in-
still these skills, or is that industry’s respon-
sibility? An innovative graduate specialty in
information engineering and management
at the University of Alabama at Birmingham
(UAB) specifically addresses these issues.

Who educates our workforce?
The age-old battle between industry and

academia over what constitutes education
and what should be left to on-the-job train-
ing has become more intense and less defined
in the IT field. Despite last year’s shrinking
economy and subsequent decrease in the
number of available jobs, highly skilled IT
professionals remain scarce.1,2 With the ever-
present gap between available jobs and

skilled workers to fill them, industry is pres-
suring educators to provide college graduates
who can enter the workforce ready to pro-
duce. However, providing advanced IT skills
and knowledge requires preliminary courses
that provide the fundamentals. With more
and more college-bound students interested
in business or other nontechnical career
paths, colleges and universities are finding it
harder to attract students to science-based
curricula. Moreover, industry pressure and
declining enrollment squeeze science-based
programs of their nontechnical coursework
to avoid extending graduation by a semester
or year. Similarly, management information
systems programs at many universities offer
students the opportunity to avoid the ad-
vanced mathematics, algorithm design, and
hardware circuitry classes central to tradi-
tional computer science, computer engineer-
ing, and electrical engineering curricula. But

Educating Experienced IT
Professionals by Addressing
Industry’s Needs

Dale Callahan and Bob Pedigo, University of Alabama at Birmingham 

What should
students learn in
school, and what
should they learn 
on the job? The
University of
Alabama at
Birmingham
developed a
graduate program
specialty in
electrical and
computer
engineering to
address industry
needs without
compromising
academic
fundamentals.

A
s information technology continues its rapid progress, both edu-
cators and employers have recognized the importance of educat-
ing the professionals that design, develop, and deploy information
systems. IT professionals—including software engineers—must

know how to address the diverse needs of stakeholders, stay abreast of the
latest technologies, and leverage them to maximize strategic advantage over
the competition. These professionals must also balance high efficiency with



MIS programs often fail to provide graduates
that can handle the technical challenges of
software engineering in their first IT jobs af-
ter college. 

Industry finds training investments the
least likely to add to their bottom line. Tight
training budgets become political hot pota-
toes—managers must balance employees’
training requests with the probable return
the company will realize from their invest-
ment. Top-performing employees often re-
ceive training at the expense of newer, less
skilled employees who have yet to prove
their value to their companies. Employees
attend company-paid training courses to ac-
quire the latest technical skills, only to leave
shortly thereafter for better-paying jobs.
Hence, corporations prefer to hire candi-
dates that already possess the skills and
knowledge to succeed.2 For recent college
graduates to compete, they must acquire the
skills and knowledge during their school
years through their curricula, internships,
co-ops, or full-time employment balanced
with schoolwork. 

Academia guided by industry
To address these issues, the UAB Depart-

ment of Electrical and Computer Engineering
asked industry executives what they ex-
pected from college graduates. The depart-
ment asked executives to define fundamen-
tal business skills that the IT candidate pool
is generally lacking and to compile a list of
topics that needed to be taught. These ques-
tions yielded some interesting feedback.

First, the executives revealed that IT
professionals are primarily lacking tech-
nology management skills, rather than
software programming or hardware skills.
They noted a major drought of capable
technical managers to perform upper-
management duties, specifically at the chief
information officer and chief technology
officer levels. In general, technology execu-
tives with business backgrounds, hired for
their business savvy and managerial skill,
lack understanding of the information and
computer assets they oversee. Because they
do not understand IT’s strategic impor-
tance in their industry, they set up the
company and themselves for failure. To
address this problem, many universities
offer technical MBA programs to provide
future business leaders with some technical

awareness. However, these programs typi-
cally lack the engineering principles neces-
sary to prepare future CIOs for the techni-
cal decisions they will face.

On the opposite end of the spectrum,
managers with robust technical skills typi-
cally lack the business savvy their MBA
peers possess. These “techies” often have
little appreciation for business imperatives
such as balancing priorities, managing prof-
its, and minimizing risks. Even worse, tech-
nical experts often harbor product and
technology biases. To them, every problem
can be solved with their favorite technology
solutions or vendors. Even experienced
technical managers sometimes focus more
on IT’s classical engineering aspects than its
business aspects.

The second major revelation from busi-
ness executives is that they are not looking
to hire software engineers, computer engi-
neers, or even business administrators. In-
stead, they seek information engineers: peo-
ple capable of participating in and designing
business processes while understanding that
information is the most essential element of
today’s business. Academia has long edu-
cated and trained people to engineer auto-
mobiles, televisions, aircraft, and comput-
ers, but today’s industry asks academia to
teach people to engineer information and
the processes that control it. 

UAB worked these topics into courses,
from which a new program has evolved: the
Master of Science in electrical engineering,
with emphasis on information engineering
and management (IEM).

Balancing theory and reality 
Academia and industry have long de-

bated the balance between theory and real-
ity in engineering curricula. Industry’s per-
ception that universities teach outdated
methods and use impractical study exam-
ples is countered by the universities’ need to
teach fundamentals before moving on to ad-
vanced, industry-relevant material. Hiring
managers demand current skills and practi-
cal experience of their entry-level employee
pool, but universities find little time to
squeeze these skills into curricula packed
with background courses in mathematics,
science, and humanities. MIS programs ad-
dress this by introducing students to the lat-
est technologies and teaching them to ad-

With more and
more college-
bound students
interested in

business 
or other

nontechnical
career paths,
colleges and
universities 
are finding it

harder to
attract students

to science-
based

curricula.

5 8 I E E E  S O F T W A R E S e p t e m b e r / O c t o b e r  2 0 0 2



dress business problems with IT tools.
However, MIS programs don’t teach the en-
gineering fundamentals that students need
to design efficient, cost-effective informa-
tion systems from the ground up. Diagnos-
ing problems is difficult (if not impossible)
without understanding how information
flows through and is used by a system. Col-
lege graduates with MIS degrees frequently
lack the background to succeed in the infor-
mation engineering job market, leading
many to return to school for graduate de-
grees. But because job candidates with grad-
uate degrees command higher salaries than
their undergraduate peers, employer expec-
tations for practical knowledge and skills
are higher still. 

The IEM program’s coursework balances
theory and reality by featuring frequent
guest speakers and realistic problem-solving
exercises to augment the theory textbooks
present. A seminar course provides a forum
for students and faculty to share experi-
ences. Guest speakers bring immediate rele-
vance to the discussion by raising problems
they are facing in their workplaces. The
CIO of a local power company talks about
the challenges of the energy business and its
effects on IT. A telecommunications execu-
tive discusses the implications of the fiber-
optic industry’s slowdown and how IT solu-
tions could mitigate bottlenecks in the
outdated communications infrastructure.
Venture capitalists encourage students to
take their innovative IT ideas to market.
Faculty encourages students to address their
own businesses’ problems as topics for class
projects. Students practice their skills on
real-world problems rather than hypotheti-
cal ones. They can implement at their work-
places the solutions they develop in class,
providing value to their companies while
honing their own practical skills. 

Software fundamentals
For IT professionals to add value, they

must understand the fundamental practices
involved in the development, deployment,
and retirement of information systems.
They must be able to identify life-cycle mod-
els, understand their differences, and know
when to use the myriad tools in their IT
toolbox. They must grasp software develop-
ment concepts such as quality management,
requirements analysis, configuration man-

agement, information integration, and soft-
ware metrics. Information engineers should
be familiar with computer-aided software
engineering tools, code libraries, and auto-
mated testing tools. These concepts are not
confined solely to software developers—
sound software engineering practices are es-
sential in any IT setting. The managers who
purchase IT consulting services and those
who implement the resulting products must
understand the methods, tools, and stan-
dards used to develop the products they
purchase. They must be able to distinguish
sound development practices from ad hoc
coding, identify good software from bad,
negotiate solid contracts with software engi-
neering consultants, and make sound busi-
ness decisions about IT assets. 

Teaching software engineering funda-
mentals has historically fallen to corporate
training programs, due to the lack (until re-
cently) of software engineering programs in
colleges and universities. Computer science
curricula have foundations in science and
mathematics rather than engineering, and
their emphasis has tended toward computer
and algorithm design rather than develop-
ing software as a business tool. Although
software engineering curricula are becom-
ing more common, long-standing corporate
IT fundamentals such as project manage-
ment, requirements analysis, and the soft-
ware development lifecycle are new aca-
demic topics. 

But software engineering is part of a
larger system that includes computer hard-
ware, communications infrastructure, third-
party applications, and the information that
these combined elements manage. The true
value in business today is information—
whether data or human-intensive “intellec-
tual capital.” Today’s IT systems provide
the strategic value of managing the infor-
mation that makes a corporation succeed.
IT managers must understand the technical
fundamentals of software, and be able to
manage the way information flows through
IT systems to add value to the corporation.

UAB carefully chose its IEM program’s
fundamentals to ensure relevant course-
work and to provide themes that are rein-
forced across the curriculum (see the “IEM
Course Outline” sidebar). The coursework
emphasizes recognized standards and stan-
dards bodies. Students develop and post

S e p t e m b e r / O c t o b e r  2 0 0 2 I E E E  S O F T W A R E 5 9

For IT
professionals 
to add value,

they must
understand the

fundamental
practices

involved in the
development,
deployment,

and retirement
of information

systems. 



Web pages that comply with World Wide
Web Consortium HTML standards. Stu-
dents plan, execute, and measure software
development projects in accordance with
the Capability Maturity Model. Texts and
class discussions center around the Software
Engineering Body of Knowledge.3 Students
complete research papers and presentations
describing IEEE software standards and cer-
tification programs. Faculty reinforce these
themes with readings from software engi-
neering community leaders such as Freder-
ick Brooks,4 Richard H. Thayer,5 Andrew S.
Tanenbaum,6 Steve McConnell,7 and Grady
Booch.8 IEM program graduates emerge
with solid knowledge of software and infor-
mation engineering fundamentals, able to
lead their peers in IT organization planning,
execution, and management. 

MBA versus MS
Most professionals who wish to advance

into management must decide whether to
obtain an MBA. Regardless of industry, an
MBA is the entry ticket for modern business
success. Holding an MBA doesn’t guarantee
admittance to management ranks, but lack-
ing one can inhibit progress. However, an
MBA does little to provide the technical
skills necessary for managing IT profession-
als or IT assets. Thus, CIOs without a tech-
nical background are at an extreme disad-
vantage. Gaining staff respect is an essential
part of being an effective manager. With-
out this respect, a manager’s best ideas
go unheeded and his decisions are second-
guessed. Engineers usually value technical
education above business savvy, so they are
more likely to tolerate a manager with an
MS but little business acumen than one with
an MBA but no technical understanding. 

The IEM program provides a graduate
degree that addresses the need for IT indus-
try leaders who possess strong technical
knowledge rounded out by practical busi-
ness and management skills. Rather than
teaching technical skills to business stu-
dents, the IEM program teaches business
skills to engineers. Students in the IEM pro-
gram learn to research the IT business envi-
ronment, monitor the market, write and
present business plans, and defend their
work to venture capitalists. These experi-
ences prepare IEM graduates for leadership
roles in startups as well as established firms.

By focusing on IT’s technical and business
aspects, the IEM program aims to fulfill in-
dustry’s need for information engineers who
can immediately add strategic value to the
IT departments of the businesses they enter.
These information engineers can tackle
management positions from network sup-
port to project management to CIO.

Computer science versus
information engineering

As information engineering moves to-
ward becoming a distinct engineering disci-
pline, the debate over whether computer sci-
ence curricula can adequately address the
needs of engineering professionals is heating
up. Arguments abound in favor of separat-
ing these two areas into distinct curricula.
Some assert that establishing a distinct in-
formation engineering curriculum is a fun-
damental step toward maintaining the field
as a legitimate engineering specialty. Others
argue that the IT industry is not sufficiently
diverse to justify multiple IT education pro-
grams. Furthermore, few colleges and uni-
versities have sufficient funding for two pro-
grams, forcing them to choose which path
to pursue, or to attempt to combine the two
paths into one program. Although both
computer science and software engineering
require similar depth of knowledge, they ap-
proach that knowledge from distinct points
of view. It is this fact that dictates distinct
curricula for the two disciplines. 

Frederick Brooks said, “The scientist
builds in order to study; the engineer studies
in order to build.”4 As he implies, computer
science curricula should attract students
who wish to gain advanced understanding
of the “hows and whys” of computer oper-
ation. Computer science coursework sup-
ports algorithm designers, programming-
language authors, and hardware architects.
These people dissect all aspects of a com-
puter’s fundamental functions and deter-
mine the best ways to make them tick. 

Engineering curricula, by contrast, teach
students to use technology to create solu-
tions and advance our ability to accom-
plish our goals. Engineers take the building
blocks that computer scientists provide and
innovate ways of assembling them to solve
problems. 

The IEM program takes a decidedly engi-
neering approach, focusing on using IT sys-

Regardless of
industry, an
MBA is the
entry ticket 
for modern
business
success.

6 0 I E E E  S O F T W A R E S e p t e m b e r / O c t o b e r  2 0 0 2



tems and assets to solve engineering prob-
lems. Software design is an important aspect
of engineering because only properly de-
signed applications can solve software-
related problems. Information engineers
learn to evaluate IT tools and choose the
right ones for the job. They learn to design IT

systems with information flow in mind from
the start to maximize the resulting systems’
business and strategic value. They learn to
evaluate the IT market and decide which IT
tools and solutions to purchase, based not
just on the latest technological trends, but on
what will bring the best value to the business.

S e p t e m b e r / O c t o b e r  2 0 0 2 I E E E  S O F T W A R E 6 1

Advanced engineering operations (EE684S)
Business systems design and programming
Case analysis
Managing in service environments
Managing product development
Needs assessment
Project management
Projections and forecasting
Quantitative methods
Risk assessment
Specification preparation
Strategic analysis
Strategic and operational planning
System analysis (cost/benefit and cost/effectiveness)
Technology transfer
The budget process

Engineering management of information resources (EE685S)
Global information technology management
Image transfer and management
Information flow and use
Information process and improvement
Management of information
Management of quality
Managing critical information
Managing information-intensive change

Enterprise information architecture engineering (EE657S)
Data warehousing
Developing and managing distributed systems
Distributed computing
Distributed computing architecture
Hardware, software, and communications 
Information architectures
Multimedia engineering
Technical architecture design

Enterprise perspectives in information engineering (EE688S)
Building a responsive information infrastructure
Business process redesign
Business systems analysis and design
Electronic-commerce technical design
Ethics

Governmental regulations and requirements
Legal considerations
Measuring information systems’ effectiveness and productivity
Reengineering and information systems evolution

Introduction to computer networking (EE632S)
Communication protocols: Internet and WWW
Computer network architectures
Network security
Networking and communications
Telecommunications (LAN, WAN, Internet, intranet)
Video and data conferencing

Object-oriented design (EE640S)
Database design
Database management (relational, object)
Databases and data handling
Graphical user interfaces
Object-oriented design and analysis
Operating systems
Programming and programming languages 
Programming standards and processes (SEI CMM, ISO 9000) 
Software engineering
Software quality and testing

Technical entrepreneurship I and II (EE686S and EE687S)
Customers, vendors, and employees
Economics and finance
Hiring and developing people 
Human resource management—general HR topics 
Interpersonal and leadership skills
Management and motivational techniques
Marketing and sales
Operations
Organization management
Organizational culture and behavior
Organizational dynamics 
People and organizational management
Personnel management
Strategic management
The negotiating process 
Venture capital

IEM Course Outline 



A s any engineer knows, design is onematter, but the final product is thetest of success. The IEM program be-
gan with the first group of students in August
2000, and these students graduated in May
2002. Did the program meet its design goals?
Feedback from these students and their em-
ployers is telling. Surveys of the first class to
complete the IEM program indicate that the
curriculum strikes dead center on what stu-
dents need to succeed in the job market.
Most students indicated that they learned in-
formation and skills they never expected to,
and all students indicated that their job and
career perspectives had broadened. 

The students were immediately able to
apply their coursework on the job. Many
completed class projects that were directly
related to their companies’ most pressing
problems—problems that were never be-
fore addressed properly. One student who
worked with a software development com-
pany devised new quality metrics and stan-
dards for upcoming offshore development
plans. A student who worked with IBM de-
veloped a framework for creating design
specifications; today, IBM’s design groups
use that framework.9 Other students have
developed new software development
models, addressed information integration
and data-mining issues, and even started
new companies developing software prod-
ucts with industry-leading quality assur-
ance procedures. 

Although most students’ employers re-
sponded positively to the students’ activities
in the IEM program, some students received
negative attention from company manage-
ment. Some managers did not like having

their IT operations scrutinized using indus-
try-standard models such as cleanroom soft-
ware development methodologies. Others
did not appreciate suggestions for improve-
ment (from newly educated IEM students),
such as using new data integration methods
to enhance information collection proce-
dures. However, IEM students successfully
handled even these negative experiences,
due in part to business and interpersonal
skills that the IEM program helped them de-
velop and enhance.

References 
1. M. Bolch, “The Coming Crunch,” IEEE Eng. Manage-

ment Rev., vol. 29, no. 3, third quarter 2001, pp. 23–26.
2. S. Stellin, “The Long, Humbling Quest for a Job in

Technology,” New York Times, 17 Mar. 2002.
3. P. Bourque and R. Dupuis, eds., Guide to the Software

Engineering Body of Knowledge, IEEE CS Press, Los
Alamitos, Calif., 2001; www.swebok.org. 

4. F. Brooks, “The Computer Scientist as Toolsmith II,”
Comm. ACM, vol. 39, no. 3, Mar. 1996; www.cs.unc.
edu/~brooks/Toolsmith-CACM.pdf.

5. R.H. Thayer, ed., Software Engineering Project Man-
agement, 2nd ed., IEEE CS Press, Los Alamitos, Calif.,
1997.

6. A.S. Tanenbaum, Computer Networks, 3rd ed., Prentice
Hall, Upper Saddle River, N.J., 1996.

7. S. McConnell, Rapid Development: Taming Wild Soft-
ware Schedules, Microsoft Press, Redmond, Wash.,
1996. 

8. G. Booch, Object-Oriented Analysis and Design, 2nd
ed., Addisson-Wesley, Boston, 1994.

9. D. Appleby and D. Callahan, “A Framework for Devel-
oping Design Specifications for Complex Heterogen-
eous Information Systems,” Proc. 34th Southeastern
Symp. System Theory (SSST 02), IEEE CS Press, Los
Alamitos, Calif., 2002, pp. 11–14.

For more information on this or ny other computing topic, please visit our
Digital Library at http://computer.org/publications/dlib.

Surveys of the
first class to
complete the
IEM program

indicate that the
curriculum
strikes dead

center on what
students need to
succeed in the

job market. 

6 2 I E E E  S O F T W A R E S e p t e m b e r / O c t o b e r  2 0 0 2

About the Authors

Dale Callahan is an assistant professor and program director of the Master of Science in
electrical engineering with emphasis on information engineering and management at the Uni-
versity of Alabama at Birmingham. He received his PhD in electrical engineering from the Uni-
versity of Alabama. He is a senior member of the IEEE and a licensed professional engineer.
Contact him at the Univ. of Alabama at Birmingham, 1150 Tenth Ave. South, Birmingham, AL
35294-4461; dcallahan@uab.edu. 

Bob Pedigo is an electrical engineer in Birmingham, Alabama. He is a graduate of the
IEM program at UAB. His technical interests include quantum computing, power systems, infor-
mation engineering, and engineering education. He is a senior member of the IEEE and chairs
the Alabama section of the IEEE Computer Society. Contact him at PO Box 361841, Birming-
ham, AL 35236-1841; rmpedigo@ieee.org.



6 4 I E E E  S O F T W A R E S e p t e m b e r / O c t o b e r  2 0 0 2 0 7 4 0 - 7 4 5 9 / 0 2 / $ 1 7 . 0 0  ©  2 0 0 2  I E E E

At the University of Saskatchewan, one of
our first-year courses, Principles of Com-
puter Science (CMPT 115), presents a
breadth-first view of computing that empha-
sizes data structures, as did our second-year
course, Analysis of Data and Language
Structures (CMPT 250). About 15 years ago,
CMPT 250 moved to the object-oriented
paradigm. Toward the mid 1990s, we added
some discussion of software engineering to it,
particularly in designing large information
systems. CMPT 250 corresponds to the
Computing Curricula 2001 report’s recom-
mended third introductory-level course (see
the sidebar on p. 67). However, some institu-
tions could use it as their second course, if
their first course is particularly strong.

Course overview
Of the Curricula 2001 report’s 12 units

on software engineering, CMPT 250 covers
all of three core units: software design, soft-

ware processes, and software validation. In
these three units, we cover more than what’s
recommended for introductory courses, es-
pecially in the software design unit. We also
cover the design-by-contract topic of the
formal methods unit. For introductory
courses, the report recommends some cov-
erage of the application programming inter-
face software tools units. Basic API use is
covered in the prerequisite courses for our
course. As for software tools, our students
use a programming environment tool. How-
ever, software educators must exercise care
not to overwhelm students with too many
tools too early.

Figure 1 contains our course’s topics and
associated prerequisite structure. We
arranged the topics from top to bottom in
order of presentation, with the left side
showing the software engineering topics.
The abstract data types (ADTs) topic in-
cludes preconditions and postconditions

focus
Integrating Software
Engineering in
Introductory Computing
Courses

Grant A. Cheston and Jean-Paul Tremblay, University of Saskatchewan

An introductory
course for
undergraduate
computing students
aims to integrate
data structures 
and software
engineering. 
The software
engineering
assignments
emphasize
teamwork, and
students use a 
10-step process to
develop an object-
oriented software
system.

F
rom the first computing curricula recommendations developed,
educators have realized that data structures are central to much of
computing and that students need a strong background in them
early on. It is also important to expose students to numerous com-

puting applications so they can see employment opportunities in the field
and realize that computing is more than programming.

educating software professionals



and leads to a discussion of the design-by-
contract paradigm for software specifica-
tion and development.1 The analysis and de-
sign topic includes a 10-step development
process for an information processing sys-
tem. The steps in this process rely heavily on
using the Unified Modeling Language
(UML)2 to represent various aspects of the
evolving system. (We describe our 10-step
process in more detail later.) The last soft-
ware engineering topic is testing. This dis-
cussion includes boundary-value and equiv-
alence-class testing from black-box testing,
statement coverage and path coverage from
white-box testing, and state-based testing
from object-oriented testing. All the soft-
ware engineering topics should be covered
in any course like this one, although a lot of
flexibility exists regarding the material cov-
ered leading into the project.

As for data structures, because our
course is at the second-year level, Figure 1’s
top three data structure topics are mostly re-
view. If we offered the course in the first
year, we would spend more time on these
topics because much of their content would
be new to students, leaving little time for the
bottom three data structure topics.

Because many of the students are not yet
ready for a course based only on software
engineering, about half the course is on data
structures. Students need more experience
writing actual programs, especially using
polymorphism and the more advanced fea-
tures of object-oriented programming and
design by contract. Also, students want to
get hands-on experience instead of just do-
ing abstract design. However, they aren’t
experienced enough to form teams to actu-
ally implement the significant systems they
design. Therefore, for the modeling exer-
cises and the project, the students do analy-
sis and design but no coding. This gives
them the freedom to incorporate many de-
sirable features without having to imple-
ment them, which can be time-consuming.
To gain practical programming experience,
the students implement and enhance various
data structures.

We alternate between topics in data
structures and software engineering. After
we cover a topic in an area, students work
on an assignment on that topic while we
discuss a topic from the other area in class.
In this way, students obtain a mixture of

concrete data structure programming and
abstract systems design. Additionally, we in-
troduce them to reuse and extending exist-
ing code. To facilitate this, we have designed
and implemented an extensive library of
data structures. This allows exercises that
entail adding new features to (or developing
a variation of) an existing data structure. In
the process, students must read and under-
stand existing code and learn to adapt it by
defining new descendants and overriding or
redefining inherited methods. Modifying
and extending existing software helps main-
tain legacy and evolutionary systems, so stu-
dents acquire valuable experience.

A simplified object-oriented
development approach

Much effort in the past decade has gone
to developing specific methodologies for OO
software development. Indeed, software pro-
fessionals have published some two dozen or
more methodologies, and although some are
more popular than others, researchers are still
doing a lot in this area. Currently, two third-
generation OO development approaches ap-
pear to dominate: object-oriented process, en-
vironment, and notation and UML. OPEN
defines a complete OO development process.

S e p t e m b e r / O c t o b e r  2 0 0 2 I E E E  S O F T W A R E 6 5

Abstract data types and
design by contract

Review of OO
programming

Analysis and
design process

Project
lead-in

Testing

Polymorphism Timing
analysis

Review of linear
data structures

Dictionary
data structures

Binary
trees

Better dictionary implementations
• hash table
• balanced trees

Direct and
Btree files

Graphs

Figure 1. Course topics and the associated prerequisite
structure.



Initially, UML was just a set of notations and
some modeling rules, but developers have
proposed a process for it called Unified. The
net result is that industry and academia are
fast adopting UML’s set of notations as the
standard. Furthermore, extensive computer-
assisted software engineering tools are rapidly
becoming available for UML, so we use UML
notation.

In the analysis phase of software devel-
opment, we obtain an object model from a
real-world domain that we can use to de-
velop a software system. We initially do the
modeling at a high level. The high-level re-
sults of the analysis phase are expanded
during the design phases to include details
of human and internal interfaces. We can
then use the design phase results to imple-
ment the desired system using an OO pro-
gramming language. Thus, objects and
classes are involved in all phases of develop-
ment. To give students more guidance in de-
veloping a system, we developed a 10-step
process.

The 10-step process
In an introductory course we cannot—

nor should we—propose a detailed method-
ology for OO software development. How-
ever, we must give students a fairly specific
approach—such as our 10-step process—
for designing a large software system.

1. Specify systems requirements
In this step, end users, domain experts,

systems analysts, and possibly other stake-
holders help develop initial requirements for
the given problem or application. This step in
the analysis phase focuses on what the soft-
ware system will do—not how it will do it.

Although requirements specification is im-
portant, we only describe it briefly in our
course, and we do not expect students to do
this task. For any analysis and design exercise,
the requirements are given to the students.

2. Determine the system boundary
The next task in software development is

separating the planned internal computer
system from the external world. Determin-
ing this system boundary is fundamentally
important and involves unambiguously
identifying the communication between the
system and the external world. Generally,
the relevant external world that we model

consists of users, agencies, devices, and other
external computer systems. To determine the
communication between the system and the
external world, we must identify incoming
and outgoing data. A context model and as-
sociated diagram represent these dataflows
to and from the external entities.

Historically, using context diagrams pre-
dates object-oriented development. Soft-
ware developers consider it a good idea to
use them to document an application’s
scope. Developers should exercise care,
however, especially regarding dataflows and
message passing. Dataflows are considered
inappropriate for object-oriented develop-
ment. Also, they are not very abstract and
might be unsuitable for starting develop-
ment. The same criticisms apply to context
diagrams based on message passing. Fur-
thermore, detailed messages probably con-
tain design information. Notwithstanding
these criticisms, we have found that, with
proper warnings, students find context dia-
grams useful.

We also identify use cases here because
they can facilitate discovering the system
boundary. Approaches to finding use cases
are either actor- or event-based. UML’s use
case diagrams are used to represent actors,
events, and use cases.

3. Identify objects and classes
An important step in object-oriented

software development is examining the
problem domain and identifying relevant
and good abstractions (that is, ADTs). Any
poor abstractions developed in this step will
propagate through the entire development
process and result in poor-quality software.

Identifying good abstractions can be dif-
ficult, especially for developers new to ob-
ject orientation. Unfortunately, no current
foolproof approach or algorithm exists for
finding good abstractions and their imple-
mentations (classes). Students usually find it
easiest to identify objects first and from
these develop abstractions and classes.

A first rough cut at finding objects and
classes involves examining the document
that specifies the problem’s system require-
ments. In this document, nouns can some-
times indicate important external-world ob-
jects. In the early development phase, we
emphasize finding these concrete entity ob-
jects. Students can find further objects from

6 6 I E E E  S O F T W A R E S e p t e m b e r / O c t o b e r  2 0 0 2

To give students
more guidance
in developing 

a system, 
we developed 

a 10-step
process.



domain knowledge and by considering enti-
ties that must interact with the system. The
context model and use case development
can often assist in identifying boundary ob-
jects in a given application. Students will
obtain other kinds of objects—including
conceptual objects, event and state objects,
interface objects, container objects, and
control objects—in later steps. Once they
have found the objects, they must categorize

them into classes. This will likely involve ex-
tensive pruning, because the initial search
for objects and classes probably included
synonyms for the same concept.

During software development, we want
to find, invent, or create three broad cate-
gories of classes: domain classes, design
classes, and implementation classes. Domain
classes belong to the problem space, whereas
design and implementation classes belong to

S e p t e m b e r / O c t o b e r  2 0 0 2 I E E E  S O F T W A R E 6 7

Computing programs have changed greatly since the
1960s. The ACM’s Curriculum ’68 report1 was the result of the
first attempt to guide emerging computer science departments
in designing computer science programs. Over the next
decade, the recommendations in this report became dated; the
ACM updated them in 1978 as the ACM Curriculum ’78 re-
port.2 The first-year introductory courses in this report, CS1
and CS2, were key, and computer science professors are still
teaching its contents (except for the programming language
used) at many North American institutions.

In 1991, the IEEE Computer Society and the ACM released
the Computing Curricula ’91 report.3 Unlike its predecessors,
this report was more comprehensive. Whereas earlier reports
identified a standard syllabus for individual courses, the 1991
report divided the necessary body of knowledge for an under-
graduate computing program into nine knowledge units. Indi-
vidual institutions, depending on their specific needs, could cus-
tomize their own programs to cover these units. One of the
report’s goals was to include software engineering topics in in-
troductory computing courses. After some 10 years, however,
this important goal is more an aspiration than a realization.

The recent ACM/IEEE Computer Society Computing Curric-
ula 2001: Computer Science report is a major revision of the
1991 report.4 It incorporates the computing developments of
the past decade and organizes the body of computer science
knowledge hierarchically into three levels: areas, units, and
topics. At the top level, the report identifies 14 areas using a
two-letter abbreviation, such as AL for algorithms and complex-
ity, PF for programming fundamentals, PL for programming lan-
guages, and SE for software engineering. Each area comprises
units, which are identified by adding a numeric suffix to the
area name; PF3, for example, deals with fundamental data
structures, SE1 describes software design, and SE6 deals with
software validation. A unit is further subdivided into topics; for
example, SE1 includes object-oriented analysis and design, de-
sign patterns, and component-level design. For software engi-
neering, the report identifies 12 units; eight are core and
should be included in any curriculum.

The report also defines detailed course implementations and
strategies for complete undergraduate curricula. It describes

three levels of courses: introductory, intermediate, and ad-
vanced. At the introductory level, the report presents six imple-
mentation strategies: imperative first, objects first, function first,
breadth first, algorithms first, and hardware first. The main text
of this article presents a course that best fits the imperative-first
and objects-first strategies. The main difference between these
strategies is that the objects-first strategy emphasizes objects
very early in the syllabus.

In each of the strategies, the report gives two separate intro-
ductory-level implementations. The first uses the traditional two-
course sequence, and the second covers the material in three
courses. Some computing educators believe that they cannot
cover introductory-level topics in only two courses and there-
fore not in the first year. Other educators use this traditional
two-course approach. The Computing Curricula 2001 Task
Force predicts that the three-course introductory sequences will
become increasingly common.4

Each introductory sequence incorporates some of the core
topics from several of the 14 identified knowledge areas. One
of these areas is software engineering. For both the imperative-
first and the objects-first strategies, at least one of the introduc-
tory courses has significant content in both data structures and
software engineering. This article’s main text describes our at-
tempt to integrate the software engineering and data structure
topics in one reasonably cohesive course.

References
1. ACM Curriculum Committee on Computer Science, “Curriculum ’68: Rec-

ommendations for the Undergraduate Program in Computer Science,”
Comm. ACM, vol. 11, no. 3, Mar. 1968, pp. 151–197.

2. ACM Curriculum Committee on Computer Science, “Curriculum ’78: Rec-
ommendations for the Undergraduate Program in Computer Science,”
Comm. ACM, vol. 22, no. 3, Mar. 1979, pp. 147–166.

3. A.B. Tucker et al., Computing Curricula ’91, Assoc. Computing Machinery
and the IEEE Computer Soc., Los Alamitos, Calif., 1991; www.
computer.org/education/cc1991.

4. Computing Curricula 2001: Computer Science, Assoc. Computing Machin-
ery and the IEEE Computer Soc., Los Alamitos, Calif., 2001; www.
computer.org/education/cc2001/index.htm.

Overview of Computing Curricula Recommendations



the solution space. Because the boundary is
usually blurred between the analysis and de-
sign phases, design classes might be the most
difficult to create. Also, design and imple-
mentation classes result from creating an ar-
chitecture that specifies how we can achieve
the desired functionality. Thus, they often
arise later in system development.

Equally important to finding good rele-
vant abstractions is recognizing poor or ir-
relevant ones. Just as we need fruitful ap-
proaches to help find good classes, we also
should examine danger signals that might
lead to classes we should reject. This is es-
pecially important for students just begin-
ning system objectification. In our course,
we discuss several of these signals.

In practice, software engineers prefer us-
ing only a few approaches to finding ob-
jects and classes, but our goal is to expose
object-oriented modeling beginners to sev-
eral approaches.

4. Identify class interactions and features
This step helps establish the various ways

objects can interact and collaborate. To
identify interactions and features, it is often
useful to study in detail the use cases found
in Step 2. By analyzing each of these as it
progresses through the system, students can
discover many interactions and features. We
find that interaction diagrams are a good
way to portray use case interactions. Also,
students find that interaction diagrams are
quite natural to develop, and through this
development, various parts of the system be-
come apparent—for example, the various
containers used to store system entities. Our
discussion for this step emphasizes the need
for an interface to handle communication
with each external entity. We also demon-
strate using controller classes to coordinate
necessary activities, and we model com-
mands by classes to promote modularity and
extensibility.

The interactions that students discover in
an interaction diagram are modeled using
inheritance, aggregation, and association re-
lationships. In the next step, students amal-
gamate the class diagrams to represent the
system’s entire structure. This step also
identifies some of the attributes and opera-
tions of each class. Sometimes we can dis-
cover suitable attributes by finding adjec-
tives in the system requirements document.

Essentially, this process involves discovering
suitable abstractions—that is, ADTs. At this
stage we ignore any implementation details
for these abstractions.

5. Group classes into subsystems
To manage complexity and produce

quality software, developers organize
classes in a system into clusters, or subsys-
tems. Each subsystem comprises selected in-
teracting classes or subsystems that collabo-
rate to deliver a desired functionality. For
trivial problems, whose class diagrams stu-
dents can draw on one page, partitioning a
system into subsystems might not be neces-
sary. However, even for small problems, and
certainly for medium-size and larger prob-
lems, identifying subsystems becomes im-
portant in software development.

This step’s main goal is to partition sys-
tem classes into subsystems that are loosely
coupled and highly cohesive. In developing
larger systems, students might have to
group classes into subsystems much ear-
lier—perhaps in the first couple of steps.

6. Determine high-level system architecture
Analysis results help produce a system ar-

chitecture that will demonstrate how to real-
ize the system’s functionality. In this step, stu-
dents map aggregation and association
relationships into client-supplier relation-
ships. Additional classes dealing with soft-
ware and hardware issues might appear. Also,
further inheritance taxonomy development
can introduce new classes that we cannot
trace back to the problem domain. Further-
more, we introduce the three-tier architec-
ture—which comprises presentation, applica-
tion, and storage layers—as a desirable one.

7. Find more detailed design classes and
perform detailed class design

This step produces lower-level classes that
support the classes identified in Step 6. Stu-
dents might obtain these new classes directly
from existing class and application libraries.
Another possibility is to adapt existing li-
brary classes to the current problem. This
step usually involves bottom-up design,
which emphasizes class design, including
each class’s full interface or services specifi-
cation. Students update UML class diagrams
for the design with the additional details.

An important part of this step is identify-

Students find
that interaction
diagrams are

quite natural to
develop, and
through this
development,
various parts 
of the system

become
apparent.

6 8 I E E E  S O F T W A R E S e p t e m b e r / O c t o b e r  2 0 0 2



ing the best data structure for each con-
tainer. We do this by matching the required
application operations with the possible
data structures’ operations. Thus, students
must be very familiar with the operations of
the various data structures and their effi-
ciencies. We cover this information in the
data structures part of the course, which
covers arrays, linked lists, stacks, queues,
trees, and various dictionaries. The diction-
ary ADT is probably the most important be-
cause it occurs in most information process-
ing systems. Thus, knowledge from the data
structures part of the course is important for
this part of software development.

8. Write code for first working prototype
In this step, the interaction (sequence or

collaboration) diagrams can again prove
useful. The interaction diagram for a use
case shows a sequence of interactions: one
object’s sequence of interactions with other
objects becomes the operations sequence for
a method of the object, and each operation
in the sequence is an attribute access in—or
a method call on—another object. Thus, by
tracing through all the interactions, students
can identify further attributes and methods
and develop the methods’ code.

9. Review system for quality considerations
This step helps improve the architecture

from reuse and quality viewpoints. Although
reuse is always considered when students
perform the previous steps, the system is
now polished with respect to its possible
reuse and quality. This activity will often re-
sult in extending and revising existing inher-
itance taxonomies. Students might change
subsystem organization to improve coupling
and cohesion.

10. Refine coding for first working prototype
and perform testing

As its name implies, this step involves
code refinement and system testing. The
testing requires designing test cases for each
class, each subsystem, and the entire system
as a whole.

Course emphasis
In our course, we emphasize some steps

more than others, particularly the analysis
in Steps 2 through 5 and the design in Steps
6 and 7. The students don’t actually do Step

8—implementing a significant system. We
discuss it in class, and of course students im-
plement data structures. We cover Step 10’s
testing component separately, rather than
covering the complex task of testing a com-
plete system. Finally, in class we discuss us-
ing several design patterns to improve sys-
tem quality. We also illustrate how you
would use the patterns in a case study. The
patterns we discuss include Expert, Creator,
Controller, Polymorphism, Law of Demeter,
Iterator, Handle, Whole-Part, and Facade.

Our 10-step approach is for developing a
system; it does not include the important
operation and maintenance phase. Also, we
must inform students that they wouldn’t
usually perform the development steps se-
quentially. Indeed, not only would they per-
form each step incrementally with repeated
refining, but they can do several steps con-
currently. In software development, we do
some parts from the top down, generate
others from the bottom up, and use a mixed
(top-down and bottom-up) strategy for oth-
ers. Particularly, we would often do Steps 8
through 10 iteratively while developing suc-
cessive versions of a system prototype.

Assignments and projects
Software engineers must be good pro-

grammers, well versed in data structures
and algorithms, and fluent in one or more
programming languages. Also, they must be
able to model an application and use that
model to design and implement a system.
Moreover, software engineers will be in-
volved in programming in the large, where
many developers collaborate to develop a
large system. On such projects, the software
engineer is part of a team and therefore
needs communication and interpersonal
skills. He or she must schedule work for
themselves and others.

Students best learn analysis and design
by doing it, so we give them challenging and
worthwhile exercises to learn these skills.
Normally, the first one is a fairly simple in-
formation processing problem with a few
obvious use cases. Students are only re-
quired to analyze and design a system with-
out doing an implementation because the
system is usually too large and complex to
implement. As we described earlier, they do
the modeling using a UML subset. The de-
sign should include the most appropriate

S e p t e m b e r / O c t o b e r  2 0 0 2 I E E E  S O F T W A R E 6 9

Software
engineers must

be able to 
model an

application 
and use that

model to design
and implement 

a system. 



data structure for each container in the so-
lution. Thus, the data structures section in-
tegrates well with the design section.

Through these exercises, students will
hopefully realize that software engineering
is not just coding. They should learn that
with a good, detailed system design, the
coding is fairly straightforward—although
sometimes long and laborious. Also, they
start to see the difference between a systems
analyst and a programmer.

Ideally, students should already be famil-
iar with the application in the exercise. Some
applications we have used are a tennis court
booking system, a rental company, and the
sale of used textbooks by consignment.

Students should do the initial analysis
and design exercise individually to ensure
that they become familiar with the steps and
associated artifacts produced. The grading
of such an exercise emphasizes a design’s
various components, including the use case
list, the context diagram, a few interaction
diagrams, the corresponding class diagrams,
a composite class diagram, and the inheri-
tance hierarchies. Only a few marks go to-
ward design quality, because students are
just learning to design.

Once an application is discussed in class, in
the text, or in an exercise, we can assign exer-
cises that add further operations or com-
mands. This is particularly easy if objects
model the commands. Often, only the design
is done for an additional command, but it
helps if a working version of the system is
available. We developed two fully operational
systems, which let students study a final sys-
tem and actually add new commands to it.

It is also worthwhile to have a final proj-
ect where students work in teams to analyze
and design a larger system. In a larger sys-
tem, many of the use cases are not so obvi-
ous, and there is usually more than one
workable design. Through teamwork, dif-
ferent members often develop somewhat
different designs. As a result, the team must
work together to analyze them and deter-
mine the best one to develop in more detail.
This enhances the students’ ability to work
at a more abstract design level.

To ensure that every student participates
in the work, teams are usually restricted to
three (sometimes two) members. Large teams
are unnecessary because the students do no
implementation. Projects we’ve used include

a university library, a university bookstore,
and a student registration system.

Although grading an undergraduate stu-
dent project is not a trivial task, a graduate
student in software engineering should be
able to do it. In doing the grading, the stu-
dent will see a variety of obtainable designs,
including the poor ones, so that he or she
can learn to avoid them.

Student response
Initially, students are somewhat over-

whelmed by analysis and design problems.
However, they can begin by identifying use
cases and developing an interaction diagram
for each one. Provided that the first problem
is not too difficult, they can generally obtain
a reasonable design. Often, some of the use
cases are discussed in the tutorials associ-
ated with the course, and students handle
the other ones. After completing one prob-
lem or application’s analysis and design,
students gain confidence and can tackle
much larger applications. In course evalua-
tions, students usually indicate that analysis
and design is their favorite part of the
course. Often, students are proud of their
project designs and sometimes reference
them in their resumes.

Support
When we first decided to include more

software engineering in our course, we real-
ized that there was no suitable text. Most
first- and second-year data structure texts
discuss ADTs, but often such discussions are
superficial. Similarly, most introductory
texts discuss testing, but the discussions of-
ten omit the details of specific test-case gen-
eration approaches. With respect to software
design, we could not find a text at the first-
and second-year levels that described an ob-
ject-oriented software development process.
There are several texts for a third-year level
course on object-oriented software develop-
ment, but they assume too much back-
ground knowledge to be useable by first-
and second-year students. Thus, we wrote
our own text, of which there are now two
editions. One edition uses Java to show the
ideas’ implementation;3 the other uses Eiffel,
a language that is not as well known.4 Eiffel
is a strongly typed, object-oriented language
with a Pascal-like syntax. It supports ab-
stract classes, multiple inheritance, generic

Students will
hopefully

realize that
software

engineering is
not just coding.

7 0 I E E E  S O F T W A R E S e p t e m b e r / O c t o b e r  2 0 0 2



types, and design by contract with assertions
popularized by Bertrand Meyer.1

To assist students in our course, a senior
student runs a weekly tutorial session to an-
swer questions about the current assign-
ment and do additional examples similar to
the required ones. When students are doing
their initial analysis and design assignment,
the senior student usually does part of the
application in tutorials to demonstrate what
is involved while the students complete the
rest. This way, they see an example that is
closely related to their assignment.

T hrough our course, students obtainmost of the fundamental concepts ofdata structures, modeling, software
design, and software validation. Students
also learn the finer points of object-oriented
programming, such as multiple inheritance
and programming with assertions.

This is important in that it

� Prepares the student for the real world
� Shows that software engineers not only

do programming in industry but cer-
tainly are expected to do analysis, de-
sign, and testing

� Demonstrates that using patterns in
software development can produce
more loosely coupled, highly cohesive
systems that will be more reusable,
modifiable, and extendible

� Emphasizes the fact that a software en-
gineer is often part of a team and there-
fore needs communicational and inter-
personal skills, which can greatly affect
team productivity

� Emphasizes that software engineers must
be able to design and implement small
collections of classes as well as work with
a team on a large, complex system

In the future, we plan to have students
use a modeling tool to draw the UML dia-
grams. We would also like to more fully in-
vestigate the problems that arise when in-
troductory students work in teams. Further-
more, we would like to measure the extent
to which the analysis and design aspects of
this course prepare students for subsequent
courses and employment. 

References
1. B. Meyer, Object-Oriented Software Construction, 2nd

ed., Prentice Hall, Upper Saddle River, N.J., 1997.
2. M. Fowler and K. Scott, UML Distilled: Applying the

Standard Object Modeling Language, Addison-Wesley,
Boston, 1997.

3. J.P. Tremblay and G.A. Cheston, Data Structures and
Software Development in an Object-Oriented Domain:
Java Edition, Prentice Hall, Upper Saddle River, N.J.,
2003.

4. J.P. Tremblay and G.A. Cheston, Data Structures and
Software Development in an Object-Oriented Do-
main: Eiffel Edition, Prentice Hall, Upper Saddle
River, N.J., 2001.

For more information on this or ny other computing topic, please visit our
Digital Library at http://computer.org/publications/dlib.

S e p t e m b e r / O c t o b e r  2 0 0 2 I E E E  S O F T W A R E 7 1

About the Authors

Grant A. Cheston is a professor in the computer science department at the University
of Saskatchewan. With Jean-Paul Tremblay, he has coauthored the Eiffel and Java editions of
Data Structures and Software Development in an Object-Oriented Domain (Prentice Hall, 2001
and 2003). His research interests are in the graph algorithms area. He has a PhD in computer
science from the University of Toronto. Contact him at the Dept. of Computer Science, 57 Cam-
pus Dr., Saskatoon, Saskatchewan, S7N 5A9, Canada; cheston@cs.usask.ca.

Jean-Paul Tremblay is a computer science professor at the University of Saskatch-
ewan. In addition to the books coauthored with Grant Cheston, he coauthored Discrete Mathe-
matics: A Computer Science Perspective (Prentice Hall, 1996) and several books in the 
McGraw-Hill Computer Science Series. He has a PhD in computer science from the Case Insti-
tute of Technology. Contact him at the Dept. of Computer Science, 57 Campus Dr., Saskatoon,
Saskatchewan, S7N 5A9, Canada; tremblay@cs.usask.ca.

computer.org/e-News

Available for 
FREE to members.

Good news for your in-box.

Be alerted to

• articles and 
special issues 

• conference news

• submission 
and registration
deadlines

• interactive 
forums

Sign Up Today 
for the IEEE 

Computer 
Society’s
e-News

Sign Up Today 
for the IEEE 

Computer 
Society’s
e-News



7 2 I E E E  S O F T W A R E S e p t e m b e r / O c t o b e r  2 0 0 2 0 7 4 0 - 7 4 5 9 / 0 2 / $ 1 7 . 0 0  ©  2 0 0 2  I E E E

To meet industry’s needs, many computer
science programs now offer software proj-
ect courses.1 Course methods vary, however,
and there is little agreement as to what the
courses should cover. Most academic pro-
grams have at least one software engineer-
ing overview course and a few offer several
courses on the subject. 

At Embry-Riddle Aeronautical Univer-
sity, students learn the Personal Software
Process2,3 in their first year, and the Intro-
ductory Team Software Process4 in their
second and third years. The PSP uses a
phased development paradigm to teach
students fundamental engineering prac-
tices. The TSPi course teaches teamwork-
ing methods and exposes students to the
practical issues and problems of team-
based product development. Many other
schools are taking an approach similar to
ERAU’s, and some schools have even insti-
tuted software engineering degree pro-
grams.5 This article reports on experiences
with the TSPi course at ERAU and at sev-
eral other institutions.

Software project courses 
In the latest draft of volume II of Com-

puting Curriculum 2001 (CC2001),6 the
CC2001 Task Force states that to help stu-
dents acquire professional skills as under-
graduates, all computer science programs
should include

� Early opportunities for teamwork
� A complex project (usually undertaken

in the senior year) designed and imple-
mented by small student teams 

Software project courses range from first-
year two- or three-student teams working on
brief (few-week) projects to one-year senior-
level courses in which student teams work for
real or quasi-real customers. At some univer-
sities (Carnegie Mellon, Georgia Tech, and
the Milwaukee School of Engineering, for ex-
ample), students join ongoing laboratory- or
studio-based software projects that might in-
volve both development and maintenance.7–9

One hotly debated issue is the degree to
which project courses should incorporate

focus
Teaching Teamwork

Thomas B. Hilburn, Embry-Riddle Aeronautical University

Watts S. Humphrey, Software Engineering Institute, Carnegie Mellon University

Software developers
need training in
software
engineering, but few
computer science
programs offer such
courses. Project
courses that use 
a defined team
process prepare
students to build
quality software
products under
real-world
constraints.

T
he software industry needs engineers who know how to produce
quality products on schedule. Because computer science pro-
grams do not typically teach engineering concepts or practices,
students often start their professional careers with little under-

standing or appreciation of the discipline needed to build quality products
or the methods needed to keep projects within cost and schedule con-
straints. As a result, industrial software groups generally work without
plans and have serious schedule and quality problems. 

educating software professionals



real-world experiences. One side advocates
exposing students to real projects with vague
and unstable requirements and unrealistic (or
unmanageable) schedule constraints—a “sink
or swim” strategy. The other side promotes
developing toy projects with stable require-
ments and realistic schedules in a familiar de-
velopment environment. Most project courses
fit somewhere between these two extremes. 

Designing a project course
The academic environment places some

special constraints on project courses. First,
you must restrict the course to a single term
or plan, manage, and coordinate it over sev-
eral terms. The dynamics of typical student
populations make it difficult to maintain
stable team membership for more than a
single term. Moreover, academic environ-
ments can rarely find users to test multiple
versions of the completed products. 

The second problem concerns team forma-
tion. Computing faculty rarely have training
or experience in creating effective software
teams. Forming and building teams involves

� Selecting team members 
� Assigning team roles 
� Building cohesive units
� Assessing progress
� Providing meaningful advice and guidance

Third is the problem of project oversight
and guidance. A software project course
should not focus solely on producing work-
ing computer programs. It must teach the
proper use of accepted engineering practices,
such as project estimation and planning, re-
quirements analysis and specification, and
high-level and detailed design. These courses
must also address practical project issues—
for example, task scheduling and tracking,
quality measurement and management, and
phased development and control.

Unfortunately, the typical undergraduate
computer science curriculum does not in-
clude these practices, and few faculty can
provide practical and specific guidance in
these areas. Without explicit guidance, most
student projects become lessons in how not
to develop software. Indeed, most of today’s
software developers learned to program by
learning a programming language, with little
or no guidance on disciplined methods or
quality practices.

The Introductory
Team Software
Process

To address these in-
dustrial and academic
problems, the Software
Engineering Institute has
developed a family of
process improvement
methods for individuals,
teams, and organiza-
tions. The PSP helps stu-
dents and professional
software engineers or-
ganize and plan their
work, track their pro-
gress, manage software
quality, and analyze and
improve their perform-
ance.2,3 It provides the necessary foundation
for subsequent team-working courses. More
than 30 institutions now offer introductory
and graduate-level PSP courses. 

Once trained in the PSP, students take a
software project course using the TSPi, which
is an academic version of the Team Software
Process that industrial software teams use.
TSPi support materials include a textbook, an
instructor’s guide, a support tool, and all the
scripts, forms, standards, and methods
needed to develop quality software products.4

The TSPi process divides a software de-
velopment project into development cycles,
with the team producing part of the product
in each cycle. Figure 1 shows the TSPi
processes and their cyclic structure. De-
pending on the course constraints, students
can complete two or three cycles in a one-
semester course. In the final cycle, students
integrate and test the finished system. 

Process description
The TSPi starts with team building. Dur-

ing project launch, students form teams (of
four to six students), establish team struc-
ture, and produce a project plan. This pro-
vides the essential foundation for a success-
ful project. Teams then set measurable goals
and objectives. For example, a team might
state a quality goal as

� Team goal—Produce a quality product.
� Measure 1—More than 80 percent of the

defects will be found before the first
compile.

S e p t e m b e r / O c t o b e r  2 0 0 2 I E E E  S O F T W A R E 7 3

Product need

Cycle 1
Cycle 2

Cycle 3

Launch

Strategy

Plan

Requirements

Design

Implementation

Test

Postmortem

Launch

Strategy

Plan

Requirements

Design

Implementation

Test

Postmortem

Launch

Strategy

Plan

Requirements

Design

Implementation

Test

Postmortem

Finished
product

Figure 1. Introductory
Team Software
Process structure and
flow. Development
teams produce the
software product in 
a series of cycles, 
integrating and 
testing the completed
system in the final
cycle.



� Measure 2—No defects will be found
during system test.

� Measure 3—At project completion, all
product requirements will be correctly
implemented.

One of the most important factors in ef-
fective team building is defining clear roles
for each team member. Table 1 describes the
TSPi roles. The process details the responsi-
bilities and activities for each role during
each phase. Thus, at the beginning of the
project, students understand their roles and
know what is expected each week. 

The TSPi process covers all of the essential
elements for effective quality management—
for example, test planning during the require-
ments and design phases and structured test
plan reviews. Each team formally inspects the
requirements and design specifications and
holds both personal code reviews and peer
code inspections of each product unit. 

Students receive review and inspection
process documentation that includes process
scripts, guidelines for developing review
checklists, and forms for recording and re-
porting inspection data. Because all TSPi 
artifacts receive quality reviews and inspec-
tions, student teams generally produce quality 
products.

During the planning cycle, teams pro-
duce a comprehensive plan that includes 

� A list of the products to be produced
and their estimated sizes

� A list of tasks to be completed and the
team member responsible for each task

� Estimated effort to complete each task
� A week-by-week schedule that identifies

the tasks to be completed and the avail-
able student work hours

� A quality plan that estimates defects to
be injected and removed in each devel-
opment phase

� A template summarizing the product’s
estimated and actual size, effort, and de-
fect data

TSPi teams develop and track their plans
with a spreadsheet tool developed by the
SEI. This tool supplies a host of metrics
with which faculty and students can track
and assess process fidelity, product quality,
plan accuracy, and project status. 

Faculty and student feedback
More than a dozen university computing

programs have used TSPi in software project
courses. Several schools, including Auburn
University, Carnegie Mellon University, and
the University of South Carolina, have shared
with us their experiences using the TSPi in
both undergraduate and graduate courses. In
most cases, instructors presented TSPi mate-
rial in a laboratory setting using a combina-
tion of lecture and informal coaching.

While course results varied considerably, all
faculty felt that the TSPi course was worth-
while. Many also found that they could adapt
the material to the level, background, and so-
phistication of their students. Not surprisingly,
instructors who had used the TSPi several
times reported greater success and satisfaction
than those who taught it only once. 

Early problems resulted from defects in
the initial version of the TSPi tool as well as
its size—it was too big to easily distribute for
team use. Also important was students’ PSP
preparation. The better their preparation,
the more likely they were to appreciate and
properly use the TSPi process. The following
quotes are faculty reactions to the TSPi
process and course.

� “TSPi gives very good material and in-
sights about how to help students organ-
ize as a team: role definition, visible com-
mitments, meeting organization, sched-
ule, and so on.”

� “I think the TSPi is a very good vehicle
for teaching a project course once the
students have PSP knowledge… it pro-
vides a lot of good, usable structure that
students can pick up, try out, and take
away from the course to their jobs.”

7 4 I E E E  S O F T W A R E S e p t e m b e r / O c t o b e r  2 0 0 2

Table 1
Introductory Team Software Process roles and responsibilities

Role Description
Team leader Leads the team and ensures that engineers report their process data and complete their work as planned
Development manager Leads and guides the team in product design, development, and testing
Planning manager Supports and guides the team in planning and tracking its work
Quality/process manager Supports the team in defining the process needs and establishing and managing the quality plan
Support manager Supports the team in determining, obtaining, and managing the tools needed to meet its technology and administrative

support needs



� “I will never teach a team project
course without TSP again!”

In general, students were most
positive when they studied PSP in
their first year and continued to use
it in subsequent courses. When in-
structors introduced PSP and TSPi
late in the curriculum, more students
objected to the required discipline.
Also, students who are already ac-
complished programmers and have
never experienced the industrial
quality and management problems
the PSP and TSP address, can be somewhat
negative, especially at the beginning of the
TSPi experience. 

The most common complaints about PSP
and TSP courses concern data gathering,
planning, tracking, and quality manage-
ment. Although these disciplines are not
easy to learn or practice, the best industrial
work requires them. Students who do not
learn these planning and quality manage-
ment skills through their coursework will
rarely learn them on the job. 

Data analysis
The computer science program at ERAU

introduces the TSPi in a second- or third-year
undergraduate team project course focusing
on software engineering fundamentals. Pre-
requisites are programming experience in an
object-oriented language (such as Ada, C++,
and Java) and PSP experience. 

The TSPi course aims to expose students
to software team project issues, principles,
methods, and technology. Because about
one-third of the course time is devoted to
software engineering lectures and discus-
sions, there is only time for a two-cycle
process. Each team follows the TSPi process
but adds a customer review at the end of the
first cycle and a more formal customer ac-
ceptance test at the end of the second, with
the instructor acting as the customer. 

For consistency, we took the TSPi data in
the following analyses from the ERAU
courses. Since Fall 1998, ERAU has offered
the TSPi course each semester. Through
Spring 2001, 42 teams had completed proj-
ects using the process. Each team collected
data on task completion time, defects found
in review, compilation, testing, and size of re-
sulting artifacts. They entered these data into

the TSPi tool to produce metrics for tracking
progress, planning support, and assessing
product quality and team performance. 

In analyzing data from the 42 ERAU
teams, we found several errors and omis-
sions. Also, data from the course’s first year
were organized differently from other years
or were not available. For this article, we
identified 18 teams that reasonably repre-
sent the work you can expect when students
follow the TSPi process properly. Table 2
summarizes the data from these 18 teams.
While they produced slightly more code in
cycle 1 than in cycle 2, the cycle-2 code was
generally more complex. We attribute the
greater productivity in cycle 2 to the teams’
better understanding of the TSPi and in-
creased efficiency. 

Defect density did not significantly im-
prove from cycle 1 to cycle 2, but test defects
increased. This is partly due to increased
code complexity but also likely indicates that
teams discovered defects in the second cycle
that they had missed in the first. Most im-
portantly, the teams had not yet developed
effective precompile reviews, as evidenced by
cycle 2’s average code-review rate of 309
lines per hour—well above the recommended
maximum rate of 200 lines per hour. This
area requires improvement. 

Teams estimated effort quite accurately for
cycle 1 but overestimated effort for cycle 2.
This occurred because the teams based their
cycle-2 plans on cycle-1 data, but their aver-
age productivity improved 66 percent from
cycle 1 to cycle 2. In a three-cycle course, the
students would have recognized and cor-
rected the problem. Figure 2 shows the effort
distribution over the development phases. 

The 15.6 percent of effort devoted to re-
quirements is appropriate for the problem size

S e p t e m b e r / O c t o b e r  2 0 0 2 I E E E  S O F T W A R E 7 5

Table 2
TSPi data from 18 teams

Metric Minimum Average Maximum
Size (LOC), cycle 1 485 692 1,015
Size (LOC), cycle 2 269 610 1,112
Effort (hours), cycle 1 99 211 251
Effort (hours), cycle 2 72 119 217
Productivity (LOC/hr), cycle 1 2.2 3.5 5.0
Productivity (LOC/hr), cycle 2 2.0 5.8 12.3
Defect density (def/KLOC), cycle 1 56.5 105.1 174.6
Defect density (def/KLOC), cycle 2 44.2 93.0 219.1
Test defect density (def/KLOC), cycle 1 2.5 9.6 20.0
Test defect density (def/KLOC), cycle 2 0.0 25.4 83.0
Effort estimation error, cycle 1 0.3% 10.8% 31.8%
Effort estimation error, cycle 2 2.7% 30.9% 53.0%



and complexity, but the 13 percent spent on
design is much too low and is probably one
reason for the high test defect density. The
course introduces a simple object-oriented de-
sign methodology, but students do not get in-
tense design experience until a follow-up jun-
ior-level software analysis and design course. 

Figure 3 shows the average defects injected
and removed in each project phase. As shown,
teams found and removed about 80 percent of
the defects before testing began. This is re-
markable for sophomore and junior student
teams.

Student assessment
After each cycle, students completed an

anonymous survey. Students, especially those
who had been involved in previous team
projects, were generally positive about their
experiences. About 75 percent of the students
were positive about TSPi, and more than 90
percent felt that working on a team project
was a worthwhile learning experience.

The survey also included questions about
what students liked most and least about the
course. Overwhelmingly, students were most
positive about having clearly defined roles
and a process that describes the tasks for each
project phase. The biggest complaint was the
amount of paperwork involved. Although
most students grudgingly admitted that doc-
umentation, data collection, and data analy-
sis were important, they did not enjoy it.

Course suggestions
Designing and implementing a software

project course can be challenging and de-
manding. Faculty who have taught such
courses will tell you that a successful teacher
must work hard, properly plan and prepare,
track team progress, and assess both the
team members’ work and their products. To
improve the likelihood of a successful effort,
you should follow several guidelines. 

First, clearly identify course goals. Incom-
plete or fuzzy goals lead to incomplete or
fuzzy results. Second, if the course is time-re-
stricted or will represent students’ first team
project experience, use a modest and well-de-
fined problem. Real-world, complex problems
can doom a team to frustration and failure. 

Third, use a defined team process for the
project work. We believe the TSPi includes all
the elements needed to build, guide, and sup-
port effective teams. However, whatever
process you use, be sure it includes 

� A detailed written description of the
project and the process to be used. This
should include support for planning,
tracking, and configuration manage-
ment; procedures and standards for re-
quirements, design, implementation, and
testing; and methods and procedures for
inspections and reviews.

� A description of team roles and associ-
ated responsibilities.

� A list of data teams should collect for
use in tracking and assessing perform-
ance and product quality. 

� A cyclic development approach. We be-
lieve incremental development is not
only good engineering practice but is a
pedagogically sound method of teaching
and learning.

Fourth, enforce process discipline (phased
development, data collection, documentation
standards, reviews and inspections, and so
on). After you have decided what activities
and deliverables are important, make sure
your students follow the process. Students do
not easily accept or understand the need for
process discipline. Most students (and many
software engineers), for example, do not en-
joy documenting project work, but few will
debate the need for it. As teachers, we must
motivate and help our students understand
the need for discipline. Easily acquiescing to

7 6 I E E E  S O F T W A R E S e p t e m b e r / O c t o b e r  2 0 0 2

Plan 13.8
Requirements

15.6

Design 13.0

Test 13.1
Miscellaneous and

analysis 31.5Implementation13.1

Figure 2. Effort 
by phase (in 
percentages). 
“Miscellaneous and
analysis” includes
the launch and 
postmortem phases
as well as the team’s
preparation of a 
final report and 
presentation. “Plan”
includes both the
strategy and 
planning phases.

De
fe

ct
s 

(in
 p

er
ce

nt
ag

es
)

90
80
70
60
50
40
30
20
10
0

Defects 
injected

Defects 
removed

Req
uire

me
nts

Des
ign

Imp
lem

ent
atio

n Tes
t

Figure 3. Defects by
phase. Students 
discovered and 
removed most defects
before testing began.



complaints and criticism can
cause teams to lose confidence
in the process and produce a
chaotic “process du jour” work
environment. 

Finally, the course instructor
should move from the lecturer
mode to a coaching mode.
Coaches not only explain meth-
ods and procedures for carrying
out tasks, they also track and ob-
serve team and individual per-
formance and help team mem-
bers improve. Moreover, they do
not throw teams into the big
game (an industrial-strength project) before
they have learned and practiced the basics
(with well-defined, modest projects).

Before initiating a TSPi-based course,
you should confer with other faculty who
have taught the process. We recommend
that you attend the TSPi faculty workshop
offered each summer (see the “Summer Fac-
ulty Workshop on the PSP and TSPi” side-
bar). We have also found that the PSP and
TSPi are most effective when integrated into
an entire software curriculum rather than
treated as isolated technologies.

A t Embry-Riddle, we have had excellentsuccess using TSPi in introductorysoftware engineering and senior
design courses. Of the 42 TSPi teams in the
introductory course, those that carefully
followed the process had the best performance
and produced the best products. However, all
teams finished on time with working products.
This is in marked contrast to our previous
experiences with team projects where many
were late or did not produce a working
product. Thus, “teaching teamwork” can
make a significant difference. 

Acknowledgments
We would like to thank the following faculty who

shared with us their TSPi experiences: Bob Cannon
(University of South Carolina), Rubby Casallas
(Rochester Institute of Technology), Jorge Diaz-Her-
rera (Southern Polytechnic University), Greg Hislop
(Drexel University), Keith Olson (Montana Tech),
Mark Sebern (Milwaukee School of Engineering), Jim
Tomayko (Carnegie Mellon University), and David
Umphress (Auburn University).

Several reviewers kindly assisted us in preparing
this article. We very much appreciate the helpful com-
ments of Julia Mullaney, Bob Musson, and Bill Peter-
son. We also thank the IEEE Computer Society re-
viewers for their insightful comments and suggestions.
Our thanks also go to the IEEE Computer Society edi-
torial staff for their professional assistance in produc-
ing the finished article.

The Personal Software Process, PSP, Team Soft-
ware Process, and TSP are service marks of Carnegie
Mellon University.

References
1. S. Jarzabek, ed., “Teaching Software Project Courses,”

Forum for Advancing Software Eng. Education (FASE),
vol. 11, no. 6, June 2001, www.cs.ttu.edu/fase.

2. W.S. Humphrey, A Discipline for Software Eng., Addi-
son-Wesley, Boston, 1995. 

3. W.S. Humphrey, Introduction to the Personal Software
Process, Addison-Wesley, Boston, 1997.

4. W.S. Humphrey, Introduction to the Team Software
Process, Addison-Wesley, Boston, 2000. 

5. K. Modesitt, “Annual Survey of SE Academic Pro-
grams,” Forum for Advancing Software Eng. Education
(FASE), vol. 10, no. 11, Nov. 2000,
www.cs.ttu.edu/fase.

6. Joint IEEE Computer Soc./ACM Task Force on Com-
puting Curriculum, Computing Curriculum 2001, vol.
II, Dec. 2001, www.computer.org/education/cc2001. 

7. D. Garlan, D. Gluch, and J.E. Tomayko, “Agents of
Change: Educating Software Engineering Leaders,”
Computer, vol. 30, no. 11, Nov. 1997, pp. 59–65.

8. M. Moore and C. Potts, “Learning by Doing: Goals
and Experiences of Two Software Engineering Project
Courses,” Proc. 7th Software Eng. Inst. Conf. Software
Eng. Education, Springer-Verlag, New York, Jan. 1994,
pp. 151–164.

9. M.J. Sebern, “The Software Development Laboratory:
Incorporating Industrial Practice in an Academic Envi-
ronment,” Proc. 15th Conf. Software Eng. Education
and Training, IEEE CS Press, Los Alamitos, Calif.,
2002, pp. 118–127. 

For more information on this or any other computing topic, please visit our
Digital Library at http://computer.org/publications/dlib.

S e p t e m b e r / O c t o b e r  2 0 0 2 I E E E  S O F T W A R E 7 7

For the past six years, the Software Engineering Institute has sponsored a summer fac-
ulty workshop on the Personal Software Process (PSP) and the Introductory Team Software
Process (TSPi). In July 2002, the SEI and the US National Science Foundation cosponsored
a one-week workshop, “Teaching a Software Team Project Course: Improve Team Perfor-
mance by Teaching Engineering to Teams,” at Southern Polytechnic State University in At-
lanta, Georgia. The workshop aimed to prepare faculty participants to

� Develop and implement a software project course or activity that teaches students to
work effectively in teams to deliver a quality product on time and within budget

� Develop courses and curricula that include software process concepts and practices

The workshop also gave participants first-hand experience with both PSP and TSPi. You
can find details about future workshops at www.sei.cmu.edu/tsp/workshop.html.

Summer Faculty Workshop on the PSP and TSPi

About the Authors

Watts Humphrey’s biography 
appears on page 24. 

Thomas B. Hilburn’s biography
appears on page 24.



7 8 I E E E  S O F T W A R E S e p t e m b e r / O c t o b e r  2 0 0 2 0 7 4 0 - 7 4 5 9 / 0 2 / $ 1 7 . 0 0  ©  2 0 0 2  I E E E

Some in the academic community might
argue that such reality-based software de-
velopment reflects industry practice. This
might be an accurate generalization of the
past, but recent trends suggest that a pur-
poseful and disciplined approach to soft-
ware development is more effective than an
extemporaneous one.1 Organizations (such
as Raytheon2 and General Dynamics3) are
making conscious efforts to transform proj-
ects from initiation rites that yield next-
time-I’ll-do-it-differently lessons into being
ventures that promote this-worked-and-I’ll-
do-it-again experiences. They see software
development as more than a grab bag of
technical undertakings—they envision it as
the purposeful orchestration of technical
and nontechnical activities. We can mirror
this vision—and hopefully the successes—in
college project courses if we are prepared to
accept what industry is learning. The lesson

is that software development requires disci-
pline, and we can foster discipline using
well-conceived software processes.

We outline our rationale for moving from
a product-oriented approach to a process-
oriented one, our experiences in determining
suitable process weight, and lessons we
learned in attempting to make reality-based
software experiences less painful and more
real.

Using processes in the software
engineering classroom

Using processes to develop software in
the college classroom has mirrored industry
history (see the “A Brief Process History”
sidebar on page 81), although on a much
more attenuated and compressed time scale.
While most projects adhere to the classical
school of development, there is a growing
recognition by instructors of the usefulness

focus
Software Process in the
Classroom: The Capstone
Project Experience

David A. Umphress, T. Dean Hendrix, and James H. Cross, Auburn University

A process-oriented
perspective on large
student projects
guides students in
integrating end-to-
end life-cycle skills
and provides
consistency of
experience among
projects. The
authors discuss
what they learned
after conducting 49
capstone projects.

I
magine the traditional college project course: students bunch together
in groups, are assigned a sizable software development task, and are
told to “have at it.” Instructors expect them to integrate the technical
skills they’ve learned in previous courses, learn to work synergistically

as a team, plan and track their work, satisfy their customer—and produce
sound software. Yet, more often than not, projects so framed teach their
participants yet another way not to develop software.

educating software professionals



of process, however meager, for student
projects in the academic world.

Although much can be said for the feel-
ings of freedom and independence gained by
letting students build software as they
please, the simple fact is that most students
have not been taught beginning-to-end proj-
ect skills. Current computer science and
software engineering curricular models en-
sure students have taken a variety of classes
relating to programming. However, this
does not assure that they have integrated the
knowledge they gained in coursework into a
comprehensive and functioning whole, nor
does it guarantee that they have the social
skills required for a successful project.

Using software processes in the classroom
helps in three ways. First, the processes de-
scribe the tasks that students must accom-
plish to build software. Suitably detailed, a
process model can describe the life-cycle ac-
tivities: their sequence and starting and
stopping conditions. It can also define the
project’s artifacts, outlining their appear-
ance, content, and the method students
should use to build them. In a sense,
processes let students focus on the creative
task of building software by defining activi-
ties instead of wasting time inventing them.
Second, processes can give the instructor
visibility into the project. Viewed this way,
they describe the rules under which the
project operates. The instructor can query
students on their progress down to the
granularity of the process description; stu-
dents follow the rules outlined in the
process to report status to the instructor.
Third, processes can provide continuity and
corporate memory across academic terms.
Instructors can build solutions to general
project problems into processes, thus improv-
ing the project’s educational worth over time.

Capstone projects 
We have concluded 49 capstone software

development projects, 27 of which used var-
ious process-oriented approaches. Each proj-
ect entailed a team of three to five students
developing new software or making signifi-
cant enhancements to existing software. All
the projects involved a customer who used
the product after delivery. We conducted the
projects at the graduate and undergraduate
levels. Graduate teams worked for a year,
while undergraduate teams worked for a sin-

gle academic term. On average, graduate
students had five years of software develop-
ment experience; undergraduates generally
had no professional exposure. All students
had taken programming-intensive classes
and at least one design class before starting
their project. Most students had completed a
software process class. Projects ranged
widely in domain, programming language,
and hardware platform; examples included
constructing software tools in Java for desk-
top computers, developing controllers in C
for embedded hardware, and building proj-
ect-tracking tools in Visual Basic for hand-
held computers. 

Software process trends in student teams
Our outlook on process follows the his-

tory of industry trends; that is, we started
with no process, injected too much process,
and then backed off to what we felt was a
satisfactory balance of discipline and chaos.
Indeed, we found that injecting process into
the academic environment requires the same
technology transition skills and tools used
in industry.

Our traditional capstone projects fol-
lowed the classical school of software devel-
opment. Although each team developed
software for widely differing customers and
domains, the projects were similar in na-
ture: They captured requirements and de-
signs, but seldom validated or verified them.
Teams ignored designs in the heat of final
deadlines. The bulk of the project work
came at the end of the project, and was nor-
mally done by a small subset of the team
working exhaustive, long hours. Project
documentation was pretty, but generally
vacuous. It was often relegated to the
weaker members of the team as a way of
providing them a task that got them out of
the way of the software construction. Re-
quirements were scaled down from the ini-
tial promises to the customer, usually near
the project’s end. The product delivered by
the team could not fully pass customer-
designated acceptance tests. Delivered soft-
ware consisted of graphical user interfaces
with little functionality underneath. Cus-
tomers could seldom install the software
without significant assistance.

Three themes emerged from the post-
mortem analyses we conducted across the
projects. First, teams had difficulty balanc-

S e p t e m b e r / O c t o b e r  2 0 0 2 I E E E  S O F T W A R E 7 9

We started with
no process,
injected too

much process,
and then backed
off to what we

felt was a
satisfactory
balance of

discipline and
chaos.



ing the workload throughout the project.
They conducted elaborate requirements
statements and designs, but then discovered
that they had underestimated the technical
prowess necessary to implement the product
within the project time frame. In most cases,
their designs relied on mental models of
how they thought software components—
either prebuilt or organic—worked, only to
discover later that those models were in-
complete, too simple, or erroneous. Because
they typically followed a waterfall-like life-
cycle, they discarded their carefully crafted
soft upstream project artifacts when build-
ing hard deliverables. Even when teams
built software in iterative cycles, they
tended to first concentrate on features they
knew how to write and delayed working on
technically difficult or complex features.
Projects thus consisted of large amounts of
unproductive work punctuated with short
bursts of intense development.

Second, skills that students learned in
their course work did not scale well to mul-
tiple-person large projects. Configuration
management was the most obvious stum-
bling block. Many teams did not have a
mechanism for controlling their source code,
claiming that such measures added un-
wanted overhead. Instead, they placed their
code in a central repository, copied needed
files to their local workspaces, made
changes, and then replaced the files without
regard to whether the original contents had
changed in the interim. They depended on
email and word of mouth to control inad-
vertent file destruction. Not only did these
informal communication methods break
down with erratic work schedules, but the
overall scheme of continually evolving the
software prevented falling back to known
baselines in times of trouble. Additionally,
teams reported that they did not track de-
fects, especially in the project’s final stages,
and often did not know if bug fixes were
ever incorporated into the delivered product.

Finally, team members’ responsibilities
were not clear. Although all project partici-
pants had some technical background, few
had training in team dynamics. At the proj-
ect onset, teams invariably organized
around an egoless model without a formal
leader and few defined roles. They rational-
ized that this model advocated the most po-
lite form of team government: students gen-

erally felt uncomfortable about presuming a
self-appointed leadership role and waited
for a natural leader to emerge. They felt
similarly about other team responsibilities,
assuming that team members would natu-
rally gravitate to whatever tasks felt most
comfortable to them. Although some teams
contained the right personalities for this
to work, most teams quickly became rud-
derless committees with few clear lines of
accountability for project activities. Team
members with weak skills or shy personali-
ties eluded productive work by shielding
themselves behind ambiguous role expecta-
tions. Members with strong personalities,
not wishing to receive a poor grade, com-
pensated for weaker members by taking on
additional work, thus paving the way for ill
feelings. Once the personality of the team fi-
nally emerged, it was often one of cliques,
contention, and miscommunication.

Interestingly, during project postmortems,
technical programming skills surfaced as
only a minor concern. The team participants
felt they were adequately equipped to write
code. What they lacked were skills to deal
with integrated project issues. They needed
guidance—at some level of abstraction—on
how to develop software. In other words,
they needed a process. 

Process 1: MIL-STD-498
We chose to adapt MIL-STD-4984 as the

first process model, abandoning an initial
attempt to cobble together a software devel-
opment process from scratch as too con-
trived. We chose this standard because it
was actively used at the time, described in-
formation requirements of numerous soft-
ware life-cycle activities, and was free. 

Working with the customer and the proj-
ect supervisor, each team spent the project’s
first week editing the MIL-STD-498 docu-
ment specifications to meet project particu-
lars. This period’s goal was to have each
team define how it would conduct project
business. In reality, this did not happen. Just
as traditional teams spent precious upfront
time putting together intricate but unrealis-
tic designs, these new teams developed elab-
orate process descriptions that they soon
jettisoned as too complex. Projects devolved
to ad hoc development, but with standard-
ized documentation.

In retrospect, choosing MIL-STD-498

8 0 I E E E  S O F T W A R E S e p t e m b e r / O c t o b e r  2 0 0 2

Skills that
students
learned 
in their 

course work
did not 

scale well to
multiple-person
large projects.



was naïve. We thought team participants
would be able to define how to conduct a
project if they knew what content they
needed to produce for project documents.
Taking the view that documentation is a
side effect of the software development ef-
fort, we thus thought our students would
use the documentation templates as guides
as to what activities they should perform. 

For seasoned software developers, this is

not an unrealistic expectation. However, the
student teams perceived the main focus of
their work to be documentation, not soft-
ware. The standard outlined the content of
artifacts resulting from each life-cycle stage,
but it did little to help them identify and
organize development tasks that would
produce the artifacts. Project postmortems
showed that the generic MIL-STD-498 was
too abstract to achieve reasonable consis-

S e p t e m b e r / O c t o b e r  2 0 0 2 I E E E  S O F T W A R E 8 1

Two disparate schools of thought regarding software devel-
opment have emerged from the software industry over the past
25 years. The classical school views building software primarily
as a product-driven activity, one that treats software as a
“thing” with little regard to how it was developed. It professes
that anyone with suitable programming skills can write software
and that activities leading to a software product are free form
and chaotic by nature. This school obtained and retains its out-
look from programming’s early days, a time in which software
development was a cottage industry that depended on expert
artisans to craft software. Its hallmarks are reliance on gurus
and heroes, homegrown methods and techniques, and a body
of knowledge that is largely anecdotal. 

A contemporary school of thought appeared in the 1970s.
This school drew its ideals heavily from the manufacturing sec-
tor and, as such, emphasized that the way software is built de-
termines, to a large extent, the end product’s quality and the
developers’ quality of life. This view of software as a process-
driven activity recognizes the value of technical prowess central
to the classical school but suggests more. It proposes that soft-
ware construction is not a free-for-all but rather is best done
under circumstances in which relationships between key devel-
opment activities are defined explicitly. These relationships, also
known as processes, identify the tasks needed to produce a
software product of known quality.

Most projects in industry today fall on a continuum some-
where between the classical and contemporary camps. Of par-
ticular interest is what portion of the continuum the industry em-
phasizes at any point in time. 

The industry primarily focused on the classical school in
programming’s early days. Methodological processes describ-
ing the technical steps for building software appeared in the
1970s. These processes, combined with the industry’s interest
in software life-cycles, pushed the philosophical focus away
from pure programming classicism. This shift became more
pronounced in the 1980s with the US government’s move to
contain costs in embedded system software. This was mani-
fested with the Ada movement and its attempts to marshal
frameworks for common methods and tools. DOD-STD-2167
and subsequent military and industry efforts to standardize
high-level life-cycle activities fueled the momentum toward the

contemporary school during this time. The 1990s saw possibly
the height of the process dialectic with the application of the
ISO 9000 series to software development and the Capability
Maturity Model for Software. Numerous process models ap-
peared at this time, including MIL-STD-498 and IEEE 1074 
(for a comprehensive history, see Yingxu Wang’s and Graham
King’s Software Engineering Processes: Principles and Applica-
tions1).

Focus on the contemporary philosophy took an interesting
turn of events in the mid-1990s. Until this point, the working
assumption was a more-is-better attitude in defining the way in
which software is built. Standardized and de facto process
models touched on virtually every development aspect. Empiri-
cal evidence showed that process discipline improved projects’
ability to contain cost, schedule, and defects;2 but this discipline
came at a cost. Operating an organization at CMM Level 5,
fully compliant IEEE 1074, or other so-called heavyweight
process meant overhead in the process’s care and nurturing.
Many developers felt encumbered by unnecessary bureaucracy
in strongly process-driven efforts. 

This led to a grass roots backlash in the late 1990s and
early 2000s against heavyweight processes to process models
that were not as confining. Lightweight processes—now known
as agile processes—appeared to establish equilibrium between
the classical and contemporary extremes, consequently shifting
the development focus to a more nonpartisan part of the philo-
sophical continuum.3 Processes and process patterns, including
Extreme Programming, Scrum, Adaptive Software Develop-
ment, and Crystal, are currently embraced by the industry as
ways of providing some of the contemporary school’s engineer-
ing discipline, while leaving room for the classical school’s raw
creative horsepower.4

References 
1. Y. Wang and G. King, Software Engineering Processes: Principles and Appli-

cations, CRC Press, Boca Raton, Fla., 2000.
2. S. McConnell, “The Business Case for Better Software Practices 2002 Keynote,”

2002, www.construx.com/BusinessCaseForSoftwarePractices-Keynote.pdf.
3. M. Fowler and J. Highsmith, “The Agile Manifesto,” Software Development,

vol. 9, no. 8, Aug. 2001, pp. 28–32.
4. M. Fowler, “Put Your Process on a Diet,” Software Development, vol. 8, no. 12,

Dec. 2000, pp. 32–37.

A Brief Process History



tency among teams without a significant
amount of added detail. Although teams
that used MIL-STD-498 for their project re-
fined the standard slightly for subsequent
teams, it retained a document-centric aura
that crippled its acceptance by the students. 

Process 2: IEEE 1074
We tailored the documentation templates

of MIL-STD-498 to the bare minimum and
then turned to IEEE 10745 to add an activ-
ity-centric flavor to the software develop-
ment process. We chose this because it enu-
merated a development project’s activities
and described the interchange of project ar-
tifacts among those activities. Thus, IEEE
1074 described project tasks and MIL-STD-
498 described document formats.

Teams began their projects by defining
their own procedures for conducting ma-
jor technical development activities; that
is, they defined their own Software Life
Cycle Model Process and Development
Process portions of IEEE 1074. We pro-
vided them with procedures for perform-
ing activities with which they had little 
experience, such as configuration manage-
ment, product installation, project moni-
toring, and so on. In short, we gave them
instructions on how they should carry
out the standard’s Project Management,
Pre-Development, Post-Development, and
Integral processes. 

Here again, the teams were overwhelmed
with the process’s weight. The portion of
the process we provided was a hefty 41
pages, to which we expected the project
teams to add their individual process de-
scriptions (usually amounting to approxi-
mately 10 pages). Our document shrank to
20 pages over two years, but never seemed
to be distilled to a kernel that could capture
the students’ imagination and dispel their
suspicions of unnecessary bureaucracy.

Like the MIL-STD-498 experience, teams
using IEEE 1074 developed procedures that
were well intentioned but unrealistic. Team
participants had been writing code in an ad
hoc fashion throughout their college educa-
tion; consequently, defining technical tasks
that team members could carry out uni-
formly was unfamiliar territory. Team
processes typically polarized: they were ei-
ther so vague that they were of little guid-
ance, or so legalistic that they were imprac-

tical to implement and monitor. 
The intended effect of using IEEE 1074

was to show the teams that they could ap-
ply discipline to software development.
However, because they had not experienced
processes independent of structured class-
room assignments, at the project’s outset,
the teams focused their attention more
on satisfying the process than on build-
ing a product. On average, several weeks
passed before they adapted and adopted
the process. Because of process overhead,
IEEE 1074 teams produced the same
amount of software in an entire project as
the ad hoc development teams produced
in several weeks, thus raising skepticism
among the students about a process-oriented
approach’s value.

Process 3: Team Software Process
Realizing that the process was encumber-

ing the product development, we moved
next in the direction of lightening the
process weight by adopting the Team
Software Process.6 Our students had more
success with this because the process de-
fined explicit project scripts and team roles.
The TSP was out-of-the-box ready—students
did not have to add their own process de-
scriptions.

Project teams understood the entire
process within the project’s first days and
could adjust it when needed. The time they
spent on the project was no longer concen-
trated at product delivery time but was dis-
tributed more evenly across the project. The
cyclic activities that the TSP promotes let
the students build, test, and deliver software
in manageable increments. Moreover, the
end-of-phase reviews that it prescribes gave
convenient points for the instructor and the
customer to provide feedback to the team. 

The downside of the process was in the
bookkeeping. Students overwhelmingly re-
jected the myriad forms that the the TSP re-
quires, even when those forms were avail-
able electronically. They felt imposed on to
follow the personal processes that the TSP
prescribes—so much so that we came to
doubt the veracity of process data we col-
lected by the project’s end. Candid post
mortems on these projects showed that the
students appreciated the high-level disci-
pline that the TSP imposed, but they balked
at the details.

Students
appreciated the

high-level
discipline that

the TSP
imposed, but

they balked at
the details.

8 2 I E E E  S O F T W A R E S e p t e m b e r / O c t o b e r  2 0 0 2



Process 4: Extreme Programming
We turned to Extreme Programming7 in

an effort to break out of the TSP’s heavy re-
liance on staff work. XP had the TSP-like
advantage of being simple and understand-
able. It also advocated an overall develop-
ment discipline in which project teams had
to produce demonstrable results at regular
intervals. Unlike the TSP, in which scripts
describe explicit instructions on conducting
various process activities, XP gives general
guidelines. XP philosophy reduces software
development processes to the bare essen-
tials. It stresses a working product over
elaborate documentation and measurements.
It was also on the cusp of the classical school
of thought; only its reliance on established,
predefined commonsense activities prevented
it from degenerating into chaos.

XP’s emphasis on getting software work-
ing early in the project and its relaxed ap-
proach to requirements and design appealed
to our project teams. It provided a suitably
welcoming bridge from the extemporaneous
software development of the classroom to a
more disciplined mindset required for the
project. Like the TSP, XP’s incremental cy-
cles smoothed the students’ effort across the
project. That we described the XP process
using guidelines rather than prescriptive
rules was not an obstacle. The guidelines
were sufficiently detailed and intuitive
enough to let the teams know what they
should be doing, yet abstract enough to let
the teams choose how best to carry them
out. Finally, project success—which we
measured by how the finished software met
customers’ expectations—surpassed that of
previous projects, whether they had used a
process or not. 

Conducting the projects using XP was
not without disadvantages. First, the project
teams collected little statistical process data.
XP’s project velocity let teams measure
progress, but the metric was not detailed
enough to provide any insight into process
improvement. The project velocity was sim-
ple to measure and difficult to conceal, thus
providing an accurate glimpse into project
progress, but we had to augment it with
other metrics. Second, student class sched-
ules made XP’s pair programming activity
unrealistic. Several project teams experi-
mented with programming in virtual pairs
using online collaborative tools, but they

stopped when their frustration with the
tools outweighed the perceived advantages
of pair programming. Third, our students
underestimated XP. They mistook its infor-
mality as an invitation to seat-of-the-pants
design and coding. We took special efforts
to point out that although XP’s published
descriptions seem casual, its mechanics of
system metaphors, design refactoring, de-
layed optimization, and configuration man-
agement require careful attention.

Lessons learned
Table 1 summarizes our experiences with

software processes, showing that the aca-
demic environment is not so different from
the industrial one. Indeed, it mirrors in
miniature industrial trends and attitudes to-
ward software development—software de-
veloped using the classical school of thought
was not meeting our customers’ needs. Our
developers could not produce a consistently
high-quality product by carrying out project
activities extemporaneously. For us, heavy-
weight processes—that is, processes that
were highly detailed and prescriptive—
reduced project ad-libbing; however, they
introduced a level of bureaucracy that inter-
fered with product development. Ironically,
like the classical school of thought, the end
result was software that did not meet our
customers’ needs. We had to find a suitable
process weight that balanced what was be-
ing built with how it was being built. This
then gave us sufficient control over projects
to maintain a relatively consistent level of
software quality and a relatively consistent
educational experience for the students.

So how can educators infuse process into
projects? We have five suggestions.

Develop a process culture
Introducing processes into the classroom

environment is not easier than injecting them
into the workplace. It requires careful work
with all project stakeholders (students, in-
structors, and customers) to educate them
on the processes’ purpose, obtain commit-
ments to abide by processes, identify
process boundaries, and so on. 

Seek agility
Students typically enjoy coding, but not

analyzing, designing, testing, and communi-
cating. Agile processes, such as XP, are easiest

S e p t e m b e r / O c t o b e r  2 0 0 2 I E E E  S O F T W A R E 8 3

Introducing
processes into
the classroom
environment is
not easier than
injecting them

into the
workplace.



for students to accept and perform because
the processes focus on working software as
the main artifact. In contrast, a heavyweight
process gives the impression of ponderous bu-
reaucracy. Matching the process weight to the
students’ abilities, expectations, and tolerance
is vital to a project’s success. None of the
process models we constructed are bad; in
fact, we used bits and pieces from each
process model in the subsequent one. We
found that, in our environment, lighter
process models more closely matched our stu-
dents’ culture. Specifically, XP was a suitable
process because it was malleable enough to fit
the diversity of our development efforts and
the variety of our students’ skills.

Develop a process infrastructure 
Giving the students a written process de-

scription is not enough. Instructors must also
provide them with process orientation and re-
sources they can use when they have a ques-
tion. Most importantly, students must have
the tools that support process activities. This
includes adequate hardware and software for
development, configuration management,
testing, method support, and so on. We cau-
tion others attempting this that the infrastruc-
ture must support the process, not subvert it.
Tools can influence the way in which students
carry out process activities. An ill-conceived
collection of tools can encourage actions the
process does not allow, resulting in a tool-
process impedance mismatch; on the other
hand, wisely selected tools can actually pro-
mote process discipline.

Use processes to focus learning 
Few students are skilled in all the techni-

cal and nontechnical activities that project
work requires; consequently, instructors
should develop processes that focus stu-
dents’ efforts on project learning objectives.
For instance, instructors might construct a
project process to give only light guidance
to tasks familiar to students. It might give
detailed, prescriptive guidance to unfamiliar
tasks that, if students invented it, would de-
tract from their learning objectives. It might
even describe a “meta” process for having
the students define their own tasks for a
particular segment of the project. 

Seek realism
Like its counterpart in industry, process

enactment in the classroom requires enforce-
ment and adjustment. Instructors should ex-
pect students to know the process and adhere
to its guidelines. In-project process audits
are effective tools for assessing process use
and perception. When a process-related prob-
lem arises, a mechanism should be in place
to change the process so that the problem is
not repeated in subsequent projects. Stu-
dents should not be denied success because
of a poor process; similarly, they should not
blame the process for their lack of success.

W e came to the hard realizationthat we were faced with the chal-lenge of infusing a new technol-
ogy—software processes—into the class-
room. Contrary to the conventional wisdom
that we could dictate to our students how
we wanted them to write software, we had
to carefully couple the software process to
the students’ abilities, expectations, and cul-

8 4 I E E E  S O F T W A R E S e p t e m b e r / O c t o b e r  2 0 0 2

Table 1
Process evolution over 49 capstone projects, with significant lessons learned

Ad hoc MIL-STD-498 IEEE 1074 Team Software Process Extreme Programming

Experience 22 projects over 5 projects over 10 projects 4 projects 8 projects
level 10 years 2 years over 4 years over 1 year over 1 year
Advantage Rite of passage Insight into artifact Insight into network  Understandable Emphasis of

content of project activities process commonsense approach
Disadvantage Product seldom Documentation-centric Complexity Paperwork Perceived

met customer outlook informality
expectations

Feature adopted Projects with Documentation templates Process framework Cyclic development, All except
and carried forward actual customers team roles pair programming
Biggest lesson Little control over Knowing documentation Overwhelming Process measurement Refactoring, configuration
learned project variability content does not unless tailored accuracy decreases management, and

necessarily lead to knowing as number of design simplicity
project activities measures increases are deceptively difficult



ture. None of the processes we used were in-
herently poor; we had to find the particular
process that matched our culture and let us
achieve the educational objectives of the
project course.

In the end, we found that introducing
processes into our capstone project courses
benefited our instructors, students, and cus-
tomers. Instructors have increased visibility
into projects, students have guidance on
how to conduct themselves, and customers
have a better engineered product. 

References
1. S. McConnell, “The Business Case for Better Software

Practices 2002 Keynote,” 2002, www.construx.com/
BusinessCaseForSoftwarePractices-Keynote.pdf.

2. P. Bowers, “Raytheon Stands Firm on Benefits of
Process Improvement,” CrossTalk, vol. 14, no. 3, Mar.
2001, pp. 9–12.

3. M. Diaz and J. King, “How CMM Impacts Quality,
Productivity, Rework, and the Bottom Line,”
CrossTalk, vol. 15, no. 3, Mar. 2002, pp. 9–14.

4. Defense Department MIL-STD-498, Software Develop-
ment and Documentation, Washington, D.C., 1994.

5. IEEE Std. 1074-1997, IEEE Standard for Developing
Software Life Cycle Processes, IEEE Press, Piscataway,
N.J., 1998.

6. W. Humphrey, Introduction to the Team Software
Process, Addison-Wesley, Boston, 2000.

7. K. Beck, Extreme Programming Explained, Addison-
Wesley, Boston, 2000.

For more information on this or any other computing topic, please visit our
Digital Library at http://computer.org/publications/dlib.

About the Authors

T. Dean Hendrix is an associate professor of
computer science and software engineering at
Auburn University. His research areas are software
engineering, software visualization, and reverse en-
gineering. He received his PhD from Auburn Uni-
versity. Contact him at the Department of Computer
Science and Software Engineering, 107 Dunstan
Hall, Auburn University, AL 36849; hendrix@eng.
auburn.edu; www.eng.auburn.edu/~hendrix.

David A. Umphress is an associate pro-
fessor of computer science and software engi-
neering at Auburn University. His research inter-
ests are software processes, requirements
engineering, and software engineering educa-
tion. He received his PhD from Texas A&M Uni-
versity. Contact him at the Department of Com-
puter Science and Software Engineering, 107
Dunstan Hall, Auburn University, AL 36849;

umphress@eng.auburn.edu; www.eng.auburn.edu/~umphress.

James H. Cross is professor and chair of the
Department of Computer Science and Software En-
gineering at Auburn University. His research inter-
ests include software engineering environments,
software visualization, and object-oriented method-
ology. He received his PhD from Texas A&M Univer-
sity. Contact him at the Department of Computer
Science and Software Engineering, 107 Dunstan
Hall, Auburn University, AL 36849; cross@eng.

auburn.edu; www.eng.auburn.edu/~cross.

S E P T E M B E R  /  O C T O B E R  2 0 0 2

Codefast Inside Back Cover
Hewlett Packard Back Cover
John Wiley & Sons 1
SAP Labs Inside Front Cover
Scientific Toolworks 11
Software Development Conference 63

Advertising Personnel

Advertiser / Product                  Page Number

Marion Delaney
IEEE Media, 
Advertising Director
Phone: +1 212 419 7766
Fax: +1 212 419 7589
Email: md.ieeemedia@ieee.org
Marian Anderson
Advertising Coordinator
Phone: +1 714 821 8380
Fax: +1 714 821 4010
Email:
manderson@computer.org

Sandy Brown
IEEE Computer Society,
Business Development Manager
Phone: +1 714 821 8380
Fax: +1 714 821 4010
Email: sb.ieeemedia@ieee.org

Debbie Sims
Assistant Advertising 
Coordinator
Phone: +1 714 821 8380
Fax: +1 714 821 4010
Email: dsims@computer.org

Mid Atlantic 
(product/recruitment)
Dawn Becker
Phone: +1 732 772 0160
Fax:      +1 732 772 0161
Email: db.ieeemedia@ieee.org

Midwest (product)
David Kovacs
Phone:   +1 847 705 6867
Fax:        +1 847 705 6878
Email: dk.ieeemedia@ieee.org

Northwest (product)
John Gibbs
Phone:    +1 415 929 7619
Fax:        +1 415 577 5198
Email:   jg.ieeemedia@ieee.org

Southern CA (product)
Marshall Rubin
Phone:   +1 818 888 2407
Fax:       +1 818 888 4907
Email: mrubin@westworld.org

Southwest (product)
Royce House
Phone:   +1 713 668 1007
Fax:        +1 713 668 1176
Email: rh.ieeemedia@ieee.org

Japan
German Tajiri
Phone: +81 42 501 9551
Fax: +81 42 501 9552
Email:  gt.ieeemedia@ieee.org

Europe
Rob Walker
Phone: +44 193 256 4999
Fax: +44 193 256 4998
Email: r.walker@husonmedia.com

New England  
(product)
Jody Estabrook
Phone:   +1 978 244 0192
Fax:        +1 978 244 0103
Email: je.ieeemedia@ieee.org

New England  
(recruitment)
Barbara Lynch
Phone:   +1 401 738 6237
Fax:        +1 401 739 7970
Email: bl.ieeemedia@ieee.org

Midwest (recruitment)
Tom Wilcoxen
Phone:   +1 847 498 4520
Fax:        +1 847 498 5911
Email: tw.ieeemedia@ieee.org

Northwest (recruitment)
Mary Tonon
Phone:    +1 415 431 5333
Fax:         +1 415 431 5335
Email: mt.ieeemedia@ieee.org

Southern CA (recruitment)
Karin Altonaga
Phone:   +1 714 974 0555
Fax:       + 1 714 974 6853
Email: ka.ieeemedia@ieee.org

Southeast 
(product/recruitment)
C. William Bentz III
Email: bb.ieeemedia@ieee.org
Gregory Maddock
Email: gm.ieeemedia@ieee.org
Sarah K. Huey
Email: sh.ieeemedia@ieee.org
Phone: +1 404 256 3800
Fax: +1 404 255 7942

Advertising Sales Representatives

S e p t e m b e r / O c t o b e r  2 0 0 2 I E E E  S O F T W A R E 8 5



8 6 I E E E  S O F T W A R E S e p t e m b e r / O c t o b e r  2 0 0 2 0 7 4 0 - 7 4 5 9 / 0 2 / $ 1 7 . 0 0  ©  2 0 0 2  I E E E

used this developmental process in a two-se-
mester capstone design course, and TTU
and UTA used it in traditional one-semester
courses. This flexibility lets departments
work in existing approved curricula.

Our process exposes students to real-
world issues and uses class projects from
different departments that, when com-
bined, result in a working software prod-
uct. Instructors from various disciplines at
the three universities teach the classes, em-
ulating distributed software development
in industry, and each class has different
project tasks, responsibilities, and expert-
ise. Students are responsible for applying
their own discipline expertise, communi-
cating the results of their efforts, and un-
derstanding feedback from other disci-
plines in a timely manner. A final software
system and documentation is produced by
the end of TCU’s second semester. UTA

and TTU courses begin concurrently with
TCU’s first semester, when much of the
analysis, initial design, and early prototyp-
ing are done. In the second semester, new
classes at UTA and TTU participate in the
product development activity (depending
on what courses are offered at the two
campuses). The process is flexible enough
to allow for such variability by modifying
each school’s task assignments.

Motivation 
Rapid technology advances and dynamic

global markets can require companies to use
teams of product development specialists in
different locations.

This change in industry paradigm—
called collaborative product development
or integrated product teams—has pushed
for changes in university curricula, empha-
sizing broader topic-based design courses,

focus
Teaching Distributed
Multidisciplinary Software
Development

Lisa J. Burnell, Texas Christian University

John W. Priest, University of Texas, Arlington

John R. Durrett, Texas Tech University

To create a more
realistic distributed
collaborative
environment, three
Texas universities
developed an
innovative teaching
method for
collaborative
software
development in
distributed
multidisciplinary
environments.

C
ollaborative software development often involves people from
multiple disciplines and different locations working toward a
common goal in an information-rich environment. To create a
more realistic distributed collaborative environment, we devel-

oped a multi-university, multidiscipline process for teaching collaborative
software development. We tested this approach at Texas Christian Univer-
sity, the University of Texas at Arlington, and Texas Tech University. TCU

educating software professionals



team design, and communication. Accredi-
tation Board for Engineering and Technol-
ogy (ABET) rules now require programs to
“demonstrate an ability to function on
multidisciplinary teams, communicate ef-
fectively, and [provide] broad education �
in a global and societal context” (www.
abet.org). Most departments have in-
creased the level of design content in many
courses, increased communication skills,
and implemented one or two semester-long
capstone design courses to meet industry
needs and accreditation requirements. Be-
cause each department is responsible for its
own curriculum, each emphasizes the de-
sign content of that specific discipline.
Thus, most courses comprise students with
similar majors and backgrounds and are
located at one place. 

However, teaching standard software
engineering without considering interac-
tion with other disciplines fails to intro-
duce students to the total environment ex-
perience in which industry products are
developed. When we demonstrate learning
in a collaborative setting, students get an
appreciation of different styles, priorities,
and kinds of communication and develop a
tolerance for differences in knowledge and
skills.

A small international survey conducted
by Mary Last on virtual-team practices in
computer science education showed inter-
esting results (http://acad.stedwards.edu/
~last/virtual_team_results.htm). The stu-
dents surveyed reported that the difficult as-
pects of participating in a collaborative vir-
tual-team project were

� Lack of response or response 
delays from counterparts (poor 
communication)

� Lack of face-to-face contact
� Sharing versions of design and code
� Interdisciplinary culture differences 
� Arranging real-time discussion
� Conflicts in working patterns
� Lack of understanding of other 

disciplines

They also reported the major advantages:

� A sense of accomplishment 
� Meeting students from other 

universities

� Exposure to other disciplines
� Teamwork
� Flexible meeting schedules
� Added motivation to learn more and to

learn it in depth

Students will be better prepared to un-
derstand behavioral, not just technical, is-
sues. The lessons learned can be directly ap-
plied to improve current industry practice,
so industry can benefit as well.

Other surveys report that universities
benefit by developing distributed, col-
laborative projects.1–3 Many accreditation
(AACSB/ABET/CAC/ACM) and university
curriculum requirements are also satisfied. 

The universities (and specific depart-
ments) need to provide learning experi-
ences that meet accredidation, university,
and departmental requirements. For exam-
ple, at TCU the computer science depart-
ment requires seniors to complete a two-
semester software development sequence.
The described collaborative process meets
many of the internal and external require-
ments for course learning objectives and
better prepares students for industry than
conventional approaches. The university
benefits because the students satisfy their
requirements, and by offering better
courses, universities can recruit and retain
students. 

Pedagogical challenges 
Designing effective team projects is de-

manding. A systematic approach is even
more crucial when designing distributed,
multidisciplinary, and multiuniversity proj-
ects. There are several key challenges.

Simulating the industrial workplace 
To adequately simulate industry experi-

ences, students should be exposed to con-
flicting goals and motivations (including
dealing with low-performing team mem-
bers), differences in skills and knowledge,
lack of communication because of differing
locations and perspectives, and deliver-
able-based performance and scheduling
problems.

Selecting an appropriate project structure
Too much structure means that the stu-

dents will not get the learning experiences
of struggling with real development issues

S e p t e m b e r / O c t o b e r  2 0 0 2 I E E E  S O F T W A R E 8 7

The lessons
learned can be
directly applied

to improve
current
industry

practice, so
industry can

benefit as well.



such as ambiguity, uncertainty, change,
task prioritization, and trade-off analysis.
Too little structure might result in students
pursuing the wrong activities at the wrong
time, leading to wasted effort. The instruc-
tors must find the proper balance and ad-
just the amount of structure (explicit direc-
tions) given to students to fit specific
situations.

Designing projects so that students expe-
rience real struggles is essential to learning.
The instructor must anticipate these strug-
gles and offer increasing levels of support
when appropriate. Introducing develop-
ment methods “just in time” is especially ef-
fective when coupled with group analysis of
why some students’ chosen approaches
failed.

Selecting appropriate project difficulty 
Students learn by experience. If the

project is too easy, they won’t be moti-
vated to learn the theory and practice of
software engineering—it becomes “extra
work” the students feel compelled to do
because of a grade, not because they see
the benefit. The project requirements must
be incomplete, open-ended, complex, and
interweaved and necessitate designs with
many subcomponents—for example, a
Web-based intelligent system with data-
base requirements.

Scheduling tasks and disseminating results 
Meeting due dates is essential so each

team can meet its schedules and instructors
can synchronize lecture topics with the
product task schedule. For example, stu-

dents from one university are required to
evaluate the deliverables of students from
another university. After the student evalua-
tors submit their reports, the other students
evaluate these evaluations. In this way, stu-
dents receive peer feedback on their per-
formance, letting them see how others are
interpreting and using their work products. 

Final products are posted on the project
Web sites that are maintained throughout
the project. TCU students give final product
presentations at the end of the second se-
mester; these are open to all universities and
local industry. Videotapes of these presenta-
tions are made available to all interested
parties.

Defining and coordinating faculty responsi-
bilities 

Communication skills are important for
any interdisciplinary team effort. Skill, ex-
perience, goals, and other differences
among the students tend to cause “territo-
rial” conflicts and shrink communication
channels. Even though our method has tra-
ditional college-level instruction—repeated
face-to-face contact with similarly inter-
ested students—faculty members must coor-
dinate their efforts, do more planning up
front, and remain flexible in task assign-
ments and schedules.

Our approach
As in an industry project, you must es-

tablish responsibilities and a schedule for
each team—in this case, for each class.
Each university is from a different disci-
pline (department), and has a unique set of

8 8 I E E E  S O F T W A R E S e p t e m b e r / O c t o b e r  2 0 0 2

Table 1 
Major project responsibilities

Texas Christian University University of Texas at Arlington Texas Tech University
Fort Worth, Texas Arlington, Texas Lubbock, Texas

Department Computer Science Industrial Engineering Information Systems
College Science and Engineering Engineering Business Administration
Course title Software engineering and Product development Advanced Java 

senior design (two semesters) (one semester) (one semester)
Students Undergraduate Graduate and undergraduate Mostly graduate
Major responsibilities Development lead: design, User requirements, UTA degree- Server-side processing, Web server—

implementation, test, documentation planning rule base, user testing database interface
evaluation

Percentage of overall grade 40 30 70
Course objective Capstone design: Students will Design content: Students will Server-side Java: Students will 

demonstrate computer science and demonstrate knowledge of the product demonstrate the ability to transform 
software engineering skills through development life cycle and the role of a set of product requirements into
the development of a significant industrial engineers in product working programs using Java 
team project. development. programming techniques.



responsibilities. Individual course objec-
tives and student skills dictate the project
task assignment (see Table 1). The percent-
age of time devoted and grade credit
earned can vary by course, as long as each
team can meet their overall product devel-
opment responsibilities.

Schedules are defined by milestones,
when project artifacts are electronically dis-
seminated (see Table 2). Each class must
meet its deadlines, even if some tasks are in-
complete, because the scheduled deliverables
provide required input for the other classes. 

Deliverables for milestone 3
Each task is documented and sent elec-

tronically to the other university groups.
TCU must provide the following milestone
3 documentation:

� Project description and plan.
� Updated use case model.
� Design model (final design revision, at

least for those aspects that have been
implemented), including pseudocode for
nontrivial algorithms. Your design sec-
tion should start with a written discus-
sion of the design, the trade-offs you
made, and justification for your choices.

� Documented implementation. Your sys-
tem might run on a single machine; your
data sources, although they can still be
local, must be close to final requirements.

Also for milestone 3, UTA must report on
the TCU deliverables, with special attention

given to the analysis model, specified as use
cases. It must also identify missing use cases
or alternative scenarios, confusing or po-
tentially misunderstood areas, and errors.
TTU must provide GUI front ends for edit-
ing and adding records directly to the data-
base. These applications are expected to
validate data entered and to use the server-
side applications created for milestone 2.
Additional documentation requirements for
all three universities include team organiza-
tion descriptions, statements of work,
weekly status reports, peer evaluations, and
project presentations.

Student project: An intelligent
advisor system

The initial project description, provided
by the instructors, gives the general vision
for the project, including a domain scenario
to aid understanding. It outlines the techni-
cal motivation for this project, describing
why it is challenging, along with the inher-
ent technical issues to be considered in the
system analysis and design. A portion of
the project description appears in the “Vir-
tual Intelligent Advisor” sidebar. In the
analysis phase, students create the require-
ments model, which includes specification
of use cases to capture functional require-
ments (see Figure 1). In the transition from
analysis to early design, students prototype
the GUI, design and document the database
as an entity relationship diagram, and de-
sign the initial class model. Testing takes
place throughout the project life cycle. Fig-

S e p t e m b e r / O c t o b e r  2 0 0 2 I E E E  S O F T W A R E 8 9

Table 2 
Project schedule by institutions

Schedule of tasks Texas Christian University University of Texas at Arlington Texas Tech University
Weeks 1-3 Study and practice requirements Develop requirements models, Study and practice of SQL scripts
Requirements phase analysis methods needed for benchmark existing systems and interfacing to databases

milestone 1
Week 4 Create analysis model, including Review analysis model Create initial entity relationship
Milestone 1 prototype (due one week after TCU submits) diagram
Architecture and early phase
design
Week 6 Evaluate UTA review Provide UTA degree-planning rules Develop model from entity

and sample student transcripts relationship diagram
Week 8 Design and implement 1st build Review design model and test Build database interface as servlets
Milestone 2 (implement part of design) 1st build and Java server pages
Design phase
Week 12 Design and implement 2nd build Review design model, test 2nd build, Build GUI front-end for database
Milestone 3 evaluate test document editing
Test phase
Week 15 Write project documentation and Restructure servlets and JSP as Web 
Milestone 4 plan for 2nd semester, submit paper services



ure 2 shows the expected output from a
representative test plan.

Project and course evaluations 
We evaluated both the course and col-

laborative process regularly. Throughout
each semester, student peer groups (from
each participating institution) and faculty
from one or more of the institutions evalu-
ated student project deliverables. Industry
advisory board members also evaluated
this approach and reported that the
process simulated a best-practices corpo-
rate environment. They also commented
on the expected benefits that resulted from
the multidisciplinary teams and communi-
cations facets of the project. 

By evaluating each other’s project deliv-
erables, the students saw how others were
using their work products. This also re-
vealed some problems with response lag
time and unclear functionality and respon-
sibilities. Too often, evaluations were re-
turned too close to the next deliverable and
therefore too late for students to make any
major changes. In addition, TCU students
were upset with UTA students’ ostensible
lack of computer literacy, UTA students be-
lieved that TCU students ignored many of
their requirements, and TTU students al-
most exclusively focused on user interface
issues. All the groups were surprised that
the other groups did not “know” what they
meant. For example, a student commented,

UTA students were unaware of our proj-
ect specifications (even though they were a
part of the deliverable) and spent too much
time focusing on mundane details rather
than system functionality. We wanted infor-
mation on how our system performed, not
on how the user interface looks. The
biggest obstacle with having the UTA stu-
dents evaluate our program was that most
were unfamiliar with programming and, 
it seemed, computer functionality. Because
our program was just a prototype, we
could not give complete installation files 
to make it as easy as possible.

Student perceptions of the projects and
the distributed collaborative process shows
striking similarity to problems found in in-
dustry: most observations focused on team-
work, communication, and common goals.
Comments included the following:

9 0 I E E E  S O F T W A R E S e p t e m b e r / O c t o b e r  2 0 0 2

The following is an excerpt from docu-
mentation given to each new team of stu-
dents assigned to Intelligent Advisor, a
Web-based support system that delivers ad-
vising services to students, such as degree
planning, course approval, transfer analy-
sis, and general information regarding
types of degree plans, market outlook (types
of jobs, location, and pay), and so on. 

Moving beyond the common yet mar-
ginally effective strategy of making paper-
based advising materials electronically
available, we seek to provide a means by
which a student (or potential student) can

engage in a dialogue with an “Intelligent
Advisor.” Students want to get answers
quickly to specific questions, not wade
through pages of online documents.

For example, Elton wants to gradu-
ate as quickly as possible, subject to the
realities of his specific situation. He can
only take online or night classes, be-
cause he works full time during the day.
In the summer, he could take a morning
class, but he would prefer not to. He be-
lieves that if the classes are not too
hard, he could take 15 hours a semes-
ter. If he has one or more tough or really

time-consuming classes, he should take
no more than 9 or 12 hours. He wants
to get a computer science degree, but if
he can graduate much sooner, he would
consider a computer information science
degree. Before deciding to switch ma-
jors, he would like to better understand
the differences between the two de-
grees—specifically, what kinds of jobs
he can get, where those jobs are, and
how much they pay.

The education domain in general, as
well as the Intelligent Advisor project,
provides a framework for studying a

The Virtual Intelligent Advisor

Description:
The student can choose to create their degree plan manually 
for a selected number of semesters. The student is given a list of 
courses offered within the university. The student can then select
courses for each semester. When finished, the system verifies the 
plan and reports errors.

Primary Scenario:
1. Student selects User Defined Degree Planner option.
2. System retrieves information on student courses and displays 
     them.
3. Student assigns courses to desired semesters and requests system 
     verification.
4. System checks rules, including prerequisites.
5. System returns with approval or explanation of errors.

Figure 1. A use case capturing the functional requirements of
a user-defined degree planning procedure.



� Product design. “It would have been best
to design, agree upon, and fully under-
stand all of the interfaces before we be-
gan work on the objects that use those
interfaces. This would have allowed us
to work independently sooner and have
less difficulty with integration.”

� Product design. “Why can’t [we] design
our own interfaces? The UTA require-
ments are way too complex, and we
need to redesign them before we can
build the database.”

� Communication. “At times it was unclear
what each group was responsible for ac-
complishing. This was especially difficult
when we began working together.”

� Teamwork. “We would rather design the
database ourselves rather than waiting
for the database implementation from
TTU. Furthermore, by using our own
database, we would have more control
over direct creation and modification of
data needed for each module. It is rather
difficult to anticipate the time and qual-
ity of responses from groups at other
universities. Rather than waiting on
their response, we could already have
worked out a solution to the problem.” 

� Teamwork and scheduling. “TTU had
to design and implement the database,
enter the data, and create the server-side
front ends before all the other students
had to do anything and before we un-
derstood enough of what we were doing
on the project technically.”

Fortunately, not all comments were neg-
ative. Overall, students generally expressed

a great deal of satisfaction with the project.
The initial requirements documents and use
cases, along with the ongoing availability of
student project results from other disci-
plines, made students feel that they were
working in a more professional environ-
ment. For example, one student said, “I
checked all the test cases in the documenta-
tion and everything worked just as it should
have. This process of round-trip evaluation
is highly recommended. I thought this team
had by far the best prototype. It is more
functional and usable.”

S e p t e m b e r / O c t o b e r  2 0 0 2 I E E E  S O F T W A R E 9 1

Figure 2. Test case output, as described by a test plan, shows
what occurs when the student creates a degree plan with 
errors due to a course conflict.

number of important concepts:

� Dynamic, complex rules vary widely
across departments and universities
and over time.

� User modeling techniques that can
adapt the user interface to the user’s
knowledge, skills, and interaction
styles are valuable. 

� We must provide services to an in-
creasingly diverse, geographically
distributed student community. 

A primary goal of this system is main-

tainability; that is, it must be easy to
adapt to specific and evolving require-
ments in and across universities. For ex-
ample, it should be straightforward for a
Texas Tech advisor to customize the sys-
tem to fit his or her requirements, even
though Texas Christian faculty have de-
veloped the system to fit its computer sci-
ence requirements first. Some data and
processes are department-, college-, and
university-specific and dynamic (rapidly
changing). The system needs to be de-
signed to account for this reality. 

Specifically, the system should be able to

� Recommend at least some courses
to take for next semester, checking
for hard constraints (such as time
conflicts) and preferences (such as
morning classes only).

� Check for a complete degree plan
(proposed plan of courses over a
number of semesters that satisfies
degree requirements). 

� Generate a degree plan of major
courses from the current semester
until the student graduates, subject
to student preferences and expected
course offerings.



The final product quality is one measure
of the project’s success. The final product
was superior to those traditionally found in
senior projects, especially in the GUI inter-
face, adherence to user requirements, and
documentation. Although the final system
lacked some desired functionality, the over-
all result was positive.

Recommendations
Our experiences resulted in a number of

lessons learned. By applying these recom-
mendations, we believe we can improve the
student experience.

Scheduling
Scheduling the due dates and distributing

materials were major challenges and possi-
bly the most important changes we would
make to the process. Getting rapid turn-
around so that evaluations are actually help-
ful is a challenge. On the date TCU projects
were due, we posted the documentation and
the prototypes on the course Web page. The
UTA and TTU students then had to retrieve
them, evaluate them, and send the results
back to faculty at UTA, TTU, and TCU. We
should have had these results posted as well
to avoid delays in getting them distributed.
The TCU students then had to assess the
evaluations quickly to get them back to the
UTA and TTU students. With major project
deadlines every three to four weeks, the
turnaround took too long. We made changes
for the second semester that helped with
scheduling and communication. 

We had each team establish special email
accounts to communicate directly, with
copies sent to the instructors. Some teams
established their own chat rooms as well.
This direct communication approach
greatly improved interschool cooperation. 

Team mindset
Creating a team mindset is crucial to suc-

cess. In any effective team, cooperation with
and adaptation to others is required. Tech-
nologically sophisticated students must
adapt to and value the contributions of
those less technologically oriented. Students
must also be motivated to view the overall
project success as the ultimate goal. Meth-
ods that let students put a face with a name,
such as videoconferencing, would be benefi-
cial. In the second semester, we held multi-

ple “meet and greet” sessions at local
restaurants for students at two of the
schools. Students enjoyed the experience
and demonstrated an improved attitude to-
ward working with the other schools, which
was reflected in their documentation and
cooperation. 

Communication
Many communication problems focused

on the differences in students’ perceptions
rather than in skills and backgrounds. Be-
cause students develop and analyze artifacts
that the other schools actually use, they
must have a clear understanding of the pur-
pose of each task they are asked to perform.
Instructors must describe the overall project
tasks, each school’s role, and how they 
interrelate. 

Special challenges
Teaching in a distributed, collaborative in-

structional environment requires special
skills.4 We can divide these skills broadly into
two categories: technical and behavioral. In-
structors need basic technical skills such as
the ability to communicate via email and the
Web. This includes setting up email distribu-
tion lists, maintaining course and project
Web sites, and posting student or instructor
materials on the Internet. They also need to
be familiar with the course objectives, meth-
ods, and student preparation in each partici-
pating course. The needed behavioral skills
are adaptability and solidarity. Instructors
must be able to adapt to changes in material
and student progress in several courses at
once rather than just in a single course. Fre-
quent faculty communication, by conference
calls, emails, or other means, is needed for
the negotiation and replanning of class tasks
and schedules. Instructors also must support
one another by communicating to their own
students why this collaborative process bene-
fits all students and by discouraging any non-
constructive criticism of the other classes’
skills, knowledge, or value. 

Implementing the process
The process was worth doing. According

to our industry advisory board, the process
successfully simulated industry problems
with communication, teamwork, and con-
flicting requirements and priorities. By
working through these problems, the end

Our
experiences
resulted in 
a number 
of lessons

learned. By
applying these

lessons, we
believe we can

improve the
student

experience.

9 2 I E E E  S O F T W A R E S e p t e m b e r / O c t o b e r  2 0 0 2



result was a quality product that was easy
to use and of which students could be
proud. 

T eamwork and communication arereal challenges for software devel-opment in both industry and uni-
versities. The process we have described
builds skills through hands-on experiences
for university students. Texts and lectures
offer method and process descriptions and
advice on their application, but students
learn by actually doing software develop-
ment and being exposed to real-world is-
sues. In some cases, students best learn les-
sons by suffering the consequences of not
applying sound software development
processes and methods. It is the instructor’s
job to provide the environment, support,
and guidance to help students navigate the
troubles they might experience. 

Acknowledgments
We thank the guest editors and anonymous re-

viewers for their comments and suggestions. We also
thank our students for their hard work and feedback
in implementing this process.

References
1. J.R. Ivins, “Interdisciplinary Project Work: Practice

Makes Perfect?” IEEE Trans. Education, vol. 40, no. 3,
Aug. 1997, pp. 179–183.

2. E.Z. Lui et al., “Web-Based Peer Review: The Learner
as both Adapter and Reviewer,” IEEE Trans.
Education, vol. 44, no. 3, Aug. 2001, pp. 246–251.

3. J.W. Priest, W.D. Bodensteiner, and N.K. Muir, “A Sur-
vey of Educational and Training Needs for Transition
of a Product from Development to Manufacturing,”
IEEE Trans. Education, vol. 37, no. 1, Feb. 1994, pp.
13–22.

4. I. McAlpine, “Collaborative Learning Online,” Dis-
tance Education, vol. 21, no.1, Jan. 2000, pp. 66–80.

For more information on this or any other computing topic, please visit our
Digital Library at http://computer.org/publications/dlib.

S e p t e m b e r / O c t o b e r  2 0 0 2 I E E E  S O F T W A R E 9 3

About the Authors

Lisa J. Burnell is an assistant professor of computer science at Texas Christian Uni-
versity. Her research interests are probabilistic reasoning, decision-theoretic inference, and
software engineering methodologies. She has a BA in mathematics, and an MS and PhD in
computer science all from The University of Texas at Arlington. You can reach her at Dept. of
Computer Science, Texas Christian Univ., TCU Box 298850, Fort Worth TX 76129;
l.burnell@tcu.edu. 

John R. Durrett is an assistant professor of information systems at Texas Tech Uni-
versity. His research and teaching interests are distributed systems design, e-learning, and net-
work security. He received his PhD from the University of Texas, Austin, in information systems
and his MBA and BA from West Texas A&M. You can reach him at Area of Information Systems
& Quantitative Sciences, MS 2101, Texas Tech Univ., Lubbock, TX, 79409; john@durrett.org. 

John W. Priest is a professor of industrial and manufacturing engineering at The
Univ. of Texas, Arlington. His technical interests include the product development process, de-
sign for manufacturing, and technical risk management. He has a BS in industrial engineering
from Kettering Univ. and an MS and PhD in industrial engineering from The Univ. of Texas at
Arlington. You can reach him at Dept. of Industrial and Manufacturing Systems Engineering,
The Univ. of Texas at Arlington, Box 19017, Arlington, TX 76019; jpriest@uta.edu. 

http://computer.org/software

IEEE

Stay in the software gameStay in the software game
Visit 
IEEE Software
on the Web 
at


